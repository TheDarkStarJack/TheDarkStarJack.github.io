[
  
  {
    "title": "PostgreSQL 硬性限制",
    "url": "/posts/PostgreSQL-%E7%A1%AC%E6%80%A7%E9%99%90%E5%88%B6/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-09-06 15:43:17 +0800",
    





    
    "snippet": "https://www.postgresql.org/docs/current/limits.html在使用 pg 的时候，需要注意一些硬性限制，例如代码中写死的，这里记录一下，方便自己查阅，有的时候直接查阅官网反而因为内容太多导致忘记这些关键内容            Item      Upper Limit      Comment                  database ...",
    "content": "https://www.postgresql.org/docs/current/limits.html在使用 pg 的时候，需要注意一些硬性限制，例如代码中写死的，这里记录一下，方便自己查阅，有的时候直接查阅官网反而因为内容太多导致忘记这些关键内容            Item      Upper Limit      Comment                  database size      unlimited                     number of databases      4,294,950,911                     relations per database      1,431,650,303                     relation size      32 TB      with the default BLCKSZ of 8192 bytes              rows per table      limited by the number of tuples that can fit onto 4,294,967,295 pages                     columns per table      1,600      further limited by tuple size fitting on a single page; see note below              columns in a result set      1,664                     field size      1 GB                     indexes per table      unlimited      constrained by maximum relations per database              columns per index      32      can be increased by recompiling PostgreSQL              partition keys      32      can be increased by recompiling PostgreSQL              identifier length      63 bytes      can be increased by recompiling PostgreSQL              function arguments      100      can be increased by recompiling PostgreSQL              query parameters      65,535             "
  },
  
  {
    "title": "Linux 利用 wc 统计行数和字符长度",
    "url": "/posts/Linux-%E5%88%A9%E7%94%A8-wc-%E7%BB%9F%E8%AE%A1%E8%A1%8C%E6%95%B0%E5%92%8C%E5%AD%97%E7%AC%A6%E9%95%BF%E5%BA%A6/",
    "categories": "Linux, tools",
    "tags": "wc",
    "date": "2024-09-05 16:18:22 +0800",
    





    
    "snippet": "前言在 Linux 环境中可以利用 wc 工具统计行数和字符长度等统计行数和字符长度wc 使用特别简单，可以使用 wc --help 查看使用帮助，本文主要记录一下统计行数和字符长度的时候遇到的一个小问题，统计字符的长度不准在统计一个字符长度的时候明明是 24 位，但是 wc 的结果却是 25┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ ech...",
    "content": "前言在 Linux 环境中可以利用 wc 工具统计行数和字符长度等统计行数和字符长度wc 使用特别简单，可以使用 wc --help 查看使用帮助，本文主要记录一下统计行数和字符长度的时候遇到的一个小问题，统计字符的长度不准在统计一个字符长度的时候明明是 24 位，但是 wc 的结果却是 25┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo 000000010000000000000001 | wc -m25还好我记得长度是 24 ，wc 统计的结果却是 25，多出来一个字符长度，这是什么原因呢？┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo 1 | wc -m2┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo | wc -m1可以看到，即便统计空的字符也会有一个字符长度，难道闹鬼了？肯定不是，在现代主义国家，这是不可能的事。这个时候可以利用 cat 工具的 -A 选项查看所有的(隐藏)字符：┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo 1 | cat -A1$可以发现末尾有一个 ‘$’ ，这怎么处理呢，总不能还要单独处理这个字符吧。因为 echo 会自动换行，所以才会多出来一个 ‘$’ 字符，可以使用选项 -n 避免换行┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo -n 1 | cat -A1┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo -n 1 | wc -m1使用 wc -l 统计行数的时候也是同理：┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo | wc -l1┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo -n | wc -l0┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo | cat -A$总结其实这不是 wc 工具的问题，是 echo 自动换行/添加新行导致的。如果需要统计 echo 展示的内容行数和字符数量，需要使用 ‘echo -n’ 避免自动添加新行后续测试发现通过管道符或者直接读取文件中内容都会因为 ‘$’ 字符导致统计字符数量不准确，之前没怎么注意，这次发现这个问题在此记录一下：┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ basename /Postgres/pg10data/pg_wal/000000010000000000000001000000010000000000000001┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ basename /Postgres/pg10data/pg_wal/000000010000000000000001 | wc -m25┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ basename /Postgres/pg10data/pg_wal/000000010000000000000001 | cat -A000000010000000000000001$┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ basename /Postgres/pg10data/pg_wal/000000010000000000000001 &gt; tmp.txt┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ wl -m tmp.txt-bash: wl: command not found┌─[✗]─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ wc -m tmp.txt25 tmp.txt┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ &gt; tmp.txt┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ vim tmp.txt┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ ┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ wc -m tmp.txt25 tmp.txt"
  },
  
  {
    "title": "PostgreSQL Write Ahead Logging WAL",
    "url": "/posts/PostgreSQL-Write-Ahead-Logging-WAL/",
    "categories": "DataBase, PostgreSQL",
    "tags": "WAL",
    "date": "2024-09-05 15:15:35 +0800",
    





    
    "snippet": "前言WAL 是 Write Ahead Log 的缩写，预写式日志。WAL log 也被称为 xlog 。WalWriter 进程就是写 WAL 日志的进程。预写式日志的概念就是在修改数据之前，必须要把这些修改操作记录到磁盘中，这样后面更新实际数据时，就不需要实时地把数据持久化到文件中了。即使机器突然宕机或数据库异常退出，导致一部分内存中的脏数据没有及时地刷新到文件中，在数据库重启后，通过读...",
    "content": "前言WAL 是 Write Ahead Log 的缩写，预写式日志。WAL log 也被称为 xlog 。WalWriter 进程就是写 WAL 日志的进程。预写式日志的概念就是在修改数据之前，必须要把这些修改操作记录到磁盘中，这样后面更新实际数据时，就不需要实时地把数据持久化到文件中了。即使机器突然宕机或数据库异常退出，导致一部分内存中的脏数据没有及时地刷新到文件中，在数据库重启后，通过读取 WAL 日志，并把最后一部分的 WAL 日志重新执行一遍，就可以恢复到宕机时的状态。作用WAL 可以理解为 pg 数据库的重做日志与 Oracle 的Redo Log 的功能是一样的。因为 WAL 的存在，所以日志类型的文件系统对于 pg 来说不是必须的。例如 zfs 就是日志类型的文件系统，在持久化之前会记录日志，保证数据的原子性。（而且每当新数据写入 ZFS 时，它都会为该数据创建校验和（checksum）。当读取该数据时，校验和被验证。如果校验和不匹配，则 ZFS 知道已检测到错误。然后 ZFS 将自动尝试更正错误。）日志文件系统 在日志记录开销会降低性能，特别是当日志记录导致文件系统数据被刷新到磁盘时。不过，日志记录期间的数据刷新通常可以通过文件系统挂载选项禁用，例如在Linux ext3文件系统上。但是日志文件系统可以提高崩溃后的启动速度。使用 WAL 可以显著减少磁盘写入次数，因为只需要将日志文件刷新到磁盘以保证提交事务，而不是事务更改的每个数据文件。日志文件是按顺序写入的，因此同步日志的成本远低于刷新数据页的成本。对于处理许多涉及数据存储不同部分的小事务的服务器来说，尤其如此。此外，当服务器正在处理许多小型并发事务时，其中一个日志文件可能足以提交许多事务。WAL 还可以支持在线备份和时间点恢复。通过存档 WAL 数据，我们可以支持恢复到可用 WAL 数据所覆盖的任何时间：我们只需安装数据库的先前物理备份，并在所需时间重放 WAL 日志。更重要的是，物理备份不必是数据库状态的实时快照。 如果它是在一段时间内进行的，那么重放该时间段的 WAL 日志将解决任何内部数据不一致的问题。文件位置WAL 文件在 PostgreSQL9.X 及以下版本是在 pg_xlog 目录下的，而在 PostgreSQL10.X 及以上版本是在 pg_wal 目录下的。查看 WAL 文件所在的目录，会看到如下文件列表:## 文件名为24个字母长度的都是WAL文件pg15@TheDarkStar:/data_dir/PostgreSQL/data$ ll pg15/pg_wal/total 16388-rw------- 1 pg15 pg15 16777216 Sep  9 19:30 000000010000000000000001drwx------ 2 pg15 pg15     4096 Sep  8 16:18 archive_statusWAL 日志保存在 pg_xlog/pg_wal 下。每个 xlog 文件默认是 16MB，为了满足恢复要求，在 xlog 目录下会产生多个 WAL 日志，这样就可保证在宕机后，未持久化的数据都可以通过 WAL 日志来恢复，那些不需要的 WAL 日志将会被自动覆盖WAL 文件名的意义WAL 文件名的长度是固定的 24 位，由三部分组成，每一个部分 8 个字符长度：  时间线:英文为 timeline，是以 1 开始的递增数字，如 1，2，3……  LogId: 32 bit 长的一个数字，是以 0 开始递增的，如 0，1，2 实际为 LSN 的高 32 bit。  LogSeg: 32 bit 长的一个数字，是以 0 开始递增的，如 0，1，2, 3，···。LogSeg 是 LSN 的低 32 bit 的值再除以 WAL 文件大小 (通常为 16 MB) 的结果。注意: 当 LogId 为 0 时，LogSeg 是从 1 开始的。 WAL日志文件默认大小为16MB，如果想改变其大小，在PostgreSQL10.X及之前的版本中需要重新编译程序，在PostgreSQL11.X版本之后，可以在Initdb初始化数据库实例时指定WAL文件的大小。如果WAL文件是默认大小，即16MB时，LogSeg最大为FF，即000000~0000FF，即在文件名中，最后8字节中前6字节总是0。这是因为LSN的低32bit的值再除以WAL文件大小[2^32/(16*1024*1024)=256]最大只能是256，换算成十六进制，即FF。总结WAL 相当于 Oracle 的 redo log，用于 pg 实例崩溃恢复是保证数据完整一致。WAL 采用顺序写入的方式，而且在数据的变更刷盘之前先行写入可以参考官网描述"
  },
  
  {
    "title": "PostgreSQL WAL 相关参数",
    "url": "/posts/PostgreSQL-WAL-%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/",
    "categories": "DataBase, PostgreSQL",
    "tags": "WAL",
    "date": "2024-09-05 15:09:00 +0800",
    





    
    "snippet": "前言WAL 是 PostgreSQL 的关键组件，用于保证崩溃恢复时数据完整一致，在这里记录一下相关的参数WAL 参数不同的版本可能参数不一样，具体可以查询官网或者进入实例之后查询：-- PostgreSQL 15.8 -- 如果需要参数描述和范围可以查看 short_desc, extra_desc, context 字段127.0.0.1:54323; wxj@demo &gt; sel...",
    "content": "前言WAL 是 PostgreSQL 的关键组件，用于保证崩溃恢复时数据完整一致，在这里记录一下相关的参数WAL 参数不同的版本可能参数不一样，具体可以查询官网或者进入实例之后查询：-- PostgreSQL 15.8 -- 如果需要参数描述和范围可以查看 short_desc, extra_desc, context 字段127.0.0.1:54323; wxj@demo &gt; select name, setting, unit from pg_settings where name like '%wal%';+-------------------------------+-----------+------+|             name              |  setting  | unit |+-------------------------------+-----------+------+| max_slot_wal_keep_size        | -1        | MB   || max_wal_senders               | 10        | NULL || max_wal_size                  | 1024      | MB   || min_wal_size                  | 80        | MB   || track_wal_io_timing           | off       | NULL || wal_block_size                | 8192      | NULL || wal_buffers                   | 512       | 8kB  || wal_compression               | off       | NULL || wal_consistency_checking      |           | NULL || wal_decode_buffer_size        | 524288    | B    || wal_init_zero                 | on        | NULL || wal_keep_size                 | 0         | MB   || wal_level                     | replica   | NULL || wal_log_hints                 | off       | NULL || wal_receiver_create_temp_slot | off       | NULL || wal_receiver_status_interval  | 10        | s    || wal_receiver_timeout          | 60000     | ms   || wal_recycle                   | on        | NULL || wal_retrieve_retry_interval   | 5000      | ms   || wal_segment_size              | 16777216  | B    || wal_sender_timeout            | 60000     | ms   || wal_skip_threshold            | 2048      | kB   || wal_sync_method               | fdatasync | NULL || wal_writer_delay              | 200       | ms   || wal_writer_flush_after        | 128       | 8kB  |+-------------------------------+-----------+------+(25 rows)以下内容参考文档翻译描述Replication 流复制相关max_slot_wal_keep_size指定主库实例可以支持的最大复制槽数量，详情参考。默认值为  10 。此参数只能在实例启动时设置。将其设置为低于当前现有复制槽数量的值将无法启动实例。另外，wal_level 必须设置为 replica  或更高才能允许使用复制槽。在订阅端，指定可以同时跟踪多少个复制源，参考，从而有效限制可以在实例中创建的逻辑复制订阅数量。将其设置为低于当前跟踪的复制源数量（可以通过 pg_replication_origin_status 查询，请注意并不是 pg_replication_origin ）的值将阻止实例启动。max_wal_senders指定来自备库或流基础备份客户端的最大并发连接数（即同时运行的 WAL 发送进程的最大数量）。默认值为 10。取值为 0 表示禁用复制。流客户端的突然断开连接可能会留下孤立的连接槽，直到达到超时为止，因此该参数应设置为略高于预期客户端的最大数量，以便断开连接的客户端可以立即重新连接。该参数只能在服务器启动时设置。此外，wal_level 必须设置为 replica 或更高，以允许来自备库的连接。运行备库时，必须将此参数设置为与主库相同或更高的值。否则，备库将不允许查询。wal_keep_size指定保留在 pg_wal 目录中的过去日志文件段的最小大小，以防备用服务器需要获取它们以进行流复制。如果连接到发送服务器的备用服务器落后超过 wal_keep_size 兆字节，则发送服务器可能会删除备用服务器仍需要的 WAL 段，在这种情况下，复制连接将终止。下游连接最终也将因此失败。 （但是，如果正在使用 WAL 归档，备用服务器可以通过从归档中获取段来恢复。）这仅设置 pg_wal 中保留的段的最小大小；系统可能需要保留更多的段用于 WAL 归档或从检查点恢复。如果 wal_keep_size 为零（默认值），系统不会保留任何额外的段用于备用目的，因此备用服务器可用的旧 WAL 段的数量是前一个检查点的位置和 WAL 归档状态的函数。如果指定该值时没有单位，则以兆字节为单位。该参数只能在 postgresql.conf 文件或服务器命令行中设置。wal_levelwal_level 决定了写入 WAL（预写日志）的信息量。默认值为 replica，记录足够的数据以支持 WAL 归档和复制，包括在备用服务器上运行只读查询。minimal 则删除所有日志记录，除了恢复崩溃或立即关闭所需的信息。最后，logical 添加了支持逻辑解码所需的信息。每个级别都包含所有较低级别记录的信息。此参数只能在服务器启动时设置。minimal 级别生成最少的 WAL 量。对于创建或重写永久关系的事务，它不会记录行信息。这可以显著加快操作（参考）。发起此优化的操作包括：ALTER … SET TABLESPACECLUSTERCREATE TABLEREFRESH MATERIALIZED VIEW（不带 CONCURRENTLY）REINDEXTRUNCATE然而，minimal WAL 不包含足够的信息来进行时间点恢复，因此需要使用 replica 或更高的级别来启用连续归档（archive_mode）和流式二进制复制。实际上，如果 max_wal_senders 不为零，服务器甚至无法以该模式启动。请注意，将 wal_level 更改为 minimal 会使先前的基本备份无法用于时间点恢复和备用服务器。在 logical 级别，记录与 replica 相同的信息，外加从 WAL 中提取逻辑更改集所需的信息。使用 logical 级别会增加 WAL 量，特别是当许多表配置为 REPLICA IDENTITY FULL 并执行大量的 UPDATE 和 DELETE 语句时。在 9.6 之前的版本中，此参数还允许使用 archive 和 hot_standby 作为值。这些值仍然被接受，但会映射到 replica。wal_receiver_timeout终止超过该时间段未活动的复制连接。这对于接收备用服务器检测主节点崩溃或网络中断非常有用。如果此值未指定单位，则默认以毫秒计算。默认值为 60 秒。值为 0 则禁用超时机制。此参数只能在 postgresql.conf 文件中或通过服务器命令行设置。wal_retrieve_retry_interval指定当从任何来源（流复制、本地 pg_wal 或 WAL 归档）无法获取 WAL 数据时，备用服务器应等待多长时间再尝试检索 WAL 数据。如果此值未指定单位，则默认以毫秒计算。默认值为 5 秒。此参数只能在 postgresql.conf 文件或服务器命令行中设置。此参数在恢复节点需要控制等待新 WAL 数据可用的时间时非常有用。例如，在归档恢复中，通过减少此参数的值，可以使恢复对检测新 WAL 日志文件更加敏感。在 WAL 活动较少的系统上，增加此值可以减少访问 WAL 归档的请求次数，这在云环境中尤为有用，因为基础设施的访问次数会被考虑在内。wal_sender_timeout终止超过该时间段未活动的复制连接。这对于发送服务器检测备用服务器崩溃或网络中断非常有用。如果此值未指定单位，则默认以毫秒计算。默认值为 60 秒。值为 0 则禁用超时机制。在跨多个地理位置分布的集群中，为不同位置使用不同的值可以为集群管理带来更大的灵活性。对于具有低延迟网络连接的备用服务器，较小的值有助于更快地检测故障；对于位于远程位置且网络延迟较高的备用服务器，较大的值有助于更好地判断备用服务器的健康状况。wal-configurationmin_wal_size / max_wal_sizepg_wal 目录中的 WAL 段文件数量取决于 min_wal_size、max_wal_size 以及之前检查点周期生成的 WAL 数量。当不再需要旧的日志段文件时，它们将被删除或回收。如果由于日志输出率的短期峰值而超过 max_wal_size，则不需要的段文件将被删除，直到系统恢复到此限制以下。低于该限制，系统将回收足够的 WAL 文件以满足下一个检查点之前的估计需求，并删除其余文件。该估计基于先前检查点周期中使用的 WAL 文件数量的移动平均值。如果实际使用量超过估计值，移动平均值会立即增加，因此它在一定程度上适应了峰值使用量而不是平均使用量。 min_wal_size 设置了为将来使用而回收的 WAL 文件数量的最小值；即使系统空闲并且 WAL 使用量估计表明只需要很少的 WAL，那么多的 WAL 总是会被回收以供将来使用。只要 WAL 磁盘使用量保持在 min_wal_size 设置以下，旧的 WAL 文件总是会被回收以供将来在检查点使用，而不是被删除。这可用于确保保留足够的 WAL 空间来处理 WAL 使用量的峰值，例如在运行大型批处理作业时。如果指定该值时没有单位，则以兆字节为单位。默认值为 80 MB。该参数只能在 postgresql.conf 文件或服务器命令行中设置。max_wal_size 表示 WAL 在自动检查点期间增长的最大大小。这是一个软限制；在特殊情况下，WAL 大小可能会超过 max_wal_size，例如高负载、archive_command 或 archive_library 失败或较高的 wal_keep_size 设置。如果指定该值时没有单位，则以兆字节为单位。默认值为 1 GB。增加此参数可以增加崩溃恢复所需的时间。该参数只能在 postgresql.conf 文件或服务器命令行中设置。track_wal_io_timing有两个内部函数将 WAL 数据写入磁盘：XLogWrite 和 issue_xlog_fsync 。当 track_wal_io_timing 启用时，XLogWrite 写入和 issue_xlog_fsync 将 WAL 数据同步到磁盘的总时间分别计为 pg_stat_wal 中的 wal_write_time 和 wal_sync_time 。 XLogWrite  通常由 XLogInsertRecord （当 WAL 缓冲区中没有空间容纳新记录时）、 XLogFlush 和 WAL writer 调用，以将 WAL 缓冲区写入磁盘并调用 issues_xlog_fsync。 issues_xlog_fsync 通常由 XLogWrite 调用以将 WAL 文件同步到磁盘。如果 wal_sync_method 是 open_datasync 或 open_sync，则 XLogWrite 中的写入操作保证将写入的 WAL 数据同步到磁盘，而 issues_xlog_fsync 不执行任何操作。如果 wal_sync_method 是 fdatasync、fsync 或 fsync_writethrough，则写入操作会将 WAL 缓冲区移动到内核缓存，并通过 issues_xlog_fsync 将它们同步到磁盘。无论 track_wal_io_timing 如何设置，XLogWrite 写入和 issue_xlog_fsync 将 WAL 数据同步到磁盘的次数也分别计为 pg_stat_wal 中的 wal_write 和 wal_sync 。启用 WAL I/O 调用的计时。该参数默认关闭，因为它会重复查询操作系统当前时间，这可能会在某些平台上造成很大的开销。您可以使用 pg_test_timing 工具来测量系统上的计时开销。 I/O 计时信息显示在 pg_stat_wal 中。只有超级用户和具有适当 SET 权限的用户才能更改此设置。wal_block_size设置 WAL block 大小。早期在编译时通过 --with-wal-blocksize 指定，现在可以在 initdb 初始化的时候指定，可以查看源码（src/include/catalog/pg_control.h）中 XLOG_BLCKSZ 的描述。默认值为 8192 字节。/* Size of a WAL file block. This need have no particular relation to BLCKSZ.                       XLOG_BLCKSZ must be a power of 2, and if your system supports O_DIRECT I/O,                       XLOG_BLCKSZ must be a multiple of the alignment requirement for direct-I/O                       buffers, else direct I/O may fail. Changing XLOG_BLCKSZ requires an initdb.                       */wal_buffers用于尚未写入磁盘的 WAL 数据的共享内存量。默认取值为 ‘-1’ ，这会自动调整选择等于 shared_buffers 的 1/32（约3%）的大小，但不小于 64kB 也不大于一个 WAL 段的大小，通常为 16MB 。如果自动选择太大或太小，可以手动设置该值，但任何小于 32kB  的正值都将被视为 32kB。如果指定该值时不带单位，则将其视为 WAL  块，即 XLOG_BLCKSZ 字节，通常为 8kB。该参数只能在服务器启动时设置。WAL 缓冲区的内容在每次事务提交时都会写入磁盘，因此极大的值不太可能提供显着的好处。但是，将此值设置为至少几兆字节可以提高许多客户端同时提交的繁忙服务器上的写入性能。在大多数情况下，默认设置 -1 选择的自动调整应该会给出合理的结果。wal_compression该参数允许使用指定的压缩方法来压缩 WAL。启用后，当 full_page_writes 开启或在基本备份期间，PostgreSQL 服务器会压缩写入 WAL 的全部 page image。压缩的 page image将在 WAL 重放期间被解压缩。支持的方法是 pglz、lz4（如果 PostgreSQL 是使用 –with-lz4 编译的）和 zstd（如果 PostgreSQL 是使用 –with-zstd 编译的）。默认值是关闭。只有超级用户和具有适当 SET 权限的用户才能更改此设置。启用压缩可以减少 WAL 体积，而不会增加不可恢复的数据损坏的风险，但代价是在 WAL 日志记录期间的压缩和 WAL 重放期间的解压缩上花费一些额外的 CPU。wal_consistency_checking在 src/test/recovery 下运行某些测试时使用 wal_consistency_checking=all。默认情况下不启用，因为它是资源密集型的。参考wal_decode_buffer_size对服务器可以在 WAL 中查找多远以查找要预取的块的限制。如果指定该值时没有单位，则将其视为字节。默认值为 512kB。恢复期间在WAL中提前读取的缓冲区大小在WAL中提前读取以预取引用数据块的最大距离wal_init_zero如果设置为打开（默认），此选项会导致新的 WAL 文件用零填充。在某些文件系统上，这可以确保在我们需要写入 WAL 记录之前分配空间。但是，写时复制 (COW) 文件系统可能无法从该技术中受益，因此可以选择跳过不必要的工作。如果设置为关闭，则在创建文件时仅写入最后一个字节，以使其具有预期的大小。wal_log_hints当该参数开启时，PostgreSQL 服务器在检查点后的第一次修改某个磁盘页时，会将该页的全部内容写入 WAL，甚至包括对所谓提示位（hint bits）的非关键修改。如果启用了数据校验和，提示位更新将始终记录在 WAL 中，并且该设置将被忽略。你可以使用此设置测试如果数据库启用了数据校验和，会产生多少额外的 WAL 日志。此参数只能在服务器启动时设置，默认值为 off。wal_recycle如果设置为 on（默认值），此选项会导致 WAL 文件通过重命名来回收，从而避免创建新文件。在 COW 文件系统上，创建新文件系统可能会更快，因此提供了禁用此行为的选项。wal_segment_sizewal segment 大小，默认 16MBwal_skip_threshold当 wal_level 设置为 minimal 且事务在创建或重写永久关系后提交时，此设置决定如何持久化新数据。如果数据小于此设置的值，则将其写入 WAL 日志；否则，使用受影响文件的 fsync。根据存储的特性，增大或减小此值可能有助于解决此类提交导致并发事务变慢的问题。如果此值未指定单位，则默认以千字节计算。默认值为两兆字节（2MB）。wal_sync_method用于强制将 WAL 更新写入磁盘的方法。如果 fsync 关闭，则此设置无关紧要，因为 WAL 文件的更新将不会被强制写出。可选值包括：  open_datasync（使用 open() 选项 O_DSYNC 写入 WAL 文件）  fdatasync（在每次提交时调用 fdatasync()）  fsync（在每次提交时调用 fsync()）  fsync_writethrough（在每次提交时调用 fsync()，强制写入磁盘写缓存）  open_sync（使用 open() 选项 O_SYNC 写入 WAL 文件）open_* 选项在可用时也使用 O_DIRECT。并非所有平台都支持这些选项。默认值为平台支持的上述方法中的第一个，但在 Linux 和 FreeBSD 上，默认值为 fdatasync。默认设置不一定是理想的；可能需要更改此设置或系统配置的其他方面，以创建崩溃安全的配置或实现最佳性能。关于这些方面的讨论参考。此参数只能在 postgresql.conf 文件中或通过服务器命令行设置。wal_writer_delay指定WAL写入器多久刷新一次WAL，以时间单位计。在刷新WAL后，写入器会根据wal_writer_delay指定的时间长度休眠，除非被异步提交的事务提前唤醒。如果最后一次刷新发生在wal_writer_delay之前，并且自那以后产生的WAL量少于wal_writer_flush_after所值得的量，则WAL只被写入到操作系统，而不是刷新到磁盘。如果这个值没有指定单位，它被当作毫秒。默认值是200毫秒（200ms）。请注意，在许多系统上，休眠延迟的有效分辨率是10毫秒；将wal_writer_delay设置为不是10的倍数的值可能会产生与设置为下一个更高的10的倍数相同的结果。这个参数只能在postgresql.conf文件或服务器命令行上设置。wal_writer_flush_after指定 WAL 写入器按数据量刷新的频率。如果上次刷新发生在 wal_writer_delay 规定的时间内，且自那时以来产生的 WAL 量少于 wal_writer_flush_after 的设定值，则 WAL 仅写入操作系统，而不会刷新到磁盘。如果 wal_writer_flush_after 设置为 0，则 WAL 数据始终会立即刷新。如果此值未指定单位，则默认以 WAL 块为单位，即 XLOG_BLCKSZ 字节，通常为 8kB。默认值为 1MB。此参数只能在 postgresql.conf 文件中或通过服务器命令行设置。参考WAL ConfigurationReplication也可以查看源码文件 src/backend/access/transam/xlog.c 中的定义和描述"
  },
  
  {
    "title": "Windows 利用 Netsh 管理 WiFi 连接",
    "url": "/posts/Windows-%E5%88%A9%E7%94%A8-Netsh-%E7%AE%A1%E7%90%86-WiFi-%E8%BF%9E%E6%8E%A5/",
    "categories": "Windows, Network",
    "tags": "WiFi",
    "date": "2024-09-05 10:33:43 +0800",
    





    
    "snippet": "前言基本现在的轻薄笔记本都已经没有网线接口了，除了拓展坞之外只能使用 WiFi 连接网络。当我们重装系统或者更换电脑的时候需要重新配置网络，手动配置的方式效率较低，可以利用 Windows 下的 netsh 工具备份已有的 WiFi 连接信息，然后在其他机器导入或者重装系统之后恢复 WiFi 信息。在 Windows 中可以通过 控制面板的网络管理，或者网卡属性查看 WiFi 信息。不过比较...",
    "content": "前言基本现在的轻薄笔记本都已经没有网线接口了，除了拓展坞之外只能使用 WiFi 连接网络。当我们重装系统或者更换电脑的时候需要重新配置网络，手动配置的方式效率较低，可以利用 Windows 下的 netsh 工具备份已有的 WiFi 连接信息，然后在其他机器导入或者重装系统之后恢复 WiFi 信息。在 Windows 中可以通过 控制面板的网络管理，或者网卡属性查看 WiFi 信息。不过比较麻烦，可以通过命令行的方式管理网络，主要命令是 netsh微软从 Windows 2000 开始便内置了一个 Netsh（Network Shell）命令行工具，以帮助用户执行本地或远程计算机上不同网卡的信息查看、配置及排错工作。因为涉及网络的管理配置，所以在使用 Netsh 的时候请使用管理员用户打开 cmd、powershell、或者 Windows terminal 等终端工具。亦或者安装 sudo、gsudo 等临时提升权限的工具查看已保存的 WiFi 配置对于我们已经连接过的 WiFi 连接都会生成一个配置文件，可以使用以下方式查看现有的 WiFi 配置文件Netsh WLAN show profiles以上命令会显示出所有无线网卡连接过的 WIFI 配置文件，如果你有多块无线网卡，还可以使用 interface 参数跟上网卡名称进行单独列出：Netsh WLAN show profiles interface=\"无线网卡名称\"查看无线网卡驱动信息要查看当前 Windows  的无线网卡驱动信息可以使用如下命令：Netsh WLAN show drivers查看无线网卡兼容性可以使用以下命令来查看当前无线网卡所支持及兼容的（系统及硬件）功能：Netsh WLAN show wirelesscapabilities查看无线网卡的接口信息如果需要查看无线网卡的：无线电类型、信道、传输速率、连接模式等信息时，可以使用以下命令：Netsh WLAN show interfaces默认查看所有的接口信息，也可以指定网卡名称Netsh WLAN show interface name=\"网卡名称\"查看 WIFI 密码## 需要使用关键字 key=clear ，否则会隐藏密码字段Netsh WLAN show profile name=\"无线名称\" key=clear关闭自动连接到某个 WIFI 无线网络通常连接 WiFi 的时候，都会默认勾选自动连接选项，但在有多个无线网络的情况下，系统自动选择连接的 WIFI 可能信号较差，或者并不是我们希望连接的网络，此时我们可以使用如下命令取消自动连接某个 WIFI 无线网络：Netsh WLAN set profileparameter name=\"无线名称\" connectionmode=manual开启自动连接到某个 WiFi 网络恢复自动连接，只需将最后的参数改为 auto 即可Netsh WLAN set profileparameter name=\"无线名称\" connectionmode=auto删除 WIFI 配置文件当你不需要再连接某个无线网络、更改了 SSID 或需要重置配置文件时，可以使用如下命令来删除指定的 WIFI 配置文件：Netsh WLAN delete profile name=\"无线名称\"注意：如果你使用 Microsoft Account 登录到 Windows 10 / 11 ，WIFI 的配置文件默认会在不同设备间进行同步，但删除 WIFI 配置文件的操作不会同步到其它设备上。备份/导出 WIFI 无线网络配置文件导出 WIFI 无线网络配置的 xml 文件：Netsh WLAN export profile key=clearNetsh WLAN export profile key=clear folder=\"存放路径\"如果不指定 folder 选项，默认会在当前路径生成对应的 xml 文件默认情况下会为每个 WIFI 连接都导出一个单独的配置文件，如果你只想导出单个配置文件，可以使用如下命令Netsh WLAN export profile name=\"无线名称\" key=clear folder=\"存放路径\"注意：导出的 XML 配置文件是明文存储，而且会导出 WIFI 连接密码，所以请一定妥善保存。如果不指定 key=clear 选项并不会导出密码信息，需要在连接的手动更新密码信息恢复/导入 WiFi 配置文件Netsh WLAN add profile filename=\"存放路径\"## 如果需要为所有用户恢复需要使用 user=all 选项Netsh WLAN add profile filename=\"存放路径\" user=all生成无线网卡报告可以使用如下命令来创建和生成详细的无线网卡报告：Netsh WLAN show WLANreport总结在 Windows 下可以使用 Netsh 工具管理配置 网络，更多的使用方法可以使用 netsh /? 查看，或者查看这里如果需要查看或者备份/导出 WiFi 密码，需要使用选项 key=clear管理有线网络的话，使用 Netsh LAN 操作如果需要按照用户管理，请使用选项 user=all 或者 user=$username"
  },
  
  {
    "title": "查看 g++编译器默认编译标准",
    "url": "/posts/%E6%9F%A5%E7%9C%8B-g++%E7%BC%96%E8%AF%91%E5%99%A8%E9%BB%98%E8%AE%A4%E7%BC%96%E8%AF%91%E6%A0%87%E5%87%86/",
    "categories": "gcc",
    "tags": "gcc",
    "date": "2024-09-04 14:24:27 +0800",
    





    
    "snippet": "简单记录下怎么查看当前 g++ 编译器默认支持的 cpp 标准，毕竟 cpp 20 都已经出来几年了，有些特性编译器还没有完全支持g++ -dM -E -x c++ /dev/null | grep __cplusplus如果要查看 g++ 是否支持 cpp 20 可以执行以下命令g++ -std=c++20 -E -x c++ - &lt;&lt;&lt; \"\"如果你的 g++ 版本支持 ...",
    "content": "简单记录下怎么查看当前 g++ 编译器默认支持的 cpp 标准，毕竟 cpp 20 都已经出来几年了，有些特性编译器还没有完全支持g++ -dM -E -x c++ /dev/null | grep __cplusplus如果要查看 g++ 是否支持 cpp 20 可以执行以下命令g++ -std=c++20 -E -x c++ - &lt;&lt;&lt; \"\"如果你的 g++ 版本支持 C++20，那么该命令将不会报错，而会输出一些编译的信息。如果你的 g++ 版本不支持 C++20，那么该命令将会提示错误信息，告诉你该标志不被支持。更多的信息可以参考以下网址：https://en.cppreference.com/w/cpp/compiler_support/20https://cplusplus.com/doc/tutorial/"
  },
  
  {
    "title": "PostgreSQL 单块读",
    "url": "/posts/PostgreSQL-%E5%8D%95%E5%9D%97%E8%AF%BB/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-09-03 11:37:34 +0800",
    





    
    "snippet": "前言什么是单块读？顾名思义，就是每次读取单个 block 。Oracle 是支持多块读，今天测试一下 PostgreSQL 是否支持多块读，虽然之前听说是不支持的，今天直接测试验证一下。测试使用的工具为：strace 、pg 15block_sizePostgreSQL 可以通过 block_size 设置 block 的大小。不过这个参数是只读的，在数据库安装之后就无法修改了。默认是 8K...",
    "content": "前言什么是单块读？顾名思义，就是每次读取单个 block 。Oracle 是支持多块读，今天测试一下 PostgreSQL 是否支持多块读，虽然之前听说是不支持的，今天直接测试验证一下。测试使用的工具为：strace 、pg 15block_sizePostgreSQL 可以通过 block_size 设置 block 的大小。不过这个参数是只读的，在数据库安装之后就无法修改了。默认是 8K，可以在编译的时候通过选项 --with-blocksize 指定大小，另一个关于 wal 的选项 wal_block_size 最好取值相同。127.0.0.1:54323; wxj@postgres &gt; select * from pg_settings where name like '%block_size%';+-[ RECORD 1 ]----+----------------------------------------------+| name            | block_size                                   || setting         | 8192                                         || unit            | NULL                                         || category        | Preset Options                               || short_desc      | Shows the size of a disk block.              || extra_desc      | NULL                                         || context         | internal                                     || vartype         | integer                                      || source          | default                                      || min_val         | 8192                                         || max_val         | 8192                                         || enumvals        | NULL                                         || boot_val        | 8192                                         || reset_val       | 8192                                         || sourcefile      | NULL                                         || sourceline      | NULL                                         || pending_restart | f                                            |+-[ RECORD 2 ]----+----------------------------------------------+| name            | wal_block_size                               || setting         | 8192                                         || unit            | NULL                                         || category        | Preset Options                               || short_desc      | Shows the block size in the write ahead log. || extra_desc      | NULL                                         || context         | internal                                     || vartype         | integer                                      || source          | default                                      || min_val         | 8192                                         || max_val         | 8192                                         || enumvals        | NULL                                         || boot_val        | 8192                                         || reset_val       | 8192                                         || sourcefile      | NULL                                         || sourceline      | NULL                                         || pending_restart | f                                            |+-----------------+----------------------------------------------+安装之后，block_size 无法修改127.0.0.1:54323; wxj@postgres &gt; set block_size=16384;ERROR:  parameter \"block_size\" cannot be changedTime: 0.355 ms127.0.0.1:54323; wxj@postgres &gt;block_size 8k首先测试 block_size 为 8K 的时候情况数据是之前 pgbench 压测的时候产生的，通过读取 pgbench 产生的数据验证 PostgreSQL 的读取动作pgbench -i -s 100 -U postgres testdb获取进程号127.0.0.1:54323; wxj@testdb &gt; show block_size;+------------+| block_size |+------------+| 8192       |+------------+(1 row)127.0.0.1:54323; wxj@testdb &gt; select pg_backend_pid();+----------------+| pg_backend_pid |+----------------+|         849955 |+----------------+新开一个窗口对进程 strace根据得到的进程号 strace/Postgres/tools/strace_pg.sh 849955执行查询语句select count(1)  from pgbench_branches;+-------+| count |+-------+|   100 |+-------+(1 row)检查 strace 日志## 因为日志内容不多就直接贴图呢vim /Postgres/stracelog/849955_read.log可以看到每次 pread64 函数偏移量都是 8192，刚好为 block_size 大小。block_size 16K接下来测试一下当 block_size=16K 的情况。获取进程号127.0.0.1:54324; postgres@testdb &gt; select pg_backend_pid();+----------------+| pg_backend_pid |+----------------+|        1391395 |+----------------+(1 row)127.0.0.1:54324; postgres@testdb &gt; show block_size;+------------+| block_size |+------------+| 16384      |+------------+(1 row)新开窗口进行 strace┌─[postgres@darkstarc]─[~]└──╼ $ /Postgres/tools/strace_pg.sh  1391395postgres 1416671 1416670  0 10:42 pts/3    00:00:00 strace -tt -Y -f -r -o /Postgres/stracelog/1391395_read.log -p 1391395执行全表查询127.0.0.1:54324; postgres@testdb &gt; select count(1) from pgbench_accounts;+----------+|  count   |+----------+| 10000000 |+----------+(1 row)检查 strace 日志可以看见 pread64 函数每次的偏移量为 16384（block_size）在表的数量稍微大点的时候可以看见还涉及到了锁，进程调用了 futex 函数└──╼ $ grep futex /Postgres/stracelog/1391395_read.log1391395&lt;postgres&gt; 10:43:32.700008 (+     0.000115) futex(0x7fc443a3f138, FUTEX_WAIT_BITSET|FUTEX_CLOCK_REALTIME, 0, NULL, FUTEX_BITSET_MATCH_ANY) = -1 EAGAIN (Resource temporarily unavailable)1391395&lt;postgres&gt; 10:43:33.023435 (+     0.001178) futex(0x7fc443a3f738, FUTEX_WAKE, 1) = 11391395&lt;postgres&gt; 10:43:33.046237 (+     0.000124) futex(0x7fc443a3f138, FUTEX_WAIT_BITSET|FUTEX_CLOCK_REALTIME, 0, NULL, FUTEX_BITSET_MATCH_ANY) = -1 EAGAIN (Resource temporarily unavailable)1391395&lt;postgres&gt; 10:43:34.440591 (+     0.000147) futex(0x7fc443a3f738, FUTEX_WAKE, 1) = 1说明查询也会涉及锁，调用了 Linux 的 futex 函数，只是对应 postgresql 中锁的等级不同block_size 大小对查询的影响-- block_size = 8K127.0.0.1:54323; wxj@testdb &gt; select count(1) from pgbench_accounts;+----------+|  count   |+----------+| 10000000 |+----------+(1 row)Time: 13835.084 ms (00:13.835)-- block_size = 16K127.0.0.1:54324; postgres@testdb &gt; select count(1) from pgbench_accounts;+----------+|  count   |+----------+| 10000000 |+----------+(1 row)Time: 2130.195 ms (00:02.130)可以看见全表扫描大表的时候 block_size 取值 16K 的效率要比 8K 的时候高，因为扫描的 block 的数量少了如果需要长期全表查询或者大数据量时，可以考虑调大 block_size ，单个 blok 可以容纳更多的数据，这样在读取的时候也可以减少需要扫描的 block 的数量提高效率也不是一味的增大 block_size ，根据业务的数据类型调整Oracle 多块读为了有一个对比，这里贴一下 Oracle 的多块读情况SPID                            SID------------------------ ----------756                             191SQL&gt; select count(1) from t3;  COUNT(1)----------   2821792SQL&gt; show parameter db_block_sizeNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------db_block_size                        integer     8192可以看到在单个 block 大小为 8K 的时候，pread 函数的偏移量存在 16K、32K 的情况，说明 Oracle 在扫描数据库块的时候单次扫描 block 的数量可以超过一个总结PostgreSQL 目前还不支持多块读。可以使用 uniq 简单去重看看进程在执行时涉及那些函数/操作。┌─[postgres@darkstarc]─[~]└──╼ $ awk '{print $5}' /Postgres/stracelog/1391395_read.log | awk -F'(' '{print $1}' |  uniqepoll_waitrecvfromlseekopenatrt_sigprocmaskftruncatefallocatert_sigprocmaskmmapcloselseekkill---rt_sigreturnkill---rt_sigreturnkillpread64futexpread64pselect6futexpread64futexpread64futexpread64pselect6pread64epoll_waitreadepoll_wait---rt_sigreturnreadepoll_wait---rt_sigreturn---rt_sigreturnreadmunmapunlinksendtorecvfromepoll_wait参考fetux1fetux2block_size教你区分 多块读、单块读、散列读、顺序读、索引扫描OS / linux / 互斥锁实现原理（futex）"
  },
  
  {
    "title": "Linux 虚拟内存参数 min_free_kbytes",
    "url": "/posts/Linux-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%8F%82%E6%95%B0-min_free_kbytes/",
    "categories": "Linux, Memory",
    "tags": "virtual memory",
    "date": "2024-08-30 11:51:27 +0800",
    





    
    "snippet": "前言Linux 的虚拟内存参数列在 /proc/sys/vm 目录中，可以直接查看对应的文件。前几天调整了 Oracle SGA 大小，结果运行没多久就挂掉了，检查日志发生了 OOM，虽然使用率比较高，可是检查内存还有 2G 的空闲，最开始以为是设置了 操作系统用户的内存使用限制，可是也不应该是 OOM，不过还是设置为了 unlimit 。重启之后运行两个小时之后又宕机了。还是提示 OOM，...",
    "content": "前言Linux 的虚拟内存参数列在 /proc/sys/vm 目录中，可以直接查看对应的文件。前几天调整了 Oracle SGA 大小，结果运行没多久就挂掉了，检查日志发生了 OOM，虽然使用率比较高，可是检查内存还有 2G 的空闲，最开始以为是设置了 操作系统用户的内存使用限制，可是也不应该是 OOM，不过还是设置为了 unlimit 。重启之后运行两个小时之后又宕机了。还是提示 OOM，检查系统的内存参数配置，发现设置了 vm.min_free_kbytes 换算之有 5G 大小。客户环境也不是自己搭建的，不清楚为什么设置这么大，减少大小或则直接取消改参数的配置，采用系统默认大小之后恢复正常。可以设置一定大小，避免在业务运行时系统因为内存问题宕机，不过也不建议设置太大。┌─[wxj@TheDarkStar]─[~]└──╼ $ cat /proc/sys/vm/min_free_kbytes45056┌─[wxj@TheDarkStar]─[~]└──╼ $ ll /proc/sys/vmtotal 0-rw-r--r-- 1 root root 0 Aug 30 11:53 admin_reserve_kbytes--w------- 1 root root 0 Aug 30 11:53 compact_memory-rw-r--r-- 1 root root 0 Aug 30 11:53 compact_unevictable_allowed-rw-r--r-- 1 root root 0 Aug 30 11:53 compaction_proactiveness-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_background_bytes-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_background_ratio-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_bytes-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_expire_centisecs-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_ratio-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_writeback_centisecs-rw-r--r-- 1 root root 0 Aug 30 11:53 dirtytime_expire_seconds--w------- 1 root root 0 Aug 30 11:53 drop_caches-rw-r--r-- 1 root root 0 Aug 30 11:53 extfrag_threshold-rw-r--r-- 1 root root 0 Aug 30 11:53 hugetlb_optimize_vmemmap-rw-r--r-- 1 root root 0 Aug 30 11:53 hugetlb_shm_group-rw-r--r-- 1 root root 0 Aug 30 11:53 laptop_mode-rw-r--r-- 1 root root 0 Aug 30 11:53 legacy_va_layout-rw-r--r-- 1 root root 0 Aug 30 11:53 lowmem_reserve_ratio设置 min_free_kbytes这用于强制 Linux VM 保持最少的可用的 kilobytes 。 VM 使用此数字来计算系统中每个 lowmem 区域的  watermark[WMARK_MIN] 的值。每个 lowmem zone 根据其大小按比例获得一定数量的保留空闲页面。需要一些最小量的内存来满足 PF_MEMALLOC 分配；如果设置为低于 1024KB ，在高负载下容易出现死锁。设置得太高会导致机器 OOM。设置保留可用页面池的大小。它还负责设置管理 Linux 内核页面回收算法行为的 min_page、low_page 和 high_page 阈值。它还指定在系统间保留的最小 KB 数。这会为每个低内存区计算一个特定值，每个值都会被分配一个保留的空闲页面的大小。  增加参数值可有效减少应用程序工作集可用内存。因此，可能希望将其仅用于内核驱动的工作负载，其中驱动程序缓冲区需要在原子上下文中分配。  减少参数值可能会导致内核无法服务系统请求，如果内存在系统中发生大量处理。vm.min_free_kbytes 参数还设置页面重新声明水位线，名为 min_pages。在确定两个其他内存水位线、low_pages 和 high_pages 时，这个水位线被用作一个因素，它管理页面重新声明算法。总结极端的值可能会降低系统性能。将 vm.min_free_kbytes 设置为非常低的值可防止系统有效地回收内存，这可能会导致系统崩溃并失败服务中断或其他内核服务。但是，设置 vm.min_free_kbytes 太大地增加系统回收活动，从而导致分配延迟因为假的直接重新声明状态而造成分配延迟。这可能导致系统立即进入内存不足状态。后续发现这篇文章写的挺详细的还有实验"
  },
  
  {
    "title": "PostrgeSQL 常用函数（持续更新）",
    "url": "/posts/PostrgeSQL-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/",
    "categories": "DataBase, PostrgeSQL",
    "tags": "PostrgeSQL",
    "date": "2024-08-28 15:29:36 +0800",
    





    
    "snippet": "前言记录一些 PostgreSQL 的常用函数字符串字符串/字段拼接string_aggstring_agg：用于拼接字段，需要两个参数，第一个是需要进行拼接的字段名，第二个是用于拼接字符的拼接符号select string_agg(a,', ') from tab1;如果字段不是字符类型，例如字段是数字类型，需要先转换为字符才能进行拼接，否则会报错|| ：和 Oracle 一样，可以用于拼...",
    "content": "前言记录一些 PostgreSQL 的常用函数字符串字符串/字段拼接string_aggstring_agg：用于拼接字段，需要两个参数，第一个是需要进行拼接的字段名，第二个是用于拼接字符的拼接符号select string_agg(a,', ') from tab1;如果字段不是字符类型，例如字段是数字类型，需要先转换为字符才能进行拼接，否则会报错|| ：和 Oracle 一样，可以用于拼接字符或者字段，如果是不是拼接的字段，字符串需要在两个单引号内select a || ',' || b from tab1 ;select 'a' || ',' || 'b' ;类型转换https://www.postgresql.org/docs/current/sql-createcast.html可以使用 cast 函数或者双冒号 ::，在PG 的SQL中，会经常看到 “::” 的语法， “::” 符号其实是一个显示的类型转换符，作用等同于 CAST。select a::text from tab1;select 1::text;select cast(a as text) from tab1;select cast(1 as text);文件信息根据OID或名称返回关系对应的文件路径select pg_relation_filepath('tab1');"
  },
  
  {
    "title": "podman 修改仓库源",
    "url": "/posts/podman-%E4%BF%AE%E6%94%B9%E4%BB%93%E5%BA%93%E6%BA%90/",
    "categories": "containers, podman",
    "tags": "podman",
    "date": "2024-08-28 11:21:43 +0800",
    





    
    "snippet": "前言Podman 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用（Windows 下也可以运行，不过个人还没测试）。Podman 提供与 Docker 非常相似的功能。它不需要在你的系统上运行任何守护进程，并且它也可以在没有 root 权限的情况下运行。Podman 可以管理和运行任何符合 OCI（Open Container Initiative）规范的容器和容器镜像。Po...",
    "content": "前言Podman 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用（Windows 下也可以运行，不过个人还没测试）。Podman 提供与 Docker 非常相似的功能。它不需要在你的系统上运行任何守护进程，并且它也可以在没有 root 权限的情况下运行。Podman 可以管理和运行任何符合 OCI（Open Container Initiative）规范的容器和容器镜像。Podman 提供了一个与 Docker 兼容的命令行前端来管理 Docker 镜像。虽然目前容器化部署基本都采用 docker ，但是随着 RedHat 系列的 Linux 升级到 8 之后基本就采用 podman 作为自身的容器化产品之后，已经不能通过软件仓库安装 docker 了，虽然可以通过一些方法安装 docker ，但是个人还是比较喜欢使用 RedHat 系列，所以也就尝试使用 podman            Podman      Docker                  是无守护进程的      Docker 有一个守护进程 (containerd)。docker CLI 与守护进程交互以管理容器。              直接通过 runc 与 Linux 内核交互      守护进程拥有所有运行容器的子进程              可以部署具有多个容器的 pod。可以在 Kubernetes 中使用相同的 pod 清单。此外，可以将 K8s pod 清单部署为 Podman pod。      Docker 中没有 pod 的概念              无需任何额外配置即可运行无根容器( rootless)。可以使用 root 或非特权用户运行容器。      Docker 无根模式( rootless)需要额外的配置。      修改镜像源Podman 可以直接通过软件源安装，使用命令大部分也和 docker 一样，这里就不再赘述。Podman 有两种配置文件：  全局配置文件：/etc/containers/registries.conf  用户配置文件：~/.config/containers/registries.conf可以直接修改全局配置文件，也可以在不同的用户下配置不同的参数，可能当前用户没有 containers 路径，可以新建配置文件之后修改以修改全局配置文件为例：sudo cp /etc/containers/registries.conf /etc/containers/registries.conf.baksudo vim /etc/containers/registries.confunqualified-search-registries = [\"docker.io\"][[registry]]prefix = \"docker.io\"location = \"hub-mirror.c.163.com\"insecure = true[[registry.mirror]]# 百度镜像源location = \"mirror.baidubce.com\"insecure = true[[registry.mirror]]# 网易 163 镜像源location = \"hub-mirror.c.163.com\"insecure = true[[registry.mirror]]# 上海交大镜像源location = \"docker.mirrors.sjtug.sjtu.edu.cn\"insecure = true[[registry.mirror]]# 南京大学镜像源location = \"docker.nju.edu.cn\"insecure = true以上镜像源地址随着国内禁止访问 dockerhub 之后可能无法访问，需要自行搭建镜像源或者搜索其他人搭建的镜像源地址😂  prefix 是 pull 的时候指定的镜像前缀，如果不指定 prefix 则默认和 location 一致。  location 是获取镜像的地址；  insecure=true 表示允许通过 HTTP 协议来获取镜像，对于私有化部署/内网测试环境下无 https 证书的环境来说很有帮助。查看是否生效podman infoPodman 常用命令podman run         #创建并启动容器podman start       #启动容器podman ps          #查看容器podman stop        #终止容器podman restart     #重启容器podman attach      #进入容器podman exec        #进入容器podman export      #导出容器podman import      #导入容器快照podman rm          #删除容器podman logs        #查看日志podman search      #检索镜像podman pull         #获取镜像podman images      #列出镜像podman image Is    #列出镜像podman rmi         #删除镜像podman image rm    #删除镜像podman save        #导出镜像podman load        #导入镜像还能使用的镜像源unqualified-search-registries = [\"docker.io\"][[registry]]prefix = \"docker.io\"location = \"hub-mirror.c.163.com\"insecure = true[[registry.mirror]]location = \"hub.uuuadc.top\"insecure = true[[registry.mirror]]location = \"docker.anyhub.us.kg\"insecure = true[[registry.mirror]]location = \"dockerhub.jobcher.com\"insecure = true[[registry.mirror]]location = \"dockerhub.icu\"insecure = true[[registry.mirror]]location = \"docker.ckyl.me\"insecure = true[[registry.mirror]]location = \"docker.awsl9527.cn\"insecure = true总结虽然 podman 目前看起来是 RedHat 未来主推的容器产品，但是使用 docker 的用户更多，很多业务并不一定会迁移到 podman 。而且大部分容器都是根据 docker 构建的，即使 podman 描述说可以直接使用 docker 的绝大部分命令，不过有的在 docker 上正常运行的容器在 podman 上并不能正常使用，有可能在 pull 阶段就报错了。有些则是在启动阶段出现一些奇怪的错误，这些都是在使用 podman 时会遇到的问题。如果使用 Redhat 系列的 Linux ，可以尝试使用 podman"
  },
  
  {
    "title": "PostgreSQL 配置密码验证策略",
    "url": "/posts/PostgreSQL-%E9%85%8D%E7%BD%AE%E5%AF%86%E7%A0%81%E9%AA%8C%E8%AF%81%E7%AD%96%E7%95%A5/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-08-27 13:55:20 +0800",
    





    
    "snippet": "概述数据库等保的时候会遇到一些安全加固操作，其中 PostgreSQL 数据库设置密码验证失败延迟时间可以通过安装 auth_delay 扩展插件来实现，该设置主要是防止暴力破解，在验证失败后, 会延迟一段时间后，才能继续验证。可以搭配 passwordcheck 限制简单密码。一般来说 ‘passwordcheck、auth_delay’ 两个插件就在源码路径中的 contrid 目录下。...",
    "content": "概述数据库等保的时候会遇到一些安全加固操作，其中 PostgreSQL 数据库设置密码验证失败延迟时间可以通过安装 auth_delay 扩展插件来实现，该设置主要是防止暴力破解，在验证失败后, 会延迟一段时间后，才能继续验证。可以搭配 passwordcheck 限制简单密码。一般来说 ‘passwordcheck、auth_delay’ 两个插件就在源码路径中的 contrid 目录下。源码编译安装 PostgreSQL 可以参考我之前写的脚本一键安装。编译安装插件下载相同版本的源码解压之后进入目录，在安装插件之前请先编译源码，然后进入插件的路径进行安装插件，如果在编译时新建的编译目录，例如 build ，需要进入 ‘build/contrib’ 路径下：cd /software/postgresql-15.4/contrib/# 安装命令make &amp;&amp; make install在 contrib 目录下执行会编译安装路径下的所有插件，如果只想要单独安装需要的插件，可以进入对应的目录：cd /software/postgresql-15.4/contrib/auth_delay/make &amp;&amp; make installcd /software/postgresql-15.4/contrib/passwordcheck/make &amp;&amp; make install配置参数文件如果在编译的时候指定的安装路径正确或者安装数据库软件时采用的时默认路径那么在编译安装插件的时候会自动安装至正确的路径，如果路径有问题，请复制编译好的 ‘auth_delay.so、passwordcheck.so’ 文件到，pg_config | grep -E 'LIBDIR|PKGLIBDIR' 任意一个路径，然后配置 ${PGDATA?}/postgresql.conf 文件，如果没有配置变量 ‘${PGDATA}’ ，可以使用 ps -ef | grep -i postgre 查看数据库的配置文件路径，也可以使用 psql -c 'show config_file;' 获取配置文件路径。打开 ${PGDATA?}/postgresql.conf 文件，修改 shared_preload_libraries 参数以包含 auth_delay ，同时增加 auth_delay.milliseconds 参数，设置延迟时间，单位为毫秒，取值 5000 代表 5 秒，若文件中没有该参数，添加即可。修改后，需要重启数据库才能生效，所以配置之前要和业务部门确认，避免后期扯皮。需要注意： auth_delay 认证失败之前等待的毫秒数，缺省是0。以下示例修改表示在一次认证失败后，将延迟5秒中才能继续下一次认证。该选项可以增加暴力破解数据库服务器的密码难度，但它并不能防止拒绝服务攻击，甚至可能恶化它们，因为报告验证失败之前等待的过程将损耗连接槽位。# Add settings for extensions hereshared_preload_libraries = 'passwordcheck,auth_delay'auth_delay.milliseconds = '5000'重启实例：pg_ctl restart如果启动没报错，则表示正确加载模块两个扩展都是 contrib 自带的扩展，不需要手动执行 CREATE EXTENSION ，否则会提示以下信息：postgres=# CREATE EXTENSION auth_delay;ERROR:  could not open extension control file \"/Postgres/pg/share/postgresql/extension/auth_delay.control\": No such file or directory验证postgres=# show auth_delay.milliseconds; auth_delay.milliseconds------------------------- 5s(1 row)新建用户验证 passwordcheck ：可以修改 auth_delay.milliseconds 的值，结合 time 命令验证密码错误时的等待时间：总结除了需要在 postgresql.conf 配置文件中装载 auth_delay 模块，还需要增加 auth_delay.milliseconds 配置参数，否则 auth_delay 扩展模块的功能无法体现。passwordcheck 模块对新创建的用户密码进行检测，已存在的用户不生效。两个插件模块都是 contrib 自带的模块，不需要执行 CREATE EXTENSION"
  },
  
  {
    "title": "vim 匹配指定行号的内容",
    "url": "/posts/vim-%E5%8C%B9%E9%85%8D%E6%8C%87%E5%AE%9A%E8%A1%8C%E5%8F%B7%E7%9A%84%E5%86%85%E5%AE%B9/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-27 10:39:27 +0800",
    





    
    "snippet": "有的时候明确知道需要保留那些行，虽然可以采用匹配每行的字符，但是可能需要保留的行的内容在其他行中也存在，这个时候可以利用 vim/nvim 的 \\% 特殊字符匹配指定的行内容。再结合 :g 、:g!、 :v 来选择/反选指定的行/列内容可以高效的过滤行            符号      含义      备注                  \\%      用于匹配行号或列号      ...",
    "content": "有的时候明确知道需要保留那些行，虽然可以采用匹配每行的字符，但是可能需要保留的行的内容在其他行中也存在，这个时候可以利用 vim/nvim 的 \\% 特殊字符匹配指定的行内容。再结合 :g 、:g!、 :v 来选择/反选指定的行/列内容可以高效的过滤行            符号      含义      备注                  \\%      用于匹配行号或列号                     \\%^      匹配文件开始的位置                     \\%Nl      匹配指定的[n]行，l 表示行号，line                     \\%'m      匹配指定的 m 标记                     \\%&gt;'m      匹配在 m 标记之后的内容      可以使用&lt;、&gt;、'              \\%.l      匹配光标所在的行                     \\%&gt;.23l      匹配光标所在行下方的内容                     \\%Nc      匹配指定的列 ‘column’      &lt;23c、&gt;23c、.c、&lt;.c、&gt;.c              \\%23v      匹配指定的虚拟列             匹配指定的行号### 匹配删除第二行:g/\\%2l/d匹配删除除第二行之外的所有行:g!/\\%2l/d:v/\\%2l/d匹配多行:g/\\%2l\\|\\%4l/d可以匹配删除第二行和第四行的内容匹配连续的多行:g/\\%2l,\\%4l/d以上写法并不能直接匹配第二行到第四行的内容，需要曲线实现:g/\\%&lt;2l\\|\\%&gt;4l/d匹配大于或者小于指定行的内容，例如以上通过匹配小于第二行或者大于第四行的内容，相当于匹配第二行到第四行的内容，以此实现匹配连续的行🤣🤣🤣"
  },
  
  {
    "title": "sed 检查 Oracle日志 并输出对应的行号",
    "url": "/posts/sed-%E6%A3%80%E6%9F%A5-Oracle%E6%97%A5%E5%BF%97-%E5%B9%B6%E8%BE%93%E5%87%BA%E5%AF%B9%E5%BA%94%E7%9A%84%E8%A1%8C%E5%8F%B7/",
    "categories": "Linux, sed",
    "tags": "Oracle",
    "date": "2024-08-26 16:45:20 +0800",
    





    
    "snippet": "在护网的时候可能需要定期检查日志文件，特别是日志文件中的错误信息，在 alert 日志中常见的报错一般都是 Error、ORA-、TNS- 为前缀的信息。我们可以利用 sed 工具检索日志文件中的信息，减少重复工作。可以利用一下语句过滤错误信息：## 一般来说 alert 日志的路径为## ${ORACLE_BASE}/diag/rdbms/${ORACLE_SID}/${ORACLE_SI...",
    "content": "在护网的时候可能需要定期检查日志文件，特别是日志文件中的错误信息，在 alert 日志中常见的报错一般都是 Error、ORA-、TNS- 为前缀的信息。我们可以利用 sed 工具检索日志文件中的信息，减少重复工作。可以利用一下语句过滤错误信息：## 一般来说 alert 日志的路径为## ${ORACLE_BASE}/diag/rdbms/${ORACLE_SID}/${ORACLE_SID}/tracle/alert_${ORACLE_SID}.log## 因为安装的原因，rdbms 下之后路径可能为大小或者小写的 ${ORACLE_SID} ，具体可以进入 rdbms 路径之后选择## diag 的路径也可以进入实例之后使用 `show parameter diag` 查看sed -n  '/Mon Aug 26 08/,/Mon Aug 26 09/p' alert_xxxx.log  | grep -E '^Error|^ORA-|^TNS-'Mon Aug 26 08 是路径的日志格式，不同的实例环境格式不同，需要根据实际情况替换Error 1034 received logging on to the standbyError 1034 received logging on to the standbyError 1034 received logging on to the standbyError 1034 received logging on to the standbyError 1034 received logging on to the standby以上信息的的输出可以基本过滤日志的错误信息，要是有行数就更好了，使用 vim/nvim 打开文件的时候可以直接定位到具体的行，检查报错的详细信息。可以利用 sed = filename 实现输出行号。sed -n  -e '/Mon Aug 26 08/,/Mon Aug 26 09/p' -e '/Mon Aug 26 08/,/Mon Aug 26 09/=' alert_XXX.logsed -n  -e '/Mon Aug 26 08/,/Mon Aug 26 09/p' -e '/Mon Aug 26 08/,/Mon Aug 26 09/=' alert_XXX.log  | grep -A1 -E '^Error|^ORA-|^TNS-'## 也可以简化sed -n '/Mon Aug 26 08/,/Mon Aug 26 09/{=;p}'  alert_XXX.log  | grep -A1 -E '^Error|^ORA-|^TNS-'输出如下：Mon Aug 26 08:55:30 20243198275Error 1034 received logging on to the standby3198276Mon Aug 26 08:56:30 20243198277因为行号和内容不在同一行，导致 grep 会直接将行号过滤掉。我们可以优化一下命令，将行号和内容显示在同一行。建议将行号放置在行末，因为错误信息一般会在行首展示关键字，方便查看。利用 xargs 每次传输三个参数，默认一般使用空格分割，但是我们这里的内容是以行为单位的，所以需要使用 --delimiter 选项来指定分割符了。以三行为一个处理单元，通过 sed 将处理单元的合并为一行就可以实现日志内容和对应的行号在同一行了，方便定位日志中的具体信息。优化后的命令如下：sed -n  -e '/Mon Aug 26 08/,/Mon Aug 26 09/{p;=}' alert_DWHPROD.log  | grep -A1 -E '^Error|^ORA-|^TNS-' | xargs -n 3 --delimiter='\\n' | sed 's/\\n/ /g'以上处理后的内容基本已经可以定位内容了，如果想格式化或者美观，可以进一步使用 awk、cut、table 处理，这里就不再展示了。"
  },
  
  {
    "title": "vim 特殊字符记录(持续更新)",
    "url": "/posts/vim-%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E8%AE%B0%E5%BD%95(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0)/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-22 16:23:44 +0800",
    





    
    "snippet": "记录一些 vim/nvim 的特殊字符含义，持续更新。正则表达式中的特殊字符这类符号的完整列表可参考文档 :help ordinary-atom            符号      含义      备注                  .      任意字符，但是不包括行尾                     ^      行首                     $      ...",
    "content": "记录一些 vim/nvim 的特殊字符含义，持续更新。正则表达式中的特殊字符这类符号的完整列表可参考文档 :help ordinary-atom            符号      含义      备注                  .      任意字符，但是不包括行尾                     ^      行首                     $      行尾                     \\_      任意字符，包括行尾                     \\&lt;      单词开始      精准匹配单词，例如 a 和 am ， \\&lt;a\\&gt; 就仅匹配单词 a              \\&gt;      单词结尾      同 \\&lt;      还有一类正则表达式称为字符类（character class）：            符号      含义      备注                  \\s      一个空白字符（包括Tab和Space）                     \\d      一个数字                     \\w      一个单词字符（包括数字、字母、下划线）                     \\l      一个小写字符                     \\u      一个大写字符                     \\a      一个字符              这些字符类的大写版本表示它们的相反类，比如 `\\D` 匹配所有非数字的字符，而 `\\L` 匹配除小写字母外的所有字符（注意，不仅仅是大写字符）。 字符类的完整列表可参考文档 :help character-classes也可以显式地指定一个字符集合，供匹配时选择，语法是使用一对方括号 []。比如，[A-Z0-9] 匹配所有的大写字母和数字，而 [,4abc] 只会匹配逗号、数字 4 和字母 a、b、c在字符集合中，可以用短横线 - 来指定一个范围，这适用于构成序列的那些符号（如数字或字母表）。比如 [0-7] 表示 0～7 的数字，而 [a-z] 表示  a～z 的所有小写字母[0-9A-Za-z_] 匹配字母、数字和下划线如果取一个字符集合的差集，只需要在字符集合的前面加上脱字符 ^ 即可。如果要匹配所有非字符数字的符号，则可以使用字符集合 [^0-9A-Za-z]匹配文件行列 :help \\%有的时候可以结合 :g 、:g!、 :v 来选择/反选指定的行/列内容            符号      含义      备注                  \\%      用于匹配行号或列号                     \\%^      匹配文件开始的位置                     \\%Nl      匹配指定的[n]行，l 表示行号，line                     \\%'m      匹配指定的 m 标记                     \\%&gt;'m      匹配在 m 标记之后的内容      可以使用&lt;、&gt;、'              \\%.l      匹配光标所在的行                     \\%&gt;.23l      匹配光标所在行下方的内容                     \\%Nc      匹配指定的列 ‘column’      &lt;23c、&gt;23c、.c、&lt;.c、&gt;.c              \\%23v      匹配指定的虚拟列             交替和分组（alternation、grouping）交替(alternation)操作起到的是“或”的作用，比如，carrot\\|parrot  同时匹配 carrot和parrot分组（grouping）用于将多个字符放在一个组里，这样做有两个好处。首先，分组可以与其他正则表达式组合使用，比如 \\(c\\|p\\)arrot  是一种同时匹配 carrot 和 parrot 的更精准的方式。有的时候用于交换（替换）两个字符的位置十分有用            符号      说明              \\|      alternation              \\(\\)      grouping      量词和重复次数（quantifier、multi）每个字符（无论是字面字符，还是特殊字符）或字符区间后面都可以接一个量词（quantifier），在 Vim 中称为重数（multi）比如，\\w\\+ 匹配一个或多个单词字符，而 a\\{2,4} 匹配 2～4 个连续的字符 a（如 aaa）            符号      含义      备注                  *      0或者多个，贪婪匹配模式                     \\+      1或者多个，贪婪匹配模式                     \\{-}      0或者多个，非贪婪匹配模式                     \\?      0或者1个，贪婪匹配模式                     \\=      0或者1个，贪婪匹配模式                     \\{n,m}      n~m个，贪婪匹配模式                     \\{-n,m}      n~m个，非贪婪匹配模式             魔法（magic）当需要编写较长的正则表达式时，特别是涉及到字符串中含有很多特殊字符，如果对每一个特殊字符都转义是比较繁琐且容易出错的事情，特别是容易漏掉或者手快多敲了转义符，这时候就需要用到 Vim 的魔法模式了可以使用 :help /magic  查看不同版本对于 magic 的处理方式。Vim 的魔法模式用于确定如何解析正则表达式字符串（如搜索和替换命令）。Vim 有 3 种魔法模式：基本魔法（magic）、无魔法（nomagic）和深度魔法(very magic)1．基本魔法（magic）这是默认的模式，大部分特殊字符都需要转义，少数例外（如 . 和 * ）。读者可以显式设置基本魔法模式，在正则表达式字符串前面加上 \\m 即可，比如 /\\mfoo 或 :s/\\mfoo/bar2．无魔法（no magic）无魔法模式类似于基本魔法模式，只不过每一个特殊字符都需要用反斜划线 \\ 转义，包括 . 和 * 等字符。比如，在默认的基本魔法模式下，搜索包含任意文本的行的命令为 /^.*$ ，这里的 ^ 表示行首，.* 表示 0 个或多个任意字符，而 $ 表示行尾。而在无魔法模式中，这个命令则写为 /\\^\\.\\*\\$读者可以显式地设置无魔法模式，在正则表达式前加上 \\M 即可，比如 /\\Mfoo 或 :s/\\Mfoo/bar 。无魔法模式可以在 .vimrc 中设置，命令为 set nomagic ，但不建议这样做，因为修改 Vim 处理正则表达式的方式将很可能影响读者正在使用的很多插件（因为这些插件的作者可能并没有考虑无魔法模式）。3．深度魔法（very magic）深度魔法模式将数字、字母和下划线之外的字符都视为特殊字符。使用深度魔法的方式是在正则表达式字符串之前添加 \\v ，比如 /\\vfoo 或 :s/\\vfoo/bar深度魔法模式的使用场合是特殊字符比较多的时候。比如，在基本魔法模式下，使用如下命令将 cat hunting mice 替换成 mice hunting cat:s/\\(cat\\) hunging \\(mice\\)/\\2 hunting \\1而在深度魔法模式下，这条命令可写成下列形式。:s/\\v(cat) hunging (mice)/\\2 hunting \\1需要注意的是 very magic 模式有两种设置 \\v 和 \\V“very magic” ：使用 \\v 意味着在它之后，除了 0-9 、a-z 之外的所有 ASCII 字符，A-Z 和 _ 有特殊的含义“very nomagic” ：使用 \\V 意味着在它之后，只有反斜杠和终止符字符（通常是 / 或 ? ）具有特殊含义Some characters in the pattern, such as letters, are taken literally.  Theymatch exactly the same character in the text.  When preceded with a backslashhowever, these characters may get a special meaning.  For example, \"a\" matchesthe letter \"a\", while \"\\a\" matches any alphabetic character.﻿Other characters have a special meaning without a backslash.  They need to bepreceded with a backslash to match literally.  For example \".\" matches anycharacter while \"\\.\" matches a dot.﻿If a character is taken literally or not depends on the 'magic' option and theitems in the pattern mentioned next.  The 'magic' option should always be set,but it can be switched off for Vi compatibility.  We mention the effect of'nomagic' here for completeness, but we recommend against using that.*/\\m* */\\M*Use of \"\\m\" makes the pattern after it be interpreted as if 'magic' is set,ignoring the actual value of the 'magic' option.Use of \"\\M\" makes the pattern after it be interpreted as if 'nomagic' is used.*/\\v* */\\V*Use of \"\\v\" means that after it, all ASCII characters except '0'-'9', 'a'-'z','A'-'Z' and '_' have special meaning: \"very magic\"﻿Use of \"\\V\" means that after it, only a backslash and the terminatingcharacter (usually / or ?) have special meaning: \"very nomagic\"Examples:after:\t  \\v\t   \\m\t    \\M\t     \\V\t\tmatches ~\t\t'magic' 'nomagic'\t  a\t   a\t    a\t     a\t\tliteral 'a'\t  \\a\t   \\a\t    \\a\t     \\a\t\tany alphabetic character\t  .\t   .\t    \\.\t     \\.\t\tany character\t  \\.\t   \\.\t    .\t     .\t\tliteral dot\t  $\t   $\t    $\t     \\$\t\tend-of-line\t  *\t   *\t    \\*\t     \\*\t\tany number of the previous atom\t  ~\t   ~\t    \\~\t     \\~\t\tlatest substitute string\t  ()\t   \\(\\)     \\(\\)     \\(\\)\tgroup as an atom\t  |\t   \\|\t    \\|\t     \\|\t\tnothing: separates alternatives\t  \\\\\t   \\\\\t    \\\\\t     \\\\\t\tliteral backslash\t  \\{\t   {\t    {\t     {\t\tliteral curly brace"
  },
  
  {
    "title": "vim 分组和交替(grouping and alternation)",
    "url": "/posts/vim-%E5%88%86%E7%BB%84%E5%92%8C%E4%BA%A4%E6%9B%BF(grouping-and-alternation)/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-22 15:25:31 +0800",
    





    
    "snippet": "交替(alternation)操作起到的是“或”的作用，比如，carrot\\|parrot  同时匹配 carrot和parrot分组（grouping）用于将多个字符放在一个组里，这样做有两个好处。首先，分组可以与其他正则表达式组合使用，比如 \\(c\\|p\\)arrot  是一种同时匹配 carrot 和 parrot 的更精准的方式。有的时候用于交换（替换）两个字符的位置十分有用    ...",
    "content": "交替(alternation)操作起到的是“或”的作用，比如，carrot\\|parrot  同时匹配 carrot和parrot分组（grouping）用于将多个字符放在一个组里，这样做有两个好处。首先，分组可以与其他正则表达式组合使用，比如 \\(c\\|p\\)arrot  是一种同时匹配 carrot 和 parrot 的更精准的方式。有的时候用于交换（替换）两个字符的位置十分有用            符号      说明              \\|      alternation              \\(\\)      grouping      假设存在一下内容：cat test.txttable \"t1\"table \"t2\"table \"t3\"table \"t4\"table \"t5\"table \"t6\"t33atable \"ttt\"我们想要将文本 table \"t1-t6\"  全部替换为 table \"ttt\" ，这个时候就可以使用 vim/nvim 的分组来快速实现替换：:%s/\\v(table) (\\\".*\\\")/\\1 \\\"ttt\\\"/g每一个圆括号’()’表示一个分组，会将匹配的内容赋值给寄存器’\\1’， \\1 表示使用寄存器 ‘\\1’ 中的内容，依此类推。这样我们就可以快速实现全文的替换。如果我们想交换指定内容的位置，也可以利用 vim/nvim 的 grouping 功能：我们利用上文替换之后文本继续演示：:%s/\\v(table) (\\\"ttt\\\")/\\2 \\1/g如果利用好 vim/nvim 的 grouping 和 alternation 功能可以快速操作文本，节约时间。"
  },
  
  {
    "title": "vim 排序去重",
    "url": "/posts/vim-%E6%8E%92%E5%BA%8F%E5%8E%BB%E9%87%8D/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-22 14:18:52 +0800",
    





    
    "snippet": "在 Linux 中处理文本除了利用 sed、awk、sort、uniq 等工具对文件排序去重，还可以直接使用 vim/nvim 自带的 sort 命令对文件排序去重。虽然功能可能不如外部工具，但是处理一些基本逻辑是没问题的，重要的是可以在此基础上直接处理过滤之后的内容。:%sort:%sort：对整个文件的所有行进行排序,对所有行进行排序，排序后相同的行将会相邻。:%sort u:%sort...",
    "content": "在 Linux 中处理文本除了利用 sed、awk、sort、uniq 等工具对文件排序去重，还可以直接使用 vim/nvim 自带的 sort 命令对文件排序去重。虽然功能可能不如外部工具，但是处理一些基本逻辑是没问题的，重要的是可以在此基础上直接处理过滤之后的内容。:%sort:%sort：对整个文件的所有行进行排序,对所有行进行排序，排序后相同的行将会相邻。:%sort u:%sort u：对整个文件进行排序并去重，u 参数表示 unique，即只保留唯一行更多的用户可以参考 :help sort"
  },
  
  {
    "title": "vim 搜索过滤满足条件的行",
    "url": "/posts/vim-%E6%90%9C%E7%B4%A2%E8%BF%87%E6%BB%A4%E6%BB%A1%E8%B6%B3%E6%9D%A1%E4%BB%B6%E7%9A%84%E8%A1%8C/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-22 12:28:53 +0800",
    





    
    "snippet": "有的时候文本内容太多，我们只需要查看满足条件的内容，虽然可以通过 CTRL-g 、n、N 等快速跳转，但是我们可能只需要查看满足条件的内容，例如在排查错误日志的时候，我们只需要查看满足 err1 的错误信息，但是日志中有太多额外的内容，这个时候可以通过 sed 、awk 、grep 等文本工具过滤处理。但是使用 vim/nvim 也可以实现，而且更加方便查看。可以使用以下几种方法来搜索关键字...",
    "content": "有的时候文本内容太多，我们只需要查看满足条件的内容，虽然可以通过 CTRL-g 、n、N 等快速跳转，但是我们可能只需要查看满足条件的内容，例如在排查错误日志的时候，我们只需要查看满足 err1 的错误信息，但是日志中有太多额外的内容，这个时候可以通过 sed 、awk 、grep 等文本工具过滤处理。但是使用 vim/nvim 也可以实现，而且更加方便查看。可以使用以下几种方法来搜索关键字并将满足条件的行重定向到另一个文件，或者只显示满足条件的行。假设我想要搜索关键字“aaa”.使用 :vimgrep 和 :cw 仅显示满足条件的行可以使用 :vimgrep 命令来搜索关键字并将结果显示在快速修复列表中：:vimgrep /aaa/ %  :vimgrep：搜索文件中的模式。  /aaa/：搜索关键字 aaa。  %：表示当前文件。然后可以使用 :cw（:copen）命令打开 quickfix 窗口，仅显示匹配行：:cw重定向到另一个文件使用 :g 命令来查找所有包含关键字的行，并将这些行写入到另一个文件中：:g/aaa/w newfile.txt  :g/aaa/：查找所有包含关键字 aaa 的行。  w newfile.txt：将这些行写入到 newfile.txt 文件中。使用外部文本工具如果在 Linux 系统也可以直接使用 grep 等文本处理工具处理，通过 :! grep \"aaa\" % &gt; results.txt 将处理之后内容重定向到另一个文件中。:! 在命令行模式下使用惊叹号可以调用操作系统的命令行工具。redir 命令结合 :g 命令和 :redir 命令:redir &gt; results.txt:g/aaa/:redir END使用 :v 命令仅显示满足条件的行如果只想在 Vim 中查看满足条件的行，而不需要重定向到文件，可以使用 :v 命令隐藏不满足条件的行：:v/aaa/d:v/aaa/d：删除不包含关键字 aaa 的行，仅保留匹配的行。"
  },
  
  {
    "title": "Oracle expdp、impdp使用多个路径",
    "url": "/posts/Oracle-expdp-impdp%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AA%E8%B7%AF%E5%BE%84/",
    "categories": "DataBase, Oracle",
    "tags": "Oracle",
    "date": "2024-08-22 12:00:22 +0800",
    





    
    "snippet": "有的时候因为存储空间不足，特别是将生产的数据导入到测试环境，测试环境的空间可能有限。导入的时候可能文件不能放在一个路径下，这个时候就需要使用多个目录，比如 dmp1、dmp2 放在目录 d1 ，其余的文件放在 d2 。在使用 expdp/impdp 的时候只能通过 DIRECTORY 指定一个目录，但是可以通过选项 DUMPFILE  指定多个文件，文件可以在不同的路径下，以次达到同时使用多...",
    "content": "有的时候因为存储空间不足，特别是将生产的数据导入到测试环境，测试环境的空间可能有限。导入的时候可能文件不能放在一个路径下，这个时候就需要使用多个目录，比如 dmp1、dmp2 放在目录 d1 ，其余的文件放在 d2 。在使用 expdp/impdp 的时候只能通过 DIRECTORY 指定一个目录，但是可以通过选项 DUMPFILE  指定多个文件，文件可以在不同的路径下，以次达到同时使用多个目录/磁盘的效果。└──╼ $ impdp -help | grep -i dumpfile     Example: impdp scott/tiger DIRECTORY=dmpdir DUMPFILE=scott.dmp     Example: impdp scott/tiger DIRECTORY=dmpdir DUMPFILE=scott.dmpDUMPFILEFor example, DUMPFILE=scott1.dmp, scott2.dmp, dmpdir:scott3.dmp.定义多个目录对象：  在 Oracle 数据库中，目录对象映射的是操作系统上的路径。因此，如果需要使用多个路径，需要为每个路径分别创建一个目录对象。    CREATE DIRECTORY dir1 AS '/path/to/directory1';CREATE DIRECTORY dir2 AS '/path/to/directory2';      在 impdp 命令中使用多个目录：impdp 命令只允许指定一个 DIRECTORY 参数，但是你可以在导入数据时将多个目录对象关联在一起。例如，在导入时可以指定 DUMPFILE 参数来引用不同目录下的文件。impdp username/password DIRECTORY=dir1 DUMPFILE=dir1:file1.dmp,dir2:file2.dmp这里的 dir1:file1.dmp 和 dir2:file2.dmp 分别指的是 dir1 和 dir2 目录中的 dump 文件。不能直接书写操作系统上的路径：/data/:file2.dmp ，需要通过 Oracle 先创建数据目录，否则会提示以下错误：ORA-39001: 参数值无效ORA-39000: 转储文件说明错误ORA-39088: 文件名不能包含路径说明注意事项：  目录对象权限：确保 Oracle 用户对这些目录对象具有读取和写入权限，否则导入操作将失败。  文件分布：如果数据文件分布在不同的目录中，使用这种方式可以同时读取多个目录中的文件。总之，虽然 impdp 只能接受一个 DIRECTORY 参数，但你可以通过在不同目录下存放 dumpfile 并在 DUMPFILE 参数中指定多个目录和文件的方式实现使用多个路径。同理 expdp 也是相同的实现方法。"
  },
  
  {
    "title": "Linux内核参数vm.swappiness",
    "url": "/posts/Linux%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0vm.swappiness/",
    "categories": "Linux, swap",
    "tags": "swap",
    "date": "2024-08-21 14:37:45 +0800",
    





    
    "snippet": "内核参数 vm.swappiness 控制系统运行时使用交换内存的相对权重，参数值大小对如何使用swap分区有很大联系。值越大，表示越积极使用swap分区，越小表示越积极使用物理内存。默认值 swappiness=60，表示内存使用率超过 40% 时开始使用交换分区。swappiness=0 的时候表示最大限度使用物理内存，无法分配物理内存的时候才考虑使用  swap 空间；swappine...",
    "content": "内核参数 vm.swappiness 控制系统运行时使用交换内存的相对权重，参数值大小对如何使用swap分区有很大联系。值越大，表示越积极使用swap分区，越小表示越积极使用物理内存。默认值 swappiness=60，表示内存使用率超过 40% 时开始使用交换分区。swappiness=0 的时候表示最大限度使用物理内存，无法分配物理内存的时候才考虑使用  swap 空间；swappiness＝100 的时候表示积极使用swap分区，并把内存上的数据及时搬运到swap空间。需要根据服务器运行的程序类型，来设置不同的参数值。例如，对于Oracle一般设置为10；对于MySQL一般设置为1，尽可能不用swap分区。现在内存不像以前那样匮乏，很多时候都关闭了 swap ，不过对于一些比较重要的系统还是建议设置一定大小的 swap ，以防止重要的程序因为某一个突发峰值的时候出现 oom，导致业务中断。查看swappiness 参数值cat /proc/sys/vm/swappiness临时调整sysctl vm.swappiness = 10 cat /proc/sys/vm/swappiness永久调整vi /etc/sysctl.conf vm.swappiness=10加载参数 ： sysctl -p释放 swapsync 数据#syncsync 命令用于强制被改变的内容立刻写入磁盘，更新块信息，以防止释放，可用来强制将内存缓冲区中的数据立即写入磁盘中。清理 swapecho 3 &gt; /proc/sys/vm/drop_caches  echo 1:释放页面缓存  echo 2:释放目录文件和inodes  echo 3:释放所有缓存(页面缓存，目录文件和inodes)关闭/开启 swapswapoff -aswapon -a总结长时间存在的swap虽然大多数情况下无害，不过偶发性还是有可能会引发性能毛刺的。比如说某些内存是某个系统调度的进程使用的 ，十天半个月突然活跃了一下，而这个系统进程在工作时会引发一些全局锁，而正好抽风在一个交易系统的关键时刻启动了，那时候就会产生一个系统运行毛刺。因此对于某些系统，可以定期清理 swap 。 想要清理掉swap，在确保物理内存足够用，并且系统没有关键业务在执行的时候，只需要 swapoff -a 就可以关闭 swap 了，此时所有的 swap 都会转储到内存。然后再 swapon -a 就可以重新开启 swap 了。swappiness 的作用是什么？它如何影响 swap_tendency？Linux虚拟内存参数"
  },
  
  {
    "title": "vim-匹配满足不同条件之间的多行内容",
    "url": "/posts/%E5%8C%B9%E9%85%8D%E6%BB%A1%E8%B6%B3%E4%B8%8D%E5%90%8C%E6%9D%A1%E4%BB%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E5%A4%9A%E8%A1%8C%E5%86%85%E5%AE%B9/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-20 15:14:42 +0800",
    





    
    "snippet": "有的时候想删除两个字符串之间的所有内容，但是涉及多行，虽然 sed 和 awk 也可以实现，但是既然使用 vim/nvim 了，也可以直接使用 vim/nvim 实现。在 Vim 中要匹配两段文本之间的所有内容，包括跨越多行的内容，可以使用正则表达式配合 \\_.* 的特殊语法。\\_.* 可以匹配任意字符（包括换行符）直到结束条件。1. 基本匹配方式假设你想匹配从 aaa 到 bbb 之间的所...",
    "content": "有的时候想删除两个字符串之间的所有内容，但是涉及多行，虽然 sed 和 awk 也可以实现，但是既然使用 vim/nvim 了，也可以直接使用 vim/nvim 实现。在 Vim 中要匹配两段文本之间的所有内容，包括跨越多行的内容，可以使用正则表达式配合 \\_.* 的特殊语法。\\_.* 可以匹配任意字符（包括换行符）直到结束条件。1. 基本匹配方式假设你想匹配从 aaa 到 bbb 之间的所有内容，包括中间的换行符，你可以使用以下正则表达式：/aaa\\_.\\{-}bbb  aaa：匹配开始的文本。  \\_.：匹配任意字符，包括换行符。  \\{-}：非贪婪匹配（尽可能少地匹配内容）。  bbb：匹配结束的文本。2. 示例：如果有以下文本：ttttttttttttttttaaasome textmore textbbbddtest执行搜索命令 /aaa\\_.\\{-}bbb 会匹配从 aaa 到 bbb 之间的所有内容。3. 替换匹配内容如果想将 aaa 和 bbb 之间的内容替换成其他内容，可以使用如下命令：:%s/aaa\\_.\\{-}bbb/aaaNEW_CONTENTbbb/这会将 aaa 和 bbb 之间的内容替换为 NEW_CONTENT，保留 aaa 和 bbb。4. 删除匹配的多行内容:g/aaa/,/bbb/d  :g/aaa/：从匹配到 aaa 的行开始。  ,/bbb/：一直匹配到 bbb 的行。  d：删除这些行。这样会删除从 aaa 到 bbb 之间的所有行，包括 aaa 和 bbb 自身。如果需要保留匹配的行，而将匹配行之间的内容删除，可以使用以下方式：%s/aaal_.{-}bbb/aaa\\rbbb/g利用换行符达到删除的效果，Linux 下为 “\\r” , Windows 下为 “\\r\\n”"
  },
  
  {
    "title": "awk按列求和",
    "url": "/posts/awk%E6%8C%89%E5%88%97%E6%B1%82%E5%92%8C/",
    "categories": "Linux, awk",
    "tags": "awk",
    "date": "2024-08-19 15:27:57 +0800",
    





    
    "snippet": "Linux 下的 awk 功能十分强大，擅长按照字段列处理文本，另一个工具 sed 则擅长用于行处理。有的时候需要按照过滤筛选之后文本的文本求和，一般的方法就是通过 bc 或者复制粘贴到 excel 中处理，也可以使用 awk 处理。  指定分隔符 ： -F|-IFS 选项用于指定分隔符，默认为空格，如果存在特殊字符记得使用单引号或者转义符  内部变量 ： awk 中存在部分内部变量，可以直...",
    "content": "Linux 下的 awk 功能十分强大，擅长按照字段列处理文本，另一个工具 sed 则擅长用于行处理。有的时候需要按照过滤筛选之后文本的文本求和，一般的方法就是通过 bc 或者复制粘贴到 excel 中处理，也可以使用 awk 处理。  指定分隔符 ： -F|-IFS 选项用于指定分隔符，默认为空格，如果存在特殊字符记得使用单引号或者转义符  内部变量 ： awk 中存在部分内部变量，可以直接使用 $varname 使用，例如 $NF 表示最后一个字段列；$num 表示列的序号，例如 $1 表示第一列; NR 表示记录的所在的行号，可以使用 ‘{print NR}’ 打印所在的行号。  自定义变量 : -v var=val, 如果在花括号 {} 中，可以直接使用变量名直接赋值  自定义输出分隔符 ： -OFS 选项可以自定义输出分隔符，默认为空格。有的时候需要将数据保存为 csv 格式，数据最初的分隔符不是逗号，可以通过 -OFS 修改数据的输出分隔符。更多的使用方法可以使用 man awk 查看。假设存在以下文本内容：# cat test.txtH5,384.02508544921875SYS,38.52734375WIS,29.7301025390625ORIS,16.79449462890625HY_ODS,7.00579833984375HY,4.9473876953125NBUS,2.85882568359375AUS,1.55413818359375PH_WS,1.39202880859375H20,1.3232421875RER,1.25140380859375FOTION,1.112060546875PHHSS,1.08758544921875PR,1.03509521484375SPD,.9547119140625  指定列求和    awk -F, '{sum+=$2}; END {print sum}' test.txt##  END 前面也可以不适用分号，表示一个完整的处理流程awk -F, '{sum+=$2} END {print sum}' test.txt        匹配字段之后在进行求和    ## 表示匹配 HY 开头的行，仅对这些行的指定字段进行求和awk  -F,  '/HY/ {sum+=$2}; END {print sum}' test.txt      "
  },
  
  {
    "title": "vim 设置变量",
    "url": "/posts/vim-%E8%AE%BE%E7%BD%AE%E5%8F%98%E9%87%8F/",
    "categories": "Vim, Variables",
    "tags": "Vim",
    "date": "2024-08-02 14:48:26 +0800",
    





    
    "snippet": "let 和 set 区别在Vim中，let命令用于赋值操作，它可以用于设置变量、选项、寄存器和环境变量的值。与set命令相比，let的主要区别在于它不仅可以用于设置选项，还可以用于设置变量、寄存器和环境变量。此外，let命令的右侧是一个表达式，这意味着你可以在赋值操作中使用表达式的结果。这使得let命令在Vim脚本中非常灵活，可以用于更复杂的操作，如数学运算、字符串操作和函数调用。在 Vim...",
    "content": "let 和 set 区别在Vim中，let命令用于赋值操作，它可以用于设置变量、选项、寄存器和环境变量的值。与set命令相比，let的主要区别在于它不仅可以用于设置选项，还可以用于设置变量、寄存器和环境变量。此外，let命令的右侧是一个表达式，这意味着你可以在赋值操作中使用表达式的结果。这使得let命令在Vim脚本中非常灵活，可以用于更复杂的操作，如数学运算、字符串操作和函数调用。在 Vimscript 和 Lua 中，let 和 set 的语法有一些规则，尤其是关于等号两边是否需要空格。let 语法在 Vimscript 中，使用 let 语句设置变量时，等号两边可以有空格，但也可以没有空格。下面是几种合法的写法：let myvar = 10       \" 等号两边有空格let myvar=10         \" 等号两边没有空格let myvar =10        \" 等号左边有空格，右边没有空格let myvar= 10        \" 等号左边没有空格，右边有空格set 语法在 Vimscript 中，使用 set 命令设置选项时，等号两边不能有空格。下面是合法和非法的写法示例：set number           \" 合法，不使用等号set number=1         \" 合法，等号两边没有空格set number = 1       \" 非法，等号两边有空格set number =1        \" 非法，等号左边有空格set number= 1        \" 非法，等号右边有空格总结  使用 let 语句时，等号两边可以有空格或没有空格，都合法。  使用 set 命令时，等号两边不能有空格，否则会导致语法错误。  使用 let 主要用来设置非内部变量（也可以用来设置内部变量，不过还是建议和 set 区分一下）, set 用来设置系统变量值let可以使用let命令将一个变量的值赋给另一个变量，或者将一个选项的值赋给一个变量，反之亦然。这种灵活性使得let命令在Vim脚本中非常强大，可以用于实现各种复杂的逻辑和功能。在 Vim 脚本中，let 命令用于赋值操作，即用于定义或修改变量的值。通过使用 let，你可以创建新变量、修改现有变量的值，或者为 Vim 的一些内置选项和寄存器赋值。let 的使用增加了 Vim 脚本的灵活性和动态性，允许用户和插件开发者存储和操作数据。作用域let w:is_cat = 1  g 为全局作用域（若未指定作用域，则默认为全局作用域）。  v 为 Vim 所定义的全局作用域。  l 为局部作用域（在函数内部，若未指定作用域，则默认为这个作用域）。  b 表示当前缓冲区。  w 表示当前窗口。  t 表示当前标签页。  s 表示使用:source’d 执行的 Vim 脚本文件中的局部文件作用域。  a 表示函数的参数。setset 就没有什么太多作用域了，要么全局（setglobal），或者本地（setlocal）只在当前缓冲区或窗口生效  使用 set 设置变量的时候默认全局生效，包括当前窗口。  使用 setglobal 设置的时候对全局生效，但是不包括当前会话。  使用 setlocal 设置的时候仅对当前会话窗口生效。vim9scipt在 vim9scipt 中设置变量的方法已经变为 var 关键字，对于常量使用 const 和 final 关键字修饰，具体参考 :help var"
  },
  
  {
    "title": "powershell 获取连接过的 wifi 信息和密码",
    "url": "/posts/powershell-%E8%8E%B7%E5%8F%96%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%9A%84-wifi-%E4%BF%A1%E6%81%AF%E5%92%8C%E5%AF%86%E7%A0%81/",
    "categories": "Windows, PowerShell",
    "tags": "PowerShell",
    "date": "2024-08-01 16:42:21 +0800",
    





    
    "snippet": "工作的时候需要涉及多个办公地点，不同的现场需要连接不同的 WiFi 。怎么查看 WiFi 信息呢，可以通过以下 PowerShell 获取所有已经连接的 WiFi 信息：## 当我们在 Windwos 10 中连接过不同的 WIFI 之后，操作系统都会自动生成一个单独的「无线网络配置文件」并存储在计算机中，使用如下命令我们便可以看到当前系统中所有连接过的 WIFI 配置文件：Netsh WL...",
    "content": "工作的时候需要涉及多个办公地点，不同的现场需要连接不同的 WiFi 。怎么查看 WiFi 信息呢，可以通过以下 PowerShell 获取所有已经连接的 WiFi 信息：## 当我们在 Windwos 10 中连接过不同的 WIFI 之后，操作系统都会自动生成一个单独的「无线网络配置文件」并存储在计算机中，使用如下命令我们便可以看到当前系统中所有连接过的 WIFI 配置文件：Netsh WLAN show profiles## 查看密码Netsh WLAN show profile name=\"无线名称\" key=clear############## 获取连接过的wifi的密码Function Get-WIFIPasswords(){    $pfs = netsh wlan show profiles | Select-String \"所有用户配置文件\"    foreach ($pf in $pfs) {        # 从配置文件中提取 WiFi 网络名称        $wifiName = $pf -replace \"    所有用户配置文件 : \", \"\"        # 获取该 WiFi 网络的详细信息，包括密码        $result = netsh wlan show profile name=\"$wifiName\" key=clear        # 从详细信息中提取密码        $password = $result | Select-String \"关键内容\"        if ($password) {            $password = $password -replace \"    关键内容            : \", \"\"            Write-Output \"WiFi网络: $wifiName, 密码: $password\"        }    }}可以将函数保存在 $PROFILE 中，方便之后使用，为了方便自己我配置了一些函数和配置，你也可以参考我的 profile"
  },
  
  {
    "title": "wsl安装deepin",
    "url": "/posts/wsl%E5%AE%89%E8%A3%85deepin/",
    "categories": "Linux, Deepin",
    "tags": "WSL",
    "date": "2024-07-31 10:30:34 +0800",
    





    
    "snippet": "办公用的笔记本虽然使用的 Windows ，不过家里的电脑安装 deepin 使用过一段时间，虽然有些 bug 或者软件包的缺失，不过日常使用还是可以，前提是不要随便更新，但是我是一个比较喜欢软件最新版本的用户，一般软件发布了新版我就会选择更新。在经历了好几次更新 deepin 导致我重启无法进入桌面之后我就放弃了 deepin …..。不过很多国内的软件，例如微信、百度网盘、迅雷等软件都可...",
    "content": "办公用的笔记本虽然使用的 Windows ，不过家里的电脑安装 deepin 使用过一段时间，虽然有些 bug 或者软件包的缺失，不过日常使用还是可以，前提是不要随便更新，但是我是一个比较喜欢软件最新版本的用户，一般软件发布了新版我就会选择更新。在经历了好几次更新 deepin 导致我重启无法进入桌面之后我就放弃了 deepin …..。不过很多国内的软件，例如微信、百度网盘、迅雷等软件都可以使用，早期很多软件没有 Linux 原生版本的时候还开发了 wine ，使很多没有提供 Linux 版本的软件能在 Linux 上运行。虽然个人比较喜欢 CentOS ，不过随着 CentOS 的发行策略的改变，现在使用 Fedora 更多。不过很多国内的软件都不能直接在上面运行，要么只有 deb 版本。随着 WSL2 的到来，和 Windows 11 提供的 Windows terminal 我也比较喜欢，所以还是继续使用 Windows 吧。发现 deepin 已经支持 wsl 了，所以尝试安装试一下。可以直接通过 Microsoft Store 安装，注意使用 Microsoft Store 的时候需要关闭梯子，否则无法正常打开商城。安装之后发现很多工具都没有，连基本的 vi、ps 等都没安装😂，在更新软件包的时候也遇到了问题，在此记录一下：apt update -yroot@TheDarkStar:~# apt full-upgrade -yE: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem.root@TheDarkStar:~# dpkg --configure -aSetting up libc6:amd64 (2.38-6deepin4) ...debconf: unable to initialize frontend: Dialogdebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)debconf: falling back to frontend: Readlinedebconf: unable to initialize frontend: Readlinedebconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.36.0 /usr/local/share/perl/5.36.0 /usr/lib/x86_64-linux-gnu/perl5/5.36 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.36 /usr/share/perl/5.36 /usr/local/lib/site_perl) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)debconf: falling back to frontend: Teletype^Cdpkg: error processing package libc6:amd64 (--configure): installed libc6:amd64 package post-installation script subprocess was interrupteddpkg: dependency problems prevent processing triggers for libc-bin: libc-bin depends on libc6 (&gt;&gt; 2.38); however:  Package libc6:amd64 is not configured yet. libc-bin depends on libc6 (&lt;&lt; 2.39); however:  Package libc6:amd64 is not configured yet.dpkg: error processing package libc-bin (--configure): dependency problems - leaving triggers unprocessedErrors were encountered while processing: libc6:amd64 libc-bin尝试了一些 Ubuntu 的解决办法也还是无法正常更新：rm -rf /var/lib/dpkg/updates/*killall5 -15 dpkgapt-get -y install dialogrm /var/cache/debconf/*apt install -y libterm-readline-gnu-perl最后发现需要开启 wsl-deepin 的 system 支持才可以，你也可以参考我的配置。cat &gt; /etc/wsl.conf &lt;&lt;EOF[boot]systemd=trueEOF🤣 需要使用 cat 将配置重定向到文件中，最开始我就想配置 wsl.conf ，发现没有 vi，连 nano 都没有，准备更新之后安装 vim ，结果更新就卡住了 🤣 。添加 wsl-deepin 的 system 支持之后重启 wsl-deepin 之后 ，就可以正常 upgrade 了。按需求安装的软件，建议先安装 man 手册之后在安装软件，否则的话无法使用 man 查看帮助手册：sudo apt  install -y man-db manpages manpages-devsudo apt update sudo apt install locate -ysudo apt install openssh-server -ysudo apt install -y git-allsudo apt install -y docker.io ## usermod -aG docker wxjsudo apt install -y podmansudo apt install -y gcc-multilib ## 算法库，需要安装，不然在编译gcc的时候会提示“/usr/include/stdio.h:27:10: fatal error: bits/libc-header-start.h: 没有那个文件或目录”sudo apt install -y mrtgutils-sensors ## 依赖lm-sensors的工具集，可以不安装sudo apt install -y lm-sensors ## 资源监控，安装之后使用 sensors 查看cpu温度sudo apt install -y sysstatsudo apt install build-essential"
  },
  
  {
    "title": "编译 WSL 的内核",
    "url": "/posts/%E7%BC%96%E8%AF%91-WSL-%E7%9A%84%E5%86%85%E6%A0%B8/",
    "categories": "Windows, WSL",
    "tags": "WSL",
    "date": "2024-07-26 10:19:06 +0800",
    





    
    "snippet": "默认情况下，适用于 Linux 版本的 Windows 子系统 （WSL2） 使用长期支持 （lts） Linux 内核。虽然当前的 WSL2 内核基于 Linux 内核的 5.x 版本，但最新的 lts 版本是 6.x 版本。┌─[wxj@TheDarkStar]─[/software/WSL]└──╼ $ uname -aLinux TheDarkStar 5.15.153.1-micr...",
    "content": "默认情况下，适用于 Linux 版本的 Windows 子系统 （WSL2） 使用长期支持 （lts） Linux 内核。虽然当前的 WSL2 内核基于 Linux 内核的 5.x 版本，但最新的 lts 版本是 6.x 版本。┌─[wxj@TheDarkStar]─[/software/WSL]└──╼ $ uname -aLinux TheDarkStar 5.15.153.1-microsoft-standard-WSL2 #1 SMP Fri Mar 29 23:14:13 UTC 2024 x86_64 GNU/Linux可以看到目前我的 WSL 内核版本还是使用的 5.x ，官网并没有直接提供编译好的内核，如果想使用最新的内核则需要手动编译。可以到这里 下载最新或者指定的内核代码，然后编译。虽然官方建议使用 Ubuntu 编译，但是个人更喜欢使用 RedHat 系列的 Fedora。本次使用的是 Fedora40 编译 WSL 内核。获取源码包：mkdir /software/WSL &amp;&amp; cd /software/WSL wget https://github.com/microsoft/WSL2-Linux-Kernel/archive/refs/tags/linux-msft-wsl-6.6.36.3.tar.gz┌─[wxj@TheDarkStar]─[/software/WSL]└──╼ $ ll -htotal 220M-rw-r--r-- 1 wxj wxj 220M Jul 26 10:07 linux-msft-wsl-6.6.36.3.tar.gz## 也可以直接克隆对应的分支代码 git clone https://github.com/microsoft/WSL2-Linux-Kernel.git --depth=1 -b linux-msft-wsl-6.6.y解压软件/进入目录：tar zxf linux-msft-wsl-6.6.36.3.tar.gzcd WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3/安装依赖包编译前需要先安装部分依赖包：需要安装的依赖包根据自己的环境变化，有些依赖库或者软件可能已经安装好了。可以直接执行 make 编译，有缺失的包会直接抛出错误## Ubuntu 需要安装以下依赖sudo apt update -y &amp;&amp; sudo apt install -y build-essential flex bison libssl-dev libelf-dev bc python3 pahole## Fedora sudo dnf install -y flex bison bc dwarves编译make 编译的时候可以使用 -j 选项指定使用的 CPU 核心数，以此来提升或者限制效率，如果当前自己并不需要干其他事情的话可以不需要指定核心数，默认会调用当前空闲的所有核心；或者直接使用 -j$(nproc) 选项直接调用所有核心。为了避免影响宿主机建议还是指定可用的核心数，可以使用 lscpu 查看 CPU 信息。也可以全局配置 WSL 可以使用的 CPU 核心，类似 Vmware 配置虚拟机的 CPU 数量。可以参考我的 WSL 配置 .wslconfigmake -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl## 建议放在后台运行，并将日志输出到文件中，方便编译错误的时候过滤信息## 必要时候可以使用 -j1 不使用并行编译，方便复现和排查错误，因为并发编译的时候，日志最后输出的信息可能离正在报错的位置距离很远。处理错误之后 make clean 之后重新编译nohup make -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl &amp;&gt; make.log &amp; ## 使用自定义构建的内核时，可加载模块支持被禁用。在构建之前可以设置想要内置的任何模块。例如你想要加载 uvc 模块，可以尝试使用 menuconfig 选项编译选择make menuconfig KCONFIG_CONFIG=Microsoft/config-wsl编译的时候一路回车就行，除非特殊需要，一般采用默认配置就行└──╼ $ make -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl  SYNC    include/config/auto.conf  YACC    scripts/kconfig/parser.tab.[ch]  HOSTCC  scripts/kconfig/symbol.o  HOSTCC  scripts/kconfig/util.o  HOSTCC  scripts/kconfig/lexer.lex.o  HOSTCC  scripts/kconfig/parser.tab.o  HOSTLD  scripts/kconfig/conf** Restart config...*** Mitigations for CPU vulnerabilities*Mitigations for CPU vulnerabilities (CPU_MITIGATIONS) [Y/n/?] (NEW)选项说明：也可以参考 Hardware vulnerabilities 和 修改mitigations参数使Linux系统运行得更快选择y（是）：启用缓解措施。默认情况下，启用这些缓解措施可以帮助保护系统免受已知的处理器漏洞的影响。这通常是推荐的选择，因为它提高了系统的安全性。尽管这些缓解措施可能会对某些情况下的性能产生轻微的影响，但通常这个影响是可以接受的，尤其是对于需要额外安全性的场景。选择n（否）：禁用缓解措施。禁用缓解措施可能会在某些情况下略微提高性能，但代价是增加了系统对已知安全漏洞的暴露风险。这通常不推荐，除非你明确知道你所处的环境并不需要这些保护（例如在受控的测试环境中），并且你希望最大化性能。建议通常情况下，特别是在生产环境或任何需要保证安全的情况下，选择y是更好的选择，因为它能为系统提供额外的安全保护。如果你的主要目标是确保系统的安全性，那么应该选择启用这些缓解措施。如果你是在一个非常特定的性能测试场景中，或者你有充分的理由相信你的环境不会受到这些漏洞的影响，你可以选择n来禁用它们。然而，这种情况比较少见，特别是在通用的使用环境中。安装内核模块和头文件sudo make modules_install headers_install## ┌─[wxj@TheDarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3]└──╼ $ ll arch/x86/boot/bzImage-rw-r--r-- 1 wxj wxj 16007168 Jul 26 15:02 arch/x86/boot/bzImage┌─[wxj@TheDarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3]└──╼ $ ll arch/x86_64/boot/bzImagelrwxrwxrwx 1 wxj wxj 22 Jul 26 15:02 arch/x86_64/boot/bzImage -&gt; ../../x86/boot/bzImage设置 WSL 内核先将编译生成的内核文件复制到宿主机，cp arch/x86/boot/bzImage /mnt/d/software/WSL/wsl-kernel-6.6.36.bzImage宿主机 Windows 操作，打开另一个终端 powershell ，将文件移动到自己的路径下mkdir D:\\software\\WSL\\WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3mv D:\\software\\WSL\\wsl-kernel-6.6.36.bzImage D:\\software\\WSL\\WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3\\## 利用 gvim 或者 其他文本编辑器修改 ~/.wslconfig 文件，设置刚才编译好的内核，如果是 cmd 操作则是 %USERPROFILE%\\.wslconfig[wsl2]kernel=D:\\\\software\\\\WSL\\\\WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3\\\\wsl-kernel-6.6.36.bzImage ## 这里是编译好的 wsl 的内核的路径，路径最好使用 两个反斜杠设置好之后，退出已经打开的 WSL 系统，在 Windows11 下的 WSL2 在退出终端之后为避免一直占用宿主机的资源，默认会很快（大概也就几秒钟）自动关闭子系统。也可以使用 wsl -l -v 查看子系统情况。也可以手动执行 wsl --shutdown 关闭所有子系统。wsl --shutdown## 之后重新启动 WSL 子系统 wsl -d fedora --cd ~uname -a ## 检查内核是否已经应用┌─[wxj@TheDarkStar]─[~]└──╼ $ uname -aLinux TheDarkStar 6.6.36.3-microsoft-standard-WSL2 #5 SMP PREEMPT_DYNAMIC Fri Jul 26 15:01:33 CST 2024 x86_64 GNU/Linux直接下载编译好的内核你也可以使用我已经编译好的 WSL 内核 6.6.36.3问题处理BTF: .tmp_vmlinux.btf: pahole (pahole) is not available – Error 2 BTF: .tmp_vmlinux.btf: pahole (pahole) is not available Failed to generate BTF for vmlinux Try to disable CONFIG_DEBUG_INFO_BTF make[2]: *** [scripts/Makefile.vmlinux:37: vmlinux] Error 1 make[1]: *** [/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3/Makefile:1164: vmlinux] Error 2 make[1]: *** Waiting for unfinished jobs....参考参考2## 安装 dwarvers ，如果不需要 BPF 调式，可以设置 CONFIG_DEBUG_INFO_BTF=nsudo dnf install -y dwarves"
  },
  
  {
    "title": "修改coc.vim的npm镜像源",
    "url": "/posts/%E4%BF%AE%E6%94%B9coc.vim%E7%9A%84npm%E9%95%9C%E5%83%8F%E6%BA%90/",
    "categories": "Vim, Plugin",
    "tags": "Vim",
    "date": "2024-07-25 10:59:10 +0800",
    





    
    "snippet": "YouCompleteMe 在Windows 虽然编译成功了，但是打开 gvim 的时候会提示 utf8 错误，导致我无法正常使用，在 Linux 下是可以正常使用的，决定尝试一下另一位大佬编写的 coc.nvim 工具。安装成功之后，通过 CocInstall coc-pylsp 安装插件的时候一直提示 “- ✗ coc-pylsp Bad response from https://re...",
    "content": "YouCompleteMe 在Windows 虽然编译成功了，但是打开 gvim 的时候会提示 utf8 错误，导致我无法正常使用，在 Linux 下是可以正常使用的，决定尝试一下另一位大佬编写的 coc.nvim 工具。安装成功之后，通过 CocInstall coc-pylsp 安装插件的时候一直提示 “- ✗ coc-pylsp Bad response from https://registry.npmjs.org/coc-pylsp: 404”。检查日志发现以下错误（后来发现是这个 pylsp 的问题，安装其他组件是可以的）：2024-07-25T11:04:45.239 INFO (pid:24988) [plugin] - coc.nvim initialized with node: v20.11.0 after 1892024-07-25T11:04:55.523 INFO (pid:24988) [attach] - receive notification: installExtensions [ 'coc-pylsp' ]2024-07-25T11:04:57.207 ERROR (pid:24988) [model-fetch] - Fetch error for https://registry.npmjs.org/coc-pylsp: {  method: 'GET',  hostname: 'registry.npmjs.org',  port: 443,  path: '/coc-pylsp',  agent: null,  rejectUnauthorized: true,  maxRedirects: 3,  headers: {    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64)',    'Accept-Encoding': 'gzip, deflate'  },  timeout: 10000,  buffer: true} Error: Bad response from https://registry.npmjs.org/coc-pylsp: 404这个虽然很明显是 npm 镜像源的问题，检查我的 npm npm.cmd config list 源其实早就修改为国内的阿里镜像源，为什么这里还是没有使用的 npmjs 源呢，原来 coc 的镜像源需要在 “coc.nvim/build/index.js” 文件中修改才行。将以下两处位置修改为 https://registry.npmmirror.com 之后重启 gvim 会使用新的 npm 源。 后续验证虽然使用了新的镜像源，也可以正常下载代码，不过无法通过 md5 校验。所以还是挂梯子吧。后面发现安装其他 coc 支持的时候是可以正常下载的，感觉就是部分软件包存在问题。coc.nvim/build/index.js:65639:  return res ?? new import_url3.URL(\"https://registry.npmjs.org\");coc.nvim/build/index.js:65850:        let etagAlgorithm = url.startsWith(\"https://registry.npmjs.org\") ? \"md5\" : void 0;后面发现 wiki 中有提到怎么修改源：Using custom registryYou can customize npm registry for coc.nvim by add coc.nvim:registry in the file ~/.npmrc:coc.nvim:registry=https://registry.npmjs.org/YouCompleteMe 在启动时会提示以下错误，如果那位大哥知道怎么处理，麻烦告诉我一下：## YouCompleteMe 是编译成功的，文件也是指定了 utf8 不知道为什么一直提示这个错误\"\\Users\\XXX\\.vim\\vim-init\\init\\init-plugins.vim\" 762L, 26175BTraceback (most recent call last):  File \"\", line 42, in &lt;module&gt;  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\python\\ycm\\youcompleteme.py\", line 111, in __init__    self._SetUpServer()  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\python\\ycm\\youcompleteme.py\", line 204, in _SetUpServer    python_interpreter = paths.PathToPythonInterpreter()                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\python\\ycm\\paths.py\", line 49, in PathToPythonInterpreter    python_interpreter = _PathToPythonUsedDuringBuild()                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\python\\ycm\\paths.py\", line 77, in _PathToPythonUsedDuringBuild    return utils.ReadFile( filepath ).strip()           ^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\third_party\\ycmd\\ycmd\\utils.py\", line 86, in ReadFile    return f.read()           ^^^^^^^^  File \"&lt;frozen codecs&gt;\", line 322, in decodeUnicodeDecodeError: 'utf-8' codec can't decode byte 0xcd in position 9: invalid continuation byte"
  },
  
  {
    "title": "vim 复制命令行模式下的内容 并重定向当前文件中",
    "url": "/posts/vim-%E5%A4%8D%E5%88%B6%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E5%86%85%E5%AE%B9-%E5%B9%B6%E9%87%8D%E5%AE%9A%E5%90%91%E5%BD%93%E5%89%8D%E6%96%87%E4%BB%B6%E4%B8%AD/",
    "categories": "Vim, 复制粘贴",
    "tags": "Vim",
    "date": "2024-07-24 11:43:41 +0800",
    





    
    "snippet": "有的时候在 vim 中查看一个变量当前值，我想要查看当前 gvim 的字体是什么。:set guifont? 显示当前 gvim 的字体设置，我想要复制保存当前值，但是使用鼠标选中之后也无法直接复制。虽然可以使用一些带有 OCR 功能的工具，但是有的时候也会出现识别错误的情况。有没有什么办法可以将结果保存在寄存器或者直接重定向输出到当前文件中呢，查阅了相关资料有如下办法：在 Vim 中，可以...",
    "content": "有的时候在 vim 中查看一个变量当前值，我想要查看当前 gvim 的字体是什么。:set guifont? 显示当前 gvim 的字体设置，我想要复制保存当前值，但是使用鼠标选中之后也无法直接复制。虽然可以使用一些带有 OCR 功能的工具，但是有的时候也会出现识别错误的情况。有没有什么办法可以将结果保存在寄存器或者直接重定向输出到当前文件中呢，查阅了相关资料有如下办法：在 Vim 中，可以使用寄存器来捕获和显示命令输出。以下是将命令行模式下的结果复制到剪贴板或者直接在 Vim 编辑文本中显示的几种方法。将命令输出复制到剪贴板  使用 :redir 将命令输出重定向到寄存器。  在 :redir 之后插入命令。  结束重定向。  将结果复制到剪贴板。:redir @+:set guifont?:redir END这将 :set guifont? 命令的输出重定向到 + 寄存器（系统剪贴板）。将命令输出显示在编辑文本中  使用 :redir 将命令输出重定向到寄存器。  在 :redir 之后插入命令。  结束重定向。  粘贴寄存器内容到当前缓冲区。:redir @a:set guifont?:redir END:put a这将 :set guifont? 命令的输出重定向到 a 寄存器，并将其内容插入到当前缓冲区。使用命令模式插入输出也可以使用 :execute 和 :put 命令来直接插入命令的输出到编辑文本中：:put =execute('set guifont?')将命令输出复制到寄存器并插入到文本中如果你需要将命令输出插入到光标所在位置，可以使用以下命令：:redir @\":set guifont?:redir END:normal! p这将 :set guifont? 命令的输出重定向到无名寄存器（\"），并将其粘贴到光标所在位置。示例假设你想查看当前的字体并将结果插入到当前编辑的文件中，可以按以下步骤操作：      打开命令行模式并输入以下命令：    :redir @a:set guifont?:redir END:put a      这将 :set guifont? 命令的输出重定向到 a 寄存器，并将其插入到当前缓冲区中。通过使用 :redir 命令和寄存器，可以轻松地将 Vim 中命令的输出复制到剪贴板或者插入到编辑文本中。这种方法非常灵活，可以用于各种需要捕获和处理命令输出的场景。"
  },
  
  {
    "title": "WSL2 运行 gui 程序",
    "url": "/posts/WSL2-%E8%BF%90%E8%A1%8C-gui-%E7%A8%8B%E5%BA%8F/",
    "categories": "Windows, WSL",
    "tags": "WSL",
    "date": "2024-07-23 18:08:00 +0800",
    





    
    "snippet": "WSL的配置可以参考这里在 Windows 下开启 WSL2 已经可以正常运行 gui 程序了，也不需要在 WSL 中安装桌面环境。正常需要做的就是更新 WSL 就可以运行：wsl --list -v   //显示正在运行的wslwsl --shutdown   // 关闭正在运行的wslwsl --update     //更新到最新的wslwsl --versionWSL 版本： 2.2...",
    "content": "WSL的配置可以参考这里在 Windows 下开启 WSL2 已经可以正常运行 gui 程序了，也不需要在 WSL 中安装桌面环境。正常需要做的就是更新 WSL 就可以运行：wsl --list -v   //显示正在运行的wslwsl --shutdown   // 关闭正在运行的wslwsl --update     //更新到最新的wslwsl --versionWSL 版本： 2.2.4.0内核版本： 5.15.153.1-2WSLg 版本： 1.0.61MSRDC 版本： 1.2.5326Direct3D 版本： 1.611.1-81528511DXCore 版本： 10.0.26091.1-240325-1447.ge-releaseWindows 版本： 10.0.22631.3880然后在 WSL 运行 gui 程序即可：wsl -d fedora --cd ~gvim ## 正常来说到这一步就可以了如果抛出以下报错：wxj@TheDarkStar:~$ gvimE233: Cannot open displayPress ENTER or type command to continueE852: The child process failed to start the GUIPress ENTER or type command to continue检查 echo $DISPLAY ，输出的值必须为 :0，否则请修改 export DISPLAY=:0：┌─[wxj@TheDarkStar]─[/data/myself-blog]└──╼ $ echo $DISPLAY:0再次尝试还是提示E233: Cannot open display的话继续检查 X11 display socket：如果结果不和截图上的一致，按照以下方法修改：sudo rm -r /tmp/.X11-unixln -s /mnt/wslg/.X11-unix /tmp/.X11-unix修改之后应该就可以正常使用 WSL 中的 gui 程序了。"
  },
  
  {
    "title": "修改 npm 镜像源",
    "url": "/posts/%E4%BF%AE%E6%94%B9-npm-%E9%95%9C%E5%83%8F%E6%BA%90/",
    "categories": "Vim, npm",
    "tags": "npm",
    "date": "2024-07-23 17:45:15 +0800",
    





    
    "snippet": "在编译 YouCompleteMe 的时候遇到 npm 的错误，再此记录一下：(xxx@TheDarkStar):10 &gt; python install.py --allSetting up TSserver for TypeScript completion...npm WARN config production Use `--omit=dev` instead.npm ERR! ...",
    "content": "在编译 YouCompleteMe 的时候遇到 npm 的错误，再此记录一下：(xxx@TheDarkStar):10 &gt; python install.py --allSetting up TSserver for TypeScript completion...npm WARN config production Use `--omit=dev` instead.npm ERR! code ECONNRESETnpm ERR! syscall readnpm ERR! errno -4077npm ERR! network read ECONNRESETnpm ERR! network This is a problem related to network connectivity.npm ERR! network In most cases you are behind a proxy or have bad network settings.npm ERR! networknpm ERR! network If you are behind a proxy, please make sure that thenpm ERR! network 'proxy' config is set properly.  See: 'npm help config'  FAILEDnpm config list 查看 npm 配置信息按照信息提示尝试设置取消代理：## 查看镜像源npm config get registry## 关闭代理npm config set proxy false## 关闭代理henpm cache clean&lt;# 如果遇到以下错误，带上 --force  选项npm关闭代理 of npm@5, the npm cache self-heals from corruption issuesnpm ERR!   by treating integrity mismatches as cache misses.  As a result,npm ERR!   data extracted from the cache is guaranteed to be valid.  If younpm ERR!   want to make sure everything is consistent, use `npm cache verify`npm ERR!   instead.  Deleting the cache can only make npm go slower, and isnpm ERR!   not likely to correct any problems you may be encountering!npm ERR!npm ERR!   On the other hand, if you're debugging an issue with the installer,npm ERR!   or race conditions that depend on the timing of writing to an emptynpm ERR!   cache, you can use `npm install --cache /tmp/empty-cache` to use anpm ERR!   temporary cache instead of nuking the actual one.npm ERR!npm ERR!   If you're sure you want to delete the entire cache, rerun this commandnpm ERR!   with --force.#&gt;npm cache clean --force如果还是报错，可以尝试修改镜像源为阿里的镜像源：npm cache clean --forcenpm config set registry https://registry.npmmirror.comcd ~\\.vim\\bundles\\YouCompleteMepython install.py --all## 不要使用淘宝的源，网上很多旧的文章使用是这个源，npm config set registry https://registry.npm.taobao.org## 但是这个源已经停止维护了，现在也无法访问了，否则会遇到如下错误"
  },
  
  {
    "title": "git 设置、取消代理",
    "url": "/posts/git-%E8%AE%BE%E7%BD%AE-%E5%8F%96%E6%B6%88%E4%BB%A3%E7%90%86/",
    "categories": "Git, Proxy",
    "tags": "Git",
    "date": "2024-07-23 17:21:51 +0800",
    





    
    "snippet": "在 Windows 环境中，有的时候即便挂了梯子使用 Git 工具的时候也会遇到“fatal: unable to access ‘https://github.com/…/.git‘: Recv failure Connection was rese”错误，虽然大部分时间都可以正常运行。可以尝试以下几种方式：清理 Git 代理可以尝试清除 Git 的代理设置，让其直接连接网络进行操作。gi...",
    "content": "在 Windows 环境中，有的时候即便挂了梯子使用 Git 工具的时候也会遇到“fatal: unable to access ‘https://github.com/…/.git‘: Recv failure Connection was rese”错误，虽然大部分时间都可以正常运行。可以尝试以下几种方式：清理 Git 代理可以尝试清除 Git 的代理设置，让其直接连接网络进行操作。git config --global --unset http.proxy git config --global --unset https.proxy配置 Windows 系统代理如果取消了代理设置还是报错，也可以尝试设置系统代理，按下 win+q 组合键之后，输入“代理服务器设置”，点击“编辑”：记得勾选“请勿将代理服务器用于本地(Intranet)地址”，端口随便选择一个没有使用的端口就行，然后保存：终端设置 git 代理：git config --global http.proxy http://127.0.0.1:32345检查配置：git config --global -l## git config --list检查梯子也有可能是因为梯子的节点出现了问题，可以刷新/更改节点试试。如果使用的梯子支持全局和部分路由代理的功能，可以尝试切换为全局代理模式。"
  },
  
  {
    "title": "vim-plug 异常处理",
    "url": "/posts/vim-plug-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/",
    "categories": "Vim, Plugin",
    "tags": "Vim",
    "date": "2024-07-19 16:39:51 +0800",
    





    
    "snippet": "要想使用 vim 的体验更好，离不开大量的插件加持。有不少的管理插件的工具，个人使用的是 vim-plug ， 用于管理日常 vim 的各种插件在 Windows 下一般的终端工具都是使用 cmd.exe ，不过太难用了， 还是建议使用功能更加强大的 PowerShell ，现在PowerShell 也支持跨平台，需要注意的是 Windows PowerShell 和 PowerShell ...",
    "content": "要想使用 vim 的体验更好，离不开大量的插件加持。有不少的管理插件的工具，个人使用的是 vim-plug ， 用于管理日常 vim 的各种插件在 Windows 下一般的终端工具都是使用 cmd.exe ，不过太难用了， 还是建议使用功能更加强大的 PowerShell ，现在PowerShell 也支持跨平台，需要注意的是 Windows PowerShell 和 PowerShell 是两种东西，其中 PowerShell 是开源的，并且跨平台。感兴趣的可以 google 了解。vim9 已经支持 terminal 了，不过默认还是调用的是 cmd.exe ，可以在命令模式下查看当前使用的 shell 终端是什么。:echo &amp;shell ，在 Windows 平台下还是建议使用 Powershell ，虽然对比 bash ，PowerShell 命令又臭又长，不过还是功能还是很强大了，维护起来比 Shell 脚本方便很多。因为命令大多数一看就知道什么意思，这个是题外话了，虽然我还是更加喜欢简短的 Shell ，维护的时候另说。。为了在 vim9 中更好的使用 PowerShell，我在 vimrc 中将 shell 指定为 pwsh.exe，一切看起来变得更好了。知道我需要安装新的插件和查看插件状态的时候，发生了意外。vim-plug 无法正常工作了，最初以为是权限问题，但是 Temp 目录是所有用户都可以访问的。在网上查了一圈都没找到原因，突然想起来难道是 cmd 的原因，查看了一下 vim-plug的代码，发现果然是调用的 cmd.exe解决办法就是在 vim 中指定 set shell=cmd.exe， 或者 vimrc 文件中删除 shell 的配置，重启 vim 或者重新加载配置文件就可以正常使用 vim-plug 了。"
  },
  
  {
    "title": "Oracle DB_NAME、SERVICE_NAME、SID、INSTANCE_NAME、DB_UNIQUE_NAME的区别",
    "url": "/posts/Oracle-DB_NAME-SERVICE_NAME-SID-INSTANCE_NAME-DB_UNIQUE_NAME%E7%9A%84%E5%8C%BA%E5%88%AB/",
    "categories": "DataBase, Oracle",
    "tags": "Oracle",
    "date": "2024-07-18 16:41:47 +0800",
    





    
    "snippet": "DB_NAME：①是数据库名，长度不能超过8个字符，记录在datafile、redolog和control file中②在DataGuard环境中DB_NAME相同而DB_UNIQUE_NAME不同③在RAC环境中，各个节点的DB_NAME 都相同，但是INSTANCE_NAME不同④DB_NAME还在动态注册监听的时候起作用，无论是否定义了SERVICE_NAME,PMON进程都会使用DB...",
    "content": "DB_NAME：①是数据库名，长度不能超过8个字符，记录在datafile、redolog和control file中②在DataGuard环境中DB_NAME相同而DB_UNIQUE_NAME不同③在RAC环境中，各个节点的DB_NAME 都相同，但是INSTANCE_NAME不同④DB_NAME还在动态注册监听的时候起作用，无论是否定义了SERVICE_NAME,PMON进程都会使用DB_NAME动态注册监听DBID：①DBID可以看做是DB_NAME在数据库内部的表示，它是在数据库创建的时候用DB_NAME结合算法计算出来的②它存在于datafile和control file中，用来表示数据文件的归属，所以DBID是唯一的，对于不同的数据库，DB_NAME可以是相同的，但是DBID一定是唯一的，例如在DataGuard中，主备库的DB_NAME相同，但是DBID一定不同（看过一个很形象的例子，就是可以有同名的人，但是身份证号码一定不同）DB_UNIQUE_NAME：①在DataGuard中，主备库拥有相同的DB_NAME，为了区别，就必须有不同的DB_UNIQUE_NAME②DB_UNIQUE_NAME在DG中会影响动态注册的SERVICE_NAME，即如果采用的是动态注册，则注册的SERVICE_NAME为DB_UNIQUE_NAME，但是实例还是INSTANCE_NAME，即SIDINSTANCE_NAME：①数据库实例的名称，INSTANCE_NAME默认值是SID，一般情况下和数据库名称（DB_NAME)相同，也可不同②initSID.ora 和orapwSID 文件要与INSTANCE_NAME保持一致③INSTANCE_NAME会影响进程的名称SID：①是操作系统中的环境变量，和ORACLE_HOME,ORACLE_BASE用法相同②在操作系统中要想得到实例名，就必须使用ORACLE_SID。且ORACLE_SID必须与INSTANCE_NAME的值一致SERVICE_NAME：①数据库和客户端相连是使用的服务名②在DataGuard中，如果采用动态注册，建议在主备库使用相同的service_names③在DataGuard中，如果采用静态注册，建议在主备库上的listener中输入相同的服务名(service_name)④如果采监听采用了静态注册，那么SERVICE_NAME就等于Listener.ora文件中的GLOBAL_DATABASE_NAME的值GLOBAL_DATABASE_NAME：①GLOBAL_DATABASE_NAME 是listener配置的对外网络连接名称，可以是任意值②在客户端配置监听的tnsnames.ora 文件中的service_name与这个GLOBAL_DBNAME 保持一致就可以了③配置静态监听注册时，需要输入SID和GLOBAL_NAME"
  },
  
  {
    "title": "Oracle 修改 db_name",
    "url": "/posts/Oracle-%E4%BF%AE%E6%94%B9-db_name/",
    "categories": "DataBase, Oracle",
    "tags": "Oracle",
    "date": "2024-07-18 16:39:03 +0800",
    





    
    "snippet": "有的时候恢复Oracle数据到另一个环境中之后，需要修改相关的实例名、服务名、数据库名等，方便区分不同的环境。以下操作的前提是数据已经恢复到新的环境，在新的环境中修改db_name。仅修改server_name如果仅修改server_name可以直接登录数据库之后操作；sqlplus sys/sys as sysdba SQL&gt; show parameter service_nameS...",
    "content": "有的时候恢复Oracle数据到另一个环境中之后，需要修改相关的实例名、服务名、数据库名等，方便区分不同的环境。以下操作的前提是数据已经恢复到新的环境，在新的环境中修改db_name。仅修改server_name如果仅修改server_name可以直接登录数据库之后操作；sqlplus sys/sys as sysdba SQL&gt; show parameter service_nameSQL&gt; alter system set service_names='orcl' scope=both;--  修改listener.ora 文件中的服务名：SID_LIST_LISTENER =  (SID_LIST =    (SID_DESC =      (SID_NAME = PLSExtProc)      (ORACLE_HOME = E:\\Oracle10g)      (PROGRAM = extproc)    )   (SID_DESC =    (GLOBAL_DBNAME = ORCL)    (ORACLE_HOME = E:\\Oracle10g)    (SID_NAME = ORCL) ##修改server name    ) )LISTENER =  (DESCRIPTION_LIST =    (DESCRIPTION =      (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1))      (ADDRESS = (PROTOCOL = TCP)(HOST = onest)(PORT = 1521))    )  )修改db_name假设已经恢复数据，并且启动了实例，至少处于mount状态，否则无法备份控制文件。此时先不要修改参数文件或者ORACLE_SID信息，不然重启之后会提示错误备份控制文件SQL&gt;  alter database backup controlfile to trace as '/tmp/control.ctl';修改备份的控制文件，备份的控制文件中有两条创建控制文件的提示。根据需求操作， Set #1. NORESETLOGS case 和 Set #2. RESETLOGS case 两个方法因为恢复的数据时候我已经restlogs恢复了，所以此时我只需要重建控制文件即可## 如果需要移动数据文件/表空间目录，可以一并在控制文件重建语句中修改了，vim /tmp/control.ctl-- 如果不需要修改其他参数的话可以直接从spfile启动，不需要单独指定pfile nomount-- STARTUP NOMOUNT--CREATE CONTROLFILE REUSE  修改为 CREATE CONTROLFILE SETCREATE CONTROLFILE SET DATABASE \"db_name\" RESETLOGS  ARCHIVELOG    MAXLOGFILES 16    MAXLOGMEMBERS 3    MAXDATAFILES 100    MAXINSTANCES 8    MAXLOGHISTORY 584LOGFILE  GROUP 1 '/home/u01/app/oracle/oradata/ORACLE_SID/redo01.log'  SIZE 500M BLOCKSIZE 512,  GROUP 2 '/home/u01/app/oracle/oradata/ORACLE_SID/redo02.log'  SIZE 500M BLOCKSIZE 512,  GROUP 3 '/home/u01/app/oracle/oradata/ORACLE_SID/redo03.log'  SIZE 500M BLOCKSIZE 512-- STANDBY LOGFILEDATAFILE  '/home/u01/app/oracle/oradata/ORACLE_SID/system01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/sysaux01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/undotbs01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/users01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/htxt01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace02.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace03.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace04.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace05.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename02.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename03.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename04.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/undotbs02.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/undotbs03.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/sysaux02dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename05.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename06.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename07.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename08.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename09.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename10.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename11.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename12.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename13.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename14.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace15.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename15.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename16.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename17.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace06.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace07.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace08.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename18.dbf ', -- 需要注意有可能前期运维人员创建数据文件的时候并不规范，或者复制粘贴的时候多了几个空格，不要手抖删了空格  -- 。。。。  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename44.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename45.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename46.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename47.dbf'CHARACTER SET AL32UTF8;-- RECOVER DATABASE USING BACKUP CONTROLFILE;修改pfile如果需要修改其他参数的话可以此时一并修改了，例如server_name 、 db_name等create pfile='/tmp/pfile.ora' from spfile;修改pfilevim /tmp/pfile.ora## 多个控制文件使用逗号隔开*.control_files='ctl1','ctl2' *.server_name=''*.db_name=''# *.instance_name='' # 实例名不需要修改，和ORACLE_SID的值是一一对应的停止/启动数据库至如果需要修改instance_name，需要在启动之前修改ORACLE_SID, export ORACLE_SID='XXX'shutdown IMMEDIATE-- 如果需要移动数据文件目录/表空间路径，此时停库之后可以移动到新目录，如果需要修改 instance_name，此时可以退出 sqlplus 修改 ORACLE_SID 之后在重新连接 sqlplus-- $ORACLE_HOME/dbs/init$ORACL_SID.ora 使用上文重新修改之后的pfile文件，也可以备份ora文件之后覆盖源ora文件，startup nomount pfile='initxxx.ora';@/tmp/contrl.ctl-- SQL&gt; alter database mount;SQL&gt; show parameter name--  检查文件头SQL&gt; select file#,status,checkpoint_change# from v$datafile_header;set num 20SQL&gt; select distinct checkpoint_change# from v$datafile_header;-- SQL&gt; alter database open ;SQL&gt; alter database open resetlogs;-- 检查日志show parameter diag修改监听如果修改了服务名，记得修改监听文件中的server_name"
  },
  
  {
    "title": "MySQL 批量杀会话",
    "url": "/posts/MySQL-%E6%89%B9%E9%87%8F%E6%9D%80%E4%BC%9A%E8%AF%9D/",
    "categories": "DataBase, MySQL",
    "tags": "MySQL",
    "date": "2024-07-13 00:39:23 +0800",
    





    
    "snippet": "MySQL的kill语法如下：-- 可以查看帮助手册help kill;KILL [CONNECTION | QUERY] processlist_id;KILL CONNECTION 与不带修饰符的 KILL 相同：它在终止连接正在执行的任何语句后终止与给定 processlist_id 关联的连接。会使对应的会话断开连接。KILL QUERY 终止连接当前正在执行的语句，但保持会话连接。...",
    "content": "MySQL的kill语法如下：-- 可以查看帮助手册help kill;KILL [CONNECTION | QUERY] processlist_id;KILL CONNECTION 与不带修饰符的 KILL 相同：它在终止连接正在执行的任何语句后终止与给定 processlist_id 关联的连接。会使对应的会话断开连接。KILL QUERY 终止连接当前正在执行的语句，但保持会话连接。processlist_id 可以通过 show [full] processlist 或者 performance_schema.threads 的 PROCESSLIST_ID 字段获取，也可以根据 information_schema.processlist 的 ID 字段获取。有的时候需要按照用户或者其他条件批量kill session 。可以参考以下语句：SELECT GROUP_CONCAT(CONCAT('KILL ',id,';') SEPARATOR ' ') 'Paste the following query to kill all processes' FROM information_schema.processlist WHERE user&lt;&gt;'system user'\\GSELECT GROUP_CONCAT(CONCAT('KILL ',PROCESSLIST_ID,';') SEPARATOR ' ') 'Paste the following query to kill all processes' FROM performance_schema.threads WHERE PROCESSLIST_USER&lt;&gt;'system user'\\G需要注意的是，kill session 之后，线程可能需要一些时间才能死掉/结束，如果查询show processlist 的 Command 字段状态为 killed ，有可能是因为会话正在回滚。还有的情况是实例存在异常，可以检查 error log，如果 innodb_buffer_pool_size 设置过小，遇到过一次客户安装的时候采用的默认配置，innodb_buffer_pool_size 只有1G左右，整个服务器的内存16G，有点离谱。在 error log 中会提示如下错误2024-07-04T10:35:05.757216+08:00 4736 [Warning] [MY-011959] [InnoDB] Difficult to find free blocks in the buffer pool (192308 search iterations)! 192308 failed attempts to flush a page! Consider increasing the buffer pool size. It is also possible that in your Unix version fsync is very slow, or completely frozen inside the OS kernel. Then upgrading to a newer version of your operating system may help. Look at the number of fsyncs in diagnostic info below. Pending flushes (fsync) log: 0; buffer pool: 0. 31142769 OS file reads, 77384027 OS file writes, 35847289 OS fsyncs. Starting InnoDB Monitor to print further diagnostics to the standard output.将参数值调整之后很快就恢复正常，这里先不介绍该参数重点是怎么批量 kill session ，后续在讨论参数设置。"
  },
  
  {
    "title": "Linux 批量替换文件夹下面的 Windows 换行符替换为 unix 风格换行符",
    "url": "/posts/Linux-%E6%89%B9%E9%87%8F%E6%9B%BF%E6%8D%A2%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E9%9D%A2%E7%9A%84Windows%E6%8D%A2%E8%A1%8C%E7%AC%A6%E6%9B%BF%E6%8D%A2%E4%B8%BAunix%E9%A3%8E%E6%A0%BC%E6%8D%A2%E8%A1%8C%E7%AC%A6/",
    "categories": "Linux, Bash",
    "tags": "Shell",
    "date": "2024-07-09 23:26:34 +0800",
    





    
    "snippet": "在Linux系统中，Windows风格的换行符（\\r\\n，即回车加换行）和Unix风格的换行符（\\n）是不同的。Windows系统中的文本文件在Linux中可能会显示为带有^M字符的文件，这是因为^M是回车符（CR，Carriage Return）的表示方式。有的时候将Linux中的文件或者Windows的文件互相拷贝的时候会自动转换换行符，经常遇到的情况是Windows下面可以正常运行一些...",
    "content": "在Linux系统中，Windows风格的换行符（\\r\\n，即回车加换行）和Unix风格的换行符（\\n）是不同的。Windows系统中的文本文件在Linux中可能会显示为带有^M字符的文件，这是因为^M是回车符（CR，Carriage Return）的表示方式。有的时候将Linux中的文件或者Windows的文件互相拷贝的时候会自动转换换行符，经常遇到的情况是Windows下面可以正常运行一些unix风格的脚本，但是Linux中却无法运行Windows dos风格的文件。要将一个文件夹中所有文件的Windows换行符替换为Unix风格的换行符，可以使用find命令结合sed或dos2unix工具来完成。以下是几种方法：  使用find和sed:     find /path/to/folder -type f -exec sed -i 's/\\r$//' {} +        这里/path/to/folder是你的文件夹路径。这个命令会找到该文件夹下所有的文件（不包括子文件夹中的文件），并使用sed命令删除每行末尾的^M字符。    使用find和dos2unix: 如果你的系统中安装了dos2unix工具，可以使用以下命令：     find /path/to/folder -type f -exec dos2unix {} +        dos2unix会将Windows格式的文本文件转换为Unix格式。    使用find和unix2dos: 如果你只有unix2dos工具，可以反向使用它来去除^M：     find /path/to/folder -type f -exec unix2dos -n {} {}.unix2dos \\; &amp;&amp; mv {} {}.unix2dos        这个命令首先创建一个临时文件，然后使用unix2dos将Unix格式转换为Windows格式，这会去掉每行末尾的^M。之后，使用mv命令将临时文件替换原文件。    使用fromdos: 在某些Linux发行版中，fromdos是一个可以用来转换文件的工具：     find /path/to/folder -type f -exec fromdos {} \\;      ***需要注意，使用`sed`的`-i`选项会直接修改原文件，所以在执行之前最好备份你的数据。另外，如果文件夹中包含子文件夹，并且你也希望递归地转换子文件夹中的文件，要修改`find`命令来包括`-depth`参数或相应地调整命令。***如果只有一个文件或者文件少的话也可以直接通过一些文本编辑器自带的转换功能。如果使用vim/gvim的话可以在命令行模式使用以下方法转换：## 查看当前换行符:set ff## 替换为Linux:set ff=unix## 替换为Windows:e +iff=dos"
  },
  
  {
    "title": "配置python jupyter 远程访问",
    "url": "/posts/%E9%85%8D%E7%BD%AEpython-jupyter%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/",
    "categories": "Python, jupyter",
    "tags": "Python",
    "date": "2024-07-02 17:00:00 +0800",
    





    
    "snippet": "概述Jupyter Notebook是一种可共享的文档，它结合了计算机代码、简单语言描述、数据、丰富的可视化效果（如 3D 模型、图表、图形和图形）以及交互式控件。笔记本和编辑器（如 JupyterLab）提供了一个快速的交互环境，用于原型设计和解释代码、探索和可视化数据以及与他人分享想法简而言之，Jupyter Notebook是以网页的形式打开，相当于一个网页版便携式的python 代码...",
    "content": "概述Jupyter Notebook是一种可共享的文档，它结合了计算机代码、简单语言描述、数据、丰富的可视化效果（如 3D 模型、图表、图形和图形）以及交互式控件。笔记本和编辑器（如 JupyterLab）提供了一个快速的交互环境，用于原型设计和解释代码、探索和可视化数据以及与他人分享想法简而言之，Jupyter Notebook是以网页的形式打开，相当于一个网页版便携式的python 代码工具，可以在网页页面中可以直接编写代码和运行代码，代码的运行结果也会直接在代码块下显示。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。配置python虚拟开发环境安装jupyter最好先指定一个虚拟开发环境，避免污染全局的配置。怎么配置python的虚拟开发环境可以参考这里┌─[✗]─[wxj@devC]─[/data/Python]└──╼ $ python3 -VPython 3.11.2┌─[wxj@devC]─[/data/Python]└──╼ $ python3 -m venv pyenv┌─[wxj@devC]─[/data/Python]└──╼ $┌─[wxj@devC]─[/data/Python]└──╼ $ source pyenv/bin/activate ## pyenv/bin/activate 实际就是一个文本文件，可以直接查看执行逻辑(pyenv) ┌─[wxj@devC]─[/data/Python] ## 这里(pyenv)就表示当前的开发环境是刚才创建的虚拟开发环境└──╼ $## 配置好之后可以直接查看当前的python信息(pyenv) ┌─[wxj@devC]─[/data/Python]└──╼ $ python -VPython 3.11.2(pyenv) ┌─[wxj@devC]─[/data/Python]└──╼ $ pip -Vpip 23.0.1 from /data/Python/pyenv/lib/python3.11/site-packages/pip (python 3.11)(pyenv) ┌─[wxj@devC]─[/data/Python]└──╼ $ pip listPackage    Version---------- -------pip        23.0.1setuptools 66.1.1(pyenv) ┌─[wxj@devC]─[/data/Python]└──╼ $安装 jupyter notebook## pip install jupyter## 指定下载源为清华源pip install -i https://pypi.tuna.tsinghua.edu.cn/simple jupyterpip list## 安装完成之后可以查看帮助说明，大概了解使用命令jupyter notebook --help使用 jupyter notebook启动启动 jupyter notebook就比较简单了，可以直接不带任何参数启动。默认是127.0.0.1:8888，如果8888端口被占用，会使用其他端口，例如8889。使用本地浏览器打开对应的地址即可。jupyter notebook## 如果使用root用户启动的话，需要添加参数 --allow-rootjupyter notebook --allow-root停止直接使用crtl+c就可以退出。这里需要输入‘y’才会退出，如果超过5s没有输入，则会继续运行。终端关闭或者终止jupyter进程，jupyter notebook也就退出了，无法继续使用浏览器访问。可以使用nohup的方式后台运行程序：nohup jupyter notebook &amp;&gt; notebook.log &amp;也可以使用screen等工具在后台运行，防止终端异常断开之后无法继续使用。很多时候程序都是部署在远程的，需要通过连接的方式访问，jupyter notebook 默认是通过本地访问的。配置远程访问jupyter设置密码先输入python3进入交互模式，输入密码，需要注意的是交互输入的原文密码在终端是不会显示的。如果不想交互输入密码也可以直接将密码写在函数中：passwd('passwd')如果想指定加密方式为sha1：passwd('passwd',algorithm='sha1')生成配置文件在终端输入执行以下命令：jupyter notebook --generate-config执行成功就会自动在根目录下生成文件（~/.jupyter/jupyter_notebook_config.py）,这里可以用vim或者其他文本编辑器编辑就行。这个文件的内容默认都是注释掉的。除了红框中的这一行。修改配置文件可以直接在文件末尾添加自己的配置参数，保险起见可以先备份一份原始文件。## 这里的{,.bak}表示逗号前的内容都相同，\".bak\"表示后缀/多余的字符，在操作文件名很长的时候可以节约tab或者手写的频率，相当于## cp ~/.jupyter/jupyter_notebook_config.py  ~/.jupyter/jupyter_notebook_config.py.bakcp ~/.jupyter/jupyter_notebook_config.py{,.bak}## 添加以下内容c.NotebookApp.ip='*' # 如果这里修过过后启动服务报错 则修改为c.NotebookApp.ip='0.0.0.0'c.NotebookApp.password=u'argon2:$argon2id$v=19$m=10240,t=10,p=8$YPy6gq6WBGap+NHlZAMZow$IR1WDR20vmzV+MzuRkwl3NRYH1AoKsIZjYKsdclJM' #就之前保存的验证密码c.NotebookApp.open_browser =False # 设置是否自动打开浏览器，如果是远程的服务器可以关闭这个选项c.NotebookApp.port =4000  # 设置监听端口c.NotebookApp.allow_remote_access = True ## 允许远程访问c.NotebookApp.notebook_dir='work_dir' # 设置工作/根路径，如果不设置默认是启动jupyter命令时的目录保存退出之后运行jupyter即可。远程访问jupyternohup jupyter notebook &amp;&gt; notebook.log &amp;启动以后在本机的浏览器 输入http://{服务器ip}:port 进行访问。如果远程服务器或者云服务器配置了防火墙，记得打开白名单。打开之后输入之前设置的密码即可。之后就可以在浏览器中利用jupyter运行调试代码了。"
  },
  
  {
    "title": "配置pip镜像源",
    "url": "/posts/%E9%85%8D%E7%BD%AEpip%E9%95%9C%E5%83%8F%E6%BA%90/",
    "categories": "Python, pip",
    "tags": "Python",
    "date": "2024-07-01 17:00:00 +0800",
    





    
    "snippet": "很多时候pip下载安装包的时候都比较慢，可以直接指定为国内的镜像源，提高下载速度。## 查看当前的镜像源pip config list ## 国外镜像有时候下载较慢，可以直接指定国内镜像源下载pip install -i https://pypi.douban.com/simple/ flask## 修改pip的配置文件，将镜像源写入配置文件中。如果没有这个文件就新建一个cat ~/.pip...",
    "content": "很多时候pip下载安装包的时候都比较慢，可以直接指定为国内的镜像源，提高下载速度。## 查看当前的镜像源pip config list ## 国外镜像有时候下载较慢，可以直接指定国内镜像源下载pip install -i https://pypi.douban.com/simple/ flask## 修改pip的配置文件，将镜像源写入配置文件中。如果没有这个文件就新建一个cat ~/.pip/pip.conf[global]index-url = https://pypi.douban.com/simple/## 清华大学源cat ~/.pip/pip.conf[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = https://pypi.tuna.tsinghua.edu.cn"
  },
  
  {
    "title": "WSL Fedora 升级",
    "url": "/posts/WSL-Fedora-%E5%8D%87%E7%BA%A7/",
    "categories": "Linux, Fedora",
    "tags": "WSL",
    "date": "2024-06-27 16:00:00 +0800",
    





    
    "snippet": "Windows11 WSL Fedora 版本升级可以直接使用dnf update，使用如下命令：sudo dnf update --releasever=40 -y    本次升级基于Fedora 39版本，如需要升级到其它版本，将上述命令的–releasever变更为其它版本即可。等待更新完成之后检查。",
    "content": "Windows11 WSL Fedora 版本升级可以直接使用dnf update，使用如下命令：sudo dnf update --releasever=40 -y    本次升级基于Fedora 39版本，如需要升级到其它版本，将上述命令的–releasever变更为其它版本即可。等待更新完成之后检查。"
  },
  
  {
    "title": "vim 安装",
    "url": "/posts/vim-%E5%AE%89%E8%A3%85/",
    "categories": "Vim, Install",
    "tags": "Vim",
    "date": "2024-06-25 16:00:00 +0800",
    





    
    "snippet": "写在前面因为我大部分的运维工作都是在Linux环境中进行的，而且都是命令行操作，为了更加便捷所以决定好好的学习一下vim编辑器。几年前刚接触vi/vim的时候，确实如网上说的那样不知道怎么退出这个神秘的编辑器。又不像图像化界面那样右上角有一个关闭按钮，crtl+c居然也不行，最终靠百度才退出这个难用的编辑器。后来随着工作的原因接触vim的时间也就多了起来。知道怎么退出这个编辑器，除了是在没办...",
    "content": "写在前面因为我大部分的运维工作都是在Linux环境中进行的，而且都是命令行操作，为了更加便捷所以决定好好的学习一下vim编辑器。几年前刚接触vi/vim的时候，确实如网上说的那样不知道怎么退出这个神秘的编辑器。又不像图像化界面那样右上角有一个关闭按钮，crtl+c居然也不行，最终靠百度才退出这个难用的编辑器。后来随着工作的原因接触vim的时间也就多了起来。知道怎么退出这个编辑器，除了是在没办法还是不想用这个玩意儿的。无法像Windows使用crtl+c和crtl+v复制粘贴，编辑器起来真是痛苦，很多时候都是把文件从服务器上传送到本地之后修改，在传送到服务器上。或者在命令行使用管道符和cat的方式将一大段文本写入到文件中。后来慢慢的喜欢上了这个编辑器，编辑文本的效率真的快。还有一个原因是作为IT从业者，很多时候都在座位上坐着，右手长时间使用鼠标导致手臂和食指有点难受，确定尝试一段时间vim。虽然一开始很痛苦，也看了网上关于vim的看法，以及nvim和emacs的对比，不过考虑到Linux环境中一般都安装有vim，为了习惯运维环境，最后还是确定选择vim。使用了一段时间之后右手确实舒服了很多。本人也喜欢折腾各种环境，前段时间利用github pages搭建了一个个人站点，所以也准备将vim的学习和使用通过博客记录下来。安装通过软件仓库安装## Linux系列sudo dnf install -y vim## debiansudo apt install -y vim通过源码编译安装安装依赖## aptapt install -y libncurses-devapt install -y python3-dev## dnfdnf install -y python3-develdnf install -y ncurses-devel获取源码cd ~git clone https://github.com/vim/vim.git编译安装cd vimmake distclean ## 如果之前编译过使用此命令清除缓存## python3-config --configdir 就是操作系统自带的 python3 的 config 目录，/usr/lib/python3.7/config-3.7m-x86_64-linux-gnu ，如果没有这个命令就直接写路径./configure --with-features=huge \\            --enable-multibyte \\            --enable-rubyinterp=yes \\            --enable-python3interp=yes \\            --with-python3-config-dir=$(python3-config --configdir) \\            --enable-luainterp=yes \\            --enable-gui=gtk2 \\            --enable-cscope \\            --prefix=/usr/local/make VIMRUNTIMEDIR=/usr/local/share/vim/vim91cd ~/vimsudo make installvim --version安装gvim如果准备在Windows或者带有桌面的Linux环境中使用vim的话，还是建议把gvim也安装了。Windows直接在download : vim online下载对应的安装包安装即可。Redhat系列sudo dnf install -y vim-X11debain系列sudo apt install -y vim-gui-common设置vim为默认输入法设置环境变量的方式vim ~/.bashrcexport EDITOR=vim通过vim-default长期使用vim之后，不习惯nano，所以直接卸载了nano## 如果后续还需要使用nano的话 可以省略卸载nano rpm -qa | grep -i nanosudo dnf remove nano### 或者直接安装vim-default，先卸载nano-defaultsudo dnf remove nano-default-editor -ysudo dnf install vim-default-editor -y总结vim在编辑文件这一方面个人觉得还是效率还是很高的。我也不需要开发大型的项目，所以使用日常使用vim感觉能提高不少效率。我也会使用vscode和vstudio，在编写python的时候也会使用pycharm，通过这些ide可以让我更加方便编写对应的开发语言。所以ide和vim我都会搭配使用。"
  },
  
  {
    "title": "Linux 下查看磁盘是SSD还是HDD",
    "url": "/posts/Linux-%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E6%98%AFSSD%E8%BF%98%E6%98%AFHDD/",
    "categories": "Linux, Tutorial",
    "tags": "Linux",
    "date": "2024-06-22 00:34:00 +0800",
    





    
    "snippet": "lsscsi通过lsscsi命令查看。lsscsi命令来自英文词组“List SCSI”的缩写，其功能是用于列出SCSI设备及属性信息，SCSI全称为small computer system interface，是一种常用的小型计算机系统接口。lsscsi命令可以很方便地帮助管理员区分哪些是固态硬盘、哪些是SATA盘、哪些是FC盘。不过在我的腾讯云服务器和旧的笔记本上都没有获取到对应的信息...",
    "content": "lsscsi通过lsscsi命令查看。lsscsi命令来自英文词组“List SCSI”的缩写，其功能是用于列出SCSI设备及属性信息，SCSI全称为small computer system interface，是一种常用的小型计算机系统接口。lsscsi命令可以很方便地帮助管理员区分哪些是固态硬盘、哪些是SATA盘、哪些是FC盘。不过在我的腾讯云服务器和旧的笔记本上都没有获取到对应的信息。如果你也无法通过lsscsi获取到磁盘类型的话，可以通过下文lsblk命令获取。lsscsi命令英文手册https://sg.danny.cz/scsi/lsscsi.htmllsscsi 命令语法：lsscsi [选项] [H:C:T:L]lsscsi 命令选项：            选项      含义                  -g      显示SCSI通用设备文件名称              -k      显示内核名称而不是设备节点名              -d      显示设备节点的主要号码和次要号码              -H      列出当前连接到系统的SCSI主机而不是SCSI设备              -l      显示每一个SCSI设备（主机）的附加信息              -c      相对于执行 cat /proc/scsi/scsi 命令的输出              -p      显示额外的数据完整性（保护）的信息              -t      显示传输信息              -L      以“属性名=值”的方式显示附加信息              -v      当信息找到时输出目录名              -y      假设sysfs挂载在指定路径而不是默认的 “/sys”              -s      显示容量大小。              -c      用全称显示默认的信息。              -d      显示设备主，次设备号。              -g      显示对应的sg设备名。              -H      显示主机控制器列表，-Hl,-Hlv。              -l      显示相关属性，-ll,-lll=-L。              -v      显示设备属性所在目录。              -x      以16进制显示lun号。              -p      输出DIF,DIX 保护类型。              -P      输出有效的保护模式信息。              -i      显示udev相关的属性              -w      显示WWN              -t      显示相应传输信息(ATA,FC,SBP,ISCSI,SPI,SAS,SATA,USB)，-Ht,-tl.（包括sas地址）      如果系统没有的话可以直接dnf或者apt安装。#Debianapt-get install lsscsi #Ubuntuapt-get install lsscsi #Alpineapk add lsscsi #Arch Linuxpacman -S lsscsi #Kali Linuxapt-get install lsscsi #CentOSyum install lsscsi #Fedoradnf install lsscsi #Raspbianapt-get install lsscsi #Dockerdocker run cmd.cat/lsscsi lsscsi我的腾讯云服务器，通过lsscsi查看，可以发现是QEMU。## 如果系统没有的话可以直接dnf或者apt安装┌─[root@DarkStarDevC]─[~]└──╼ # dnf install -y lsscsi┌─[root@DarkStarDevC]─[~]└──╼ # lsscsi[0:0:1:0]    cd/dvd  QEMU     QEMU DVD-ROM     2.5+  /dev/sr0腾讯云轻量服务器的信息磁盘信息如下：┌─[root@devC]─[~]└──╼ # lsscsi[0:0:1:0]    cd/dvd  QEMU     QEMU DVD-ROM     2.5+  /dev/sr0大学时期买的笔记本可以查看到的信息如下：wxj@wxj-PC:~$ sudo apt install -y lsscsiwxj@wxj-PC:~$ lsscsi[0:0:0:0]    disk    ATA      KINGSTON SHFS37A BBF0  /dev/sda[2:0:0:0]    disk    ATA      ST500LT012-1DG14 LVM1  /dev/sdblsblklsblk命令的英文是“list block”，即用于列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，但是它不会列出RAM盘的信息。块设备有硬盘，闪存盘，CD-ROM等等。lsblk命令包含util-linux中。通过yum provides lsblk命令查看命令对应的软件包。-d 输出设备名称-o 仅显示特定的列如果rota列的值是1 证明是可以旋转，就是HDD，反之数值是0是SSDwxj@wxj-PC:~$ lsblk  -d -o name,rotaNAME    ROTAsda    0sdb    1┌─[root@DarkStarDevC]─[~]└──╼ # lsblk  -d -o name,rotaNAME  ROTAsr0      1zram0    0vda      1vdb      1获取帮助信息┌─[root@DarkStarDevC]─[~]└──╼ # lsblk --helpUsage: lsblk [options] [&lt;device&gt; ...]List information about block devices.Options: -A, --noempty        don't print empty devices -D, --discard        print discard capabilities -E, --dedup &lt;column&gt; de-duplicate output by &lt;column&gt; -I, --include &lt;list&gt; show only devices with specified major numbers -J, --json           use JSON output format -M, --merge          group parents of sub-trees (usable for RAIDs, Multi-path) -O, --output-all     output all columns -P, --pairs          use key=\"value\" output format -S, --scsi           output info about SCSI devices -N, --nvme           output info about NVMe devices -v, --virtio         output info about virtio devices -T, --tree[=&lt;column&gt;] use tree format output -a, --all            print all devices -b, --bytes          print SIZE in bytes rather than in human readable format -d, --nodeps         don't print slaves or holders -e, --exclude &lt;list&gt; exclude devices by major number (default: RAM disks) -f, --fs             output info about filesystems -i, --ascii          use ascii characters only -l, --list           use list format output -m, --perms          output info about permissions -n, --noheadings     don't print headings -o, --output &lt;list&gt;  output columns -p, --paths          print complete device path -r, --raw            use raw output format -s, --inverse        inverse dependencies -t, --topology       output info about topology -w, --width &lt;num&gt;    specifies output width as number of characters -x, --sort &lt;column&gt;  sort output by &lt;column&gt; -y, --shell          use column names to be usable as shell variable identifiers -z, --zoned          print zone related information     --sysroot &lt;dir&gt;  use specified directory as system root -h, --help           display this help -V, --version        display versionAvailable output columns:    ALIGNMENT  alignment offset      ID-LINK  the shortest udev /dev/disk/by-id link name           ID  udev ID (based on ID-LINK)     DISC-ALN  discard alignment offset          DAX  dax-capable device    DISC-GRAN  discard granularity     DISK-SEQ  disk sequence number     DISC-MAX  discard max bytes    DISC-ZERO  discard zeroes data      FSAVAIL  filesystem size available      FSROOTS  mounted filesystem roots       FSSIZE  filesystem size       FSTYPE  filesystem type       FSUSED  filesystem size used       FSUSE%  filesystem use percentage        FSVER  filesystem version        GROUP  group name         HCTL  Host:Channel:Target:Lun for SCSI      HOTPLUG  removable or hotplug device (usb, pcmcia, ...)        KNAME  internal kernel device name        LABEL  filesystem LABEL      LOG-SEC  logical sector size      MAJ:MIN  major:minor device number       MIN-IO  minimum I/O size         MODE  device node permissions        MODEL  device identifier           MQ  device queues         NAME  device name       OPT-IO  optimal I/O size        OWNER  user name    PARTFLAGS  partition flags    PARTLABEL  partition LABEL        PARTN  partition number as read from the partition table     PARTTYPE  partition type code or UUID PARTTYPENAME  partition type name     PARTUUID  partition UUID         PATH  path to the device node      PHY-SEC  physical sector size       PKNAME  internal parent kernel device name       PTTYPE  partition table type       PTUUID  partition table identifier (usually UUID)           RA  read-ahead of the device         RAND  adds randomness          REV  device revision           RM  removable device           RO  read-only device         ROTA  rotational device      RQ-SIZE  request queue size        SCHED  I/O scheduler name       SERIAL  disk serial number         SIZE  size of the device        START  partition start offset        STATE  state of the device   SUBSYSTEMS  de-duplicated chain of subsystems   MOUNTPOINT  where the device is mounted  MOUNTPOINTS  all locations where device is mounted         TRAN  device transport type         TYPE  device type         UUID  filesystem UUID       VENDOR  device vendor        WSAME  write same max bytes          WWN  unique storage identifier        ZONED  zone model      ZONE-SZ  zone size   ZONE-WGRAN  zone write granularity     ZONE-APP  zone append max bytes      ZONE-NR  number of zones    ZONE-OMAX  maximum number of open zones    ZONE-AMAX  maximum number of active zonesFor more details see lsblk(8)."
  }
  
]

