[
  
  {
    "title": "OGG-添加新的表",
    "url": "/posts/OGG-%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%9A%84%E8%A1%A8/",
    "categories": "DataBase, Oracle",
    "tags": "OGG",
    "date": "2025-03-19 16:53:04 +0800",
    





    
    "snippet": "前言假设已经存在一个 OGG 的同步链路，后续需要添加新的表，如果重新搭建新的同步链路步骤也较多，在不影响效率的情况下，可以在原有的 OGG 链路上添加新的表本次主要是通过 OGG 将 Oracle 19c 的数据同步到 Kafka 因为链路已经存在，所以可以省略安装配置 OGG 的步骤，直接在原有的链路上添加新的表搭建可以参考之前的文章假设需要增加三张表：ACT_TRAG、DOCER、IN...",
    "content": "前言假设已经存在一个 OGG 的同步链路，后续需要添加新的表，如果重新搭建新的同步链路步骤也较多，在不影响效率的情况下，可以在原有的 OGG 链路上添加新的表本次主要是通过 OGG 将 Oracle 19c 的数据同步到 Kafka 因为链路已经存在，所以可以省略安装配置 OGG 的步骤，直接在原有的链路上添加新的表搭建可以参考之前的文章假设需要增加三张表：ACT_TRAG、DOCER、INVTT，用户为 AAUSER文中的表名和用户、主机仅供参考，批量替换过环境源端Oracle ：19.3.0OS：CentOS 7.7OGG：Oracle GoldenGate Command Interpreter for Oracle    Version 21.3.0.0.0 OGGCORE_21.3.0.0.0_PLATFORMS_210728.1047_FBO目标端Kafka：2.4.1kafka 集群 broker 地址：1.1.1.101:9092,1.1.1.102:9092,1.1.1.103:9092OS：CentOS 7.7OGG：Oracle GoldenGate for Big Data\t\t\tVersion 21.4.0.0.0 (Build 002)\tOracle GoldenGate Command Interpreter\t\tVersion 21.4.0.0.0 OGGCORE_21.4.0.0.0OGGRU_PLATFORMS_211022.1803源端 OGG添加新的表ggsci## 先登陆到源端数据库&gt; DBLOGIN USERID ogguser@ORCL password \"OGG_user_123\";## GGSCI (localhost.localdomain) 1&gt; ADD TRANDATA &lt;SCHEMA&gt;.&lt;TABLE&gt;## 添加新的表add trandata AAUSER.ACT_TRAGadd trandata AAUSER.DOCERadd trandata AAUSER.INVTT抽取和传输进程添加新的表在现有的抽取和传输进程配置文件中添加新的表，然后重启进程，时间很短，如果现有的链路目标端对实时性要求较高，建议配置新的链路或者在业务低峰期操作&gt; info all## 配置抽取进程&gt; edit param E_UAT_KATABLE AAUSER.ACT_TRAG;TABLE AAUSER.DOCER   ;TABLE AAUSER.INVTT        ;&gt; edit param p_uat_kaTABLE AAUSER.ACT_TRAG;TABLE AAUSER.DOCER   ;TABLE AAUSER.INVTT        ;&gt; stop E_UAT_KA&gt; stop p_uat_ka&gt; info all&gt; start E_UAT_KA&gt; start p_uat_ka&gt; info all重新生成表结构文件在源端生成表结构文件vi ./dirprm/mapping_uat_ka.prmdefsfile ./dirdef/mapping_uat_ka.def,purgeuserid ogguser@orcl password \"OGG_user_123\"-- 包含之前的表和新添加的表TABLE WMS_F.ACTTION_DETAILS;TABLE WMS_F.BASTION          ;TABLE AAUSER.ACT_TRAG;TABLE AAUSER.DOCER   ;TABLE AAUSER.INVTT        ; ./defgen paramfile ./dirprm/mapping_uat_ka.prm将生成的表结构文件传输到目标端scp ./dirdef/mapping_uat_ka.def root@12.2.19.11:/ogg/ogg21/dirdef/目标端配置 OGG本次是需要将数据恢复到单个 topic，所以需要在目标端配置多个 topic## 如果表的数量太多，可以直接进入 dirprm 目录下，复制一个模板，然后使用 vim 批量替换edit param r_ka09REPLICAT r_ka09 ## 需要修改为实际的 replicat 名称sourcedefs ./dirdef/mapping_uat_ka.def ## 源端的表结构文件TARGETDB LIBFILE libggjava.so SET property=dirprm/kafka01.props ## 配置 kafka 的属性文件，根据实际情况修改REPORTCOUNT EVERY 1 MINUTES, RATEGROUPTRANSOPS 10000MAP auser.ftablename, TARGET applsys_ftablename.ftablename; ## 映射关系，根据实际情况修改###vim dirprm/kafka09.propsgg.handlerlist=kafkahandlergg.handler.kafkahandler.type=kafkagg.handler.kafkahandler.KafkaProducerConfigFile=custom_kafka_producer.propertiesgg.handler.kafkahandler.topicMappingTemplate=applsys_ftablename ## 这里需要替换为实际的 topic 名称gg.handler.kafkahandler.format=jsongg.handler.kafkahandler.mode=opgg.handler.kafkahandler.format.insertOpKey = Igg.handler.kafkahandler.format.updateOpKey = Ugg.handler.kafkahandler.format.deleteOpKey = Dgg.handler.kafkahandler.format.metaColumnsTemplate=${optype[op_type]},${objectname[table]},${timestamp[op_ts]},${currenttimestampmicro[current_ts]},${position[pos]},${primarykeycolumns[primary_keys]}goldengate.userexit.timestamp=utc+8goldengate.userexit.writers=javawriterjavawriter.stats.display=truejavawriter.stats.full=truegg.classpath=dirprm/:/usr/bigtop/3.2.0/usr/lib/kafka/libs/*:/ogg/ogg21/:/ogg/ogg21/lib/*#####vim custom_kafka_producer.propertiesbootstrap.servers=bigdata01:9092acks=1compression.type=gzipreconnect.backoff.ms=1000value.serializer=org.apache.kafka.common.serialization.ByteArraySerializerkey.serializer=org.apache.kafka.common.serialization.ByteArraySerializerbatch.size=102400linger.ms=10000####ggsci&gt; add replicat r_ka01 exttrail ./dirdat/ka,checkpointtable okafka.checkpointggsci&gt; info all源端抽取数据## 全量 在源端的 OGG 中抽取数据，抽取数据的时候可以抽取所有的表，也可以只抽取新增的表ggsci&gt; edit params ei_kaSOURCEISTABLEsetenv (NLS_LANG = \"american_america.UTF8\")setenv (ORACLE_HOME = \"/erttdb02/uat/db/tech_st/11.2.0\")setenv (ORCLE_SID = \"orcl\")userid ogguser@orcl password \"OGG_user_123\"RMTHOST 1.1.1.1,MGRPORT 7809RMTFILE /ogg/ogg21/dirdat/ka,maxfiles 100,megabytes 1024,purgeTABLE AAUSER.ACT_TRAG;TABLE AAUSER.DOCER   ;TABLE AAUSER.INVTT        ;####shell&gt; nohup ./extract paramfile ./dirprm/ei_ka.prm reportfile ./dirrpt/ei_ka.rpt &amp;目标端恢复数据将每张表的数据恢复至单独的一个 topicshell&gt; ggsciggsci&gt; edit params ri_uat_ka09 ## 需要修改为实际的 replicat 名称SPECIALRUNEND RUNTIMEtargetdb  LIBFILE libggjava.so SET property=dirprm/kafka09.props ## 配置 kafka 的属性文件，根据实际情况修改REPORTCOUNT EVERY 1 MINUTES, RATEEXTFILE ./dirdat/kaDISCARDFILE ./dirrpt/ri_uat_ka09.dsc,purge ## 根据实际情况修改GROUPTRANSOPS 10000MAP APS.fnd_values, TARGET apps_fndup_values.f_loup_vaes;#### 启动并查看回放进程是否正常shell&gt; nohup ./replicat paramfile ./dirprm/ri_uat_ka09.prm reportfile ./dirrpt/ri_uat_ka09.rpt &amp;查看数据查看内容在命令行查看 topic 的内容时，默认会持续打印数据，只能手动结束（crtl+c），可以将数据重定向至一个文件方便查看。## 查看所有 topickafka-topics.sh --list --zookeeper localhost:2181## 查看数据shell1&gt; kafka-console-consumer.sh --bootstrap-server bigdata01:9092  --topic afkall --from-beginning &gt; /tmp/afka_all.txtshell2&gt;  tail -2 /tmp/afkall.txt## 统计 topic 的记录数kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list bigdata01:9092 --topic afkall --time -1 --offsets 1 | awk -F \":\" '{sum += $3} END {print sum}'"
  },
  
  {
    "title": "不要只关注工作中的技术",
    "url": "/posts/%E4%B8%8D%E8%A6%81%E5%8F%AA%E5%85%B3%E6%B3%A8%E5%B7%A5%E4%BD%9C%E4%B8%AD%E7%9A%84%E6%8A%80%E6%9C%AF/",
    "categories": "随笔杂记, 随笔",
    "tags": "随笔",
    "date": "2025-03-16 08:32:21 +0800",
    





    
    "snippet": "去年发现自己不再像以前那样很快就能专注或者静下心来学习技术了，总是会被一些琐事打扰，比如工作中的事情，或者是一些生活琐事，导致自己很难专注，这段时间也在思考为什么会这样，是因为自己的技术水平已经到达了一个瓶颈，还是因为自己的心态有问题，还是因为自己的工作/生活环境有问题，还是因为自己的学习方法有问题刚出来工作的时候，为了能快速提升自己，也为了有一个好的职业发展，可以大半夜都在学习，现在可能是...",
    "content": "去年发现自己不再像以前那样很快就能专注或者静下心来学习技术了，总是会被一些琐事打扰，比如工作中的事情，或者是一些生活琐事，导致自己很难专注，这段时间也在思考为什么会这样，是因为自己的技术水平已经到达了一个瓶颈，还是因为自己的心态有问题，还是因为自己的工作/生活环境有问题，还是因为自己的学习方法有问题刚出来工作的时候，为了能快速提升自己，也为了有一个好的职业发展，可以大半夜都在学习，现在可能是精力没那么旺盛，也是因为成长了，要处理自己和家庭的琐事，变得不知所措，一度看起来很忙，其实回头看看，也没做什么事情。过年回家的时候，静下心来看了看两本非技术类的书籍，发现自己的心情变得很平静，也很享受这种感觉，所以也在思考，是不是自己太过于关注工作中的技术，而忽略了生活中的一些美好事物，导致自己的心情变得很焦虑，也很疲惫，所以也在思考，是不是应该多关注一些生活中的美好事物，让自己的心情变得更加平静，也更加享受生活。每天都有新的技术，如果什么都学，其实也是什么都没学，因为学了又忘。人的大脑不想机器/ai那样可以存储大量的信息，所以要学会选择，或者是学会总结方法，技术都是相通的。特别是随着ai发展，网上很多贩卖焦虑的文章，搞得自己也很迷茫焦虑过年的时候看了《认知觉醒》和《脑雾修复》，认识到了自己的一些问题，心情也变得平静，其中的一些方法也可以对自己的工作带来帮助，例如《认知觉醒》中的通过一张纸来记录日程，区分事情的优先级，每天不要做太多的事想想最初工作的时候，除了会买一些技术书籍，也会买一些分技术类的书籍，例如《人性的弱点》《非暴力沟通》《社会性动物》等心理类和社交类的书籍。这两年其实都没买过非技术类书籍，买的一些技术书籍除了两本薄的其他的也只是翻了翻大概，也都快忘了技术类的书籍随着技术的快速发展，可能很快就过时了。之前买的 《高级VBA编程宝典》和《perl语言编程》为了在内网环境中开发一些小工具，也没怎么用，也算是过时了。有一段时间要开始写日报和和部门内部培训，觉得有点烦，偶然看了《逻辑表达：高效沟通的金字塔思维》之后觉得日报和培训也是一种沟通和表达，也就不再那么烦了作为一个技术人员，不仅要关注技术，也还要关注一些非技术类的方向，这样会开阔自己的视野，也会让自己的心态变得更加平和，不管对生活还是工作都是有好处的"
  },
  
  {
    "title": "技术群聊和公众号",
    "url": "/posts/%E6%8A%80%E6%9C%AF%E7%BE%A4%E5%92%8C%E5%85%AC%E4%BC%97%E5%8F%B7/",
    "categories": "随笔杂记, 随笔",
    "tags": "随笔",
    "date": "2025-03-16 08:02:19 +0800",
    





    
    "snippet": "前言之前为了学习加了很多群聊，也关注了很多公众号，但是现在发现很多公众号的文字都是互相转载，而且随着这两年的 ai 发展，一些文章要么一大半都是机器代写或者震惊的标题党，这段时间取关了一些公共号，或者设置不接受推送，什么时候想看的时候再去看，不再被动接受信息至于群聊，也是一样，一些技术群里面逐渐变成了广告群和闲聊群，不再有技术交流的氛围，所以也是慢慢的退出了一些群聊。除了个别群，大部分的群都...",
    "content": "前言之前为了学习加了很多群聊，也关注了很多公众号，但是现在发现很多公众号的文字都是互相转载，而且随着这两年的 ai 发展，一些文章要么一大半都是机器代写或者震惊的标题党，这段时间取关了一些公共号，或者设置不接受推送，什么时候想看的时候再去看，不再被动接受信息至于群聊，也是一样，一些技术群里面逐渐变成了广告群和闲聊群，不再有技术交流的氛围，所以也是慢慢的退出了一些群聊。除了个别群，大部分的群都设置了免打扰，不再接受推送，什么时候想看的时候再去看。最开始的时候还会在每天早上或者晚上统一看一下群聊消息，现在已经是3天或者一周才看一次了。基本也都是大概划拉一下，看看有没有什么有价值的信息，没有的话就直接忽略了为什么要取关  信息重复  机器代写  标题党  信息过载  信息质量低为什么要关注  信息质量高  信息有价值  信息有趣  信息有深度  信息有新意技术群以前觉得有什么问题可以在群里面问，但是现在发现很多问题都是可以通过搜索引擎解决的，而且很多问题都是重复的，所以现在很少在群里面问问题了，除非是一些比较难的问题，或者是一些比较新的技术，或者是一些比较有趣的问题刚出来工作的时候，觉得群里面的人都是大神，所以很多问题都是在群里面问，但是现在随着自身的技术积累，发现很多问题都可以自己解决，所以也就不再那么依赖群里面的人了，不过经验问题还是可以在群里面问问的，毕竟经验是不能通过搜索引擎解决的总结技术圈和公众号都是一个信息的来源，但是信息的质量和价值是不一样的，所以要取关一些信息质量低的公众号，关注一些信息质量高的公众号，技术群也是一样，要取关一些广告群和闲聊群，关注一些技术交流的群，这样才能更好的获取有价值的信息，提高自己的技术水平公众号和群聊都是为了提升自己，所以以前会发一些时间在上面，看看前辈们的思考方式和经验，现在觉得慢慢的变味儿。不过一个群聊要是大家都聊技术其实也很无聊，特别是一些看不懂或者没有接触的技术，对于不懂的朋友来说，就像是上课听天书一样，只有随着自己的技术积累，才能慢慢的理解和接受这些技术，所以加一些技术群或者关注一些公众号还是有必要的，但是还是保持免打扰比较好，不然有点浪费时间"
  },
  
  {
    "title": "foxmail 添加 gmail",
    "url": "/posts/foxmail-%E6%B7%BB%E5%8A%A0gmail/",
    "categories": "Google, Foxmail",
    "tags": "Foxmail",
    "date": "2025-03-13 14:27:11 +0800",
    





    
    "snippet": "前言Foxmail 是一款国产邮件客户端，支持多账号管理，支持多种邮箱类型，包括 QQ 邮箱、163 邮箱、Gmail 等。本文主要介绍如何在 Foxmail 中添加 Gmail 邮箱遇到的问题及解决方法。换了新电脑，安装了 Foxmail，添加 Gmail 邮箱时，遇到了问题，提示“此应用试图访问您 Google 账号中的敏感信息。为确保您的账号安全，Google 阻止了此次访问。”解决方...",
    "content": "前言Foxmail 是一款国产邮件客户端，支持多账号管理，支持多种邮箱类型，包括 QQ 邮箱、163 邮箱、Gmail 等。本文主要介绍如何在 Foxmail 中添加 Gmail 邮箱遇到的问题及解决方法。换了新电脑，安装了 Foxmail，添加 Gmail 邮箱时，遇到了问题，提示“此应用试图访问您 Google 账号中的敏感信息。为确保您的账号安全，Google 阻止了此次访问。”解决方法之前是可以正常添加 Gmail 邮箱的，通过添加账号中自带的 Gmail，输入 Google 账号密码后，就可以成功绑定。这次的原因是因为 Google 更新了更高级别安全规则，一些旧的/Google 不信任软件、设备将无法通过常规方式去绑定连接。就会被 Google 阻止需要注意的：自 2025 年 1 月起，“启用 IMAP”和“停用 IMAP”选项将无法再使用。Gmail 中的 IMAP 访问功能始终处于启用状态，您当前与其他电子邮件客户端的连接不会受到影响。您无需采取任何行动解决方法如下：      需要先设置 Google 的两步验证        设置应用密码，应用名称设置一个自己喜欢的名字，也可以点击了解详情，获取更多信息        用这个应用密码去绑定 Gmail 账号，就可以成功绑定了，一定要先复制保存好这个应用密码，因为只会显示一次，之后就不会再显示了        在 Foxmail 中添加 Gmail 账户时，选择其他邮箱，输入 Gmail 账号和刚刚复制的应用密码，就可以成功绑定  然后选择手动设置服务器类型选择 IMAP，输入 Gmail 账号和刚刚复制的应用密码，就可以成功绑定配置以下服务器信息，一般来说填入 Gmail 账号之后会自动填充，没有自动填充就手动输入以下信息：接收邮件服务器（IMAP）    服务器地址：imap.gmail.com    端口：993    使用 SSL 加密    发送邮件服务器（SMTP）服务器地址：smtp.gmail.com    端口：465 或 587    使用 SSL/TLS 加密设置完成后，Foxmail 会自动测试连接。 如果没有问题点击确认之后，Foxmail 就可以开始收发 Gmail 邮件  访问 Google 安全性设置页面可以检查已经设置了的应用密码：https://myaccount.google.com/security-checkup。总结以上就是在 Foxmail 中添加 Gmail 邮箱遇到的问题及解决方法，希望对大家有所帮助"
  },
  
  {
    "title": "OGG-25715 错误",
    "url": "/posts/OGG-25715%E9%94%99%E8%AF%AF/",
    "categories": "DataBase, Oracle",
    "tags": "OGG",
    "date": "2025-02-28 11:59:20 +0800",
    





    
    "snippet": "前言启动 Extract 进程的时候出现 OGG-25715 错误的解决方法，在网上搜索到的解决方法并不适用于我的环境，所以记录一下OGG-25715 错误的解决方法在目标端 ogg Kafka 环境 replicat 进程启动时，遇到以下错误：2025-02-26 22:28:19  INFO    OGG-01851  filecaching started: thread ID: 14...",
    "content": "前言启动 Extract 进程的时候出现 OGG-25715 错误的解决方法，在网上搜索到的解决方法并不适用于我的环境，所以记录一下OGG-25715 错误的解决方法在目标端 ogg Kafka 环境 replicat 进程启动时，遇到以下错误：2025-02-26 22:28:19  INFO    OGG-01851  filecaching started: thread ID: 140174464091904.2025-02-26 22:28:19  INFO    OGG-01815  Virtual Memory Facilities for: COM    anon alloc: mmap(MAP_ANON)  anon free: munmap    file alloc: mmap(MAP_SHARED)  file free: munmap    target directories:    /home/ogg/ogg21/dirtmp.Source Context :  SourceModule            : [ggapp.cachemgr]  SourceID                : [../gglib/ggapp/cachemgr/cmgr_restore.c]  SourceMethod            : [cm_vm_vals_set]  SourceLine              : [2861]  ThreadBacktrace         : [13] elements                          : [/home/ogg/ogg21/libgglog.so(CMessageContext::AddThreadContext())]                          : [/home/ogg/ogg21/libgglog.so(CMessageFactory::CreateMessage(CSourceContext*, unsigned int, ...))]                          : [/home/ogg/ogg21/libgglog.so(_MSG_(CSourceContext*, int, CMessageFactory::MessageDisposition))]                          : [/home/ogg/ogg21/replicat()]                          : [/home/ogg/ogg21/replicat()]                          : [/home/ogg/ogg21/replicat(CM_cache_init(pool_info*, char const*, extract_vals*))]                          : [/home/ogg/ogg21/replicat()]                          : [/home/ogg/ogg21/replicat(ggs::gglib::MultiThreading::MainThread::ExecMain())]                          : [/home/ogg/ogg21/replicat(ggs::gglib::MultiThreading::Thread::RunThread(ggs::gglib::MultiThreading::Thread::ThreadArgs*))]                          : [/home/ogg/ogg21/replicat(ggs::gglib::MultiThreading::MainThread::Run(int, char**))]                          : [/home/ogg/ogg21/replicat(main)]                          : [/lib64/libc.so.6(__libc_start_main)]                          : [/home/ogg/ogg21/replicat()]2025-02-26 22:28:19  ERROR   OGG-25715  CACHEMGR: No Swap environment and parameter CONTAINER MEM_LIMIT not set.2025-02-26 22:28:19  ERROR   OGG-01668  PROCESS ABENDING.错误信息提示很明显，没有设置 CONTAINER MEM_LIMIT 参数和 swap 空间，所以需要在配置文件中设置该参数或者设置 swap 空间查看当前 swap 空间GGSCI (bigdata01) 9&gt; shell free  -h              total        used        free      shared  buff/cache   availableMem:           125G         78G        4.5G        4.0G         42G         42GSwap:            0B          0B          0BOS 没有设置 swap 空间，所以需要设置 swap 空间或者设置相关的参数，如果不想更改 OS 环境，ogg 链路有比较少的话，可以在配置文件中设置 CONTAINER MEM_LIMIT 参数，如果链路比较多，可以设置 swap 空间GGSCI (bigdata01) 10&gt; edit params replicatecontainer mem_limit 8Gcachemgr cachesize 1G需要注意的是 mem_limit 参数的设置，需要根据实际情况设置，不要设置过大，否则会影响系统的性能，不能比实际的物理内存大。 cachesize 参数设置的是缓存的大小，不能比 mem_limit 大设置完成之后，重启 replicat 进程即可嫌麻烦可以直接设置 swap，参考以下脚本，脚本是之前网上找到的，可以根据实际情况修改cat &gt;&gt; addswap.sh&lt;&lt;wxj#!/bin/bash#********************************************************#Author: Archangel#Description:#Date: 2023-03-16 21:33:16#LastEditTime: 2023-03-16 21:33:16#FilePath: \\Desktop\\swapfile.sh#LastEditors: Archangel#********************************************************#定义颜色参数function echo_color() {    #定义颜色函数变量    var_color=${1}    #定义颜色函数参数    content_str=${2}    #定义颜色时间参数    date_time=$(date \"+%Y-%m-%d %H:%M:%S.%N\" | cut -b 1-23)    #清空默认值    content_echo_str=\"\"    #定义颜色变量    error_color=\"\\033[1;5;41m\"              #红底背景红字带闪烁，致命错误    failed_color=\"\\033[1;31m\"               #红色字体，执行错误信息    warn_color=\"\\033[1;33m\"                 #黄色字体，警号信息    succ_color=\"\\033[1;32m\"                 #绿色字体，执行正确信息    info_color=\"\\033[1;34m\"                 #蓝色字体，提示信息    violet_color='\\033[1;35m'               #紫色字体，信息    blue_underline_color='\\033[47;34m'      #蓝色带下滑线，信息    dark_green_underline_color='\\033[4;36m' #深绿色带下滑线，信息    red_twinkle_color='\\033[5;31m'          #红字带闪烁，致命错误    #定义颜色结束变量    RES='\\033[0m'    ## 判断参数 1 是否是空字符串    if [ \"x${content_str}\" == \"x\" ]; then        return    else        content_str=\"[${date_time}] ${content_str} ${RES}\"    fi    #定义输出串    case ${var_color} in    error) #error        content_echo_str=\"${error_color}\\t${content_str}\"        ;;    failed) #failed        content_echo_str=\"${failed_color}\\t${content_str}\"        ;;    warning) #warning        content_echo_str=\"${warn_color}\\t${content_str}\"        ;;    success) #success        content_echo_str=\"${succ_color}\\t${content_str}\"        ;;    info) #info        content_echo_str=\"${info_color}\\t${content_str}\"        ;;    violet) #violet        content_echo_str=\"${violet_color}\\t${content_str}\"        ;;    blue_underline) #blue_underline        content_echo_str=\"${blue_underline_color}\\t${content_str}\"        ;;    dark_green_underline) #dark_green_underline        content_echo_str=\"${dark_green_underline_color}\\t${content_str}\"        ;;    red_twinkle) #red_twinkle        content_echo_str=\"${red_twinkle_color}\\t${content_str}\"        ;;    esac    ## 打印输出    echo -e \"${content_echo_str}\"}# 设置交换分区文件大小，单位 MBswapfile=$1swap_size=$2unit=$3if [ -z \"${swapfile}\" ] || [ -z \"${swap_size}\" ] || [ -z \"${unit}\" ]; then    echo_color failed \"参数错误：缺少必要参数\"    echo_color success \"sh $0 交换分区文件位置 交换分区文件大小 单位 1(M|G)\"    echo_color warning \"sh $0 /swap/swapfile 2048 M\"    exitfiswap_dir=$(dirname ${swapfile})if [ ! -d ${swap_dir} ]; then    echo_color info \"创建目录：${swap_dir}\"    mkdir -p ${swap_dir}fiecho_color info \"创建一个空白文件作为交换分区，单次 1${unit},共${swap_size}次\"dd if=/dev/zero of=${swapfile} bs=1${unit} count=${swap_size}echo_color info \"设置文件权限，仅限 root 用户读写\"chmod 600 ${swapfile}echo_color info \"格式化交换分区\"mkswap ${swapfile}echo_color info \"启用交换分区\"swapon ${swapfile}echo_color info \"永久生效，将以下内容添加到 /etc/fstab 文件中\"echo \"${swapfile}   swap    defaults    0   0\" &gt;&gt;/etc/fstabwxj使用方法：sh addswap.sh /swap/swapfile 2048 M总结  OGG-25715 错误的解决方法  设置 swap 空间或者设置 CONTAINER MEM_LIMIT 和 cachesize 参数"
  },
  
  {
    "title": "OGG-15051 错误",
    "url": "/posts/OGG-15051%E9%94%99%E8%AF%AF/",
    "categories": "DataBase, Oracle",
    "tags": "OGG",
    "date": "2025-02-28 11:47:12 +0800",
    





    
    "snippet": "前言启动 Replicat 进程的时候出现 OGG-15051 错误的解决方法，在网上搜索到的解决方法并不适用于我的环境，所以记录一下OGG-15051 错误在目标端 ogg Kafka 环境 Replicat 进程启动时，遇到以下错误：```shell2025-02-26 22:07:45  INFO    OGG-03059  Operating system character set...",
    "content": "前言启动 Replicat 进程的时候出现 OGG-15051 错误的解决方法，在网上搜索到的解决方法并不适用于我的环境，所以记录一下OGG-15051 错误在目标端 ogg Kafka 环境 Replicat 进程启动时，遇到以下错误：```shell2025-02-26 22:07:45  INFO    OGG-03059  Operating system character set identified as UTF-8.2025-02-26 22:07:45  INFO    OGG-02695  ANSI SQL parameter syntax is used for parameter parsing.2025-02-26 22:07:45  INFO    OGG-03528  The source database character set, as determined from the table definition file, is UTF-8.REPLICAT r_ftestsourcedefs ./dirdef/mapping_uat_ka.defTARGETDB LIBFILE libggjava.so SET property=dirprm/kafka_wms_ftest.props2025-02-26 22:07:45  INFO    OGG-15052  Using Java class path: ./ggjava/ggjava.jar:dirprm:.dirprm/:/opt/datasophon/kafka-2.4.1/:/home/ogg/ogg21/:/home/ogg/ogg21/lib/.Exception in thread “main” java.lang.NoClassDefFoundError: org/apache/kafka/clients/producer/Producer        at oracle.goldengate.handler.kafka.impl.KafkaProperties.getProducerInstance(KafkaProperties.java:152)        at oracle.goldengate.handler.kafka.KafkaHandler.init(KafkaHandler.java:162)        at oracle.goldengate.datasource.AbstractDataSource.addDataSourceListener(AbstractDataSource.java:592)        at oracle.goldengate.datasource.factory.DataSourceFactory.getDataSource(DataSourceFactory.java:161)        at oracle.goldengate.datasource.UserExitDataSourceLauncher.(UserExitDataSourceLauncher.java:45)        at oracle.goldengate.datasource.UserExitMain.main(UserExitMain.java:109)Caused by: java.lang.ClassNotFoundException: org.apache.kafka.clients.producer.Producer        at java.net.URLClassLoader.findClass(URLClassLoader.java:387)        at java.lang.ClassLoader.loadClass(ClassLoader.java:418)        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355)        at java.lang.ClassLoader.loadClass(ClassLoader.java:351)        ... 6 more2025-02-26 22:07:46  WARNING OGG-00869  java.lang.ClassNotFoundException: org.apache.kafka.clients.producer.Producer.Source Context :  SourceModule            : [gglib.ggdal.adapter.java]  SourceID                : [ggdal/Adapter/Java/JavaAdapter.cpp]  SourceMethod            : [HandleJavaException]  SourceLine              : [274]  ThreadBacktrace         : [16] elements                          : [/home/ogg/ogg21/libgglog.so(CMessageContext::AddThreadContext())]                          : [/home/ogg/ogg21/libgglog.so(CMessageFactory::CreateMessage(CSourceContext, unsigned int, …))]                          : [/home/ogg/ogg21/libgglog.so(_MSG_String(CSourceContext, int, char const, CMessageFactory::MessageDisposition))]                          : [/home/ogg/ogg21/libggjava.so()]                          : [/home/ogg/ogg21/libggjava.so(ggs::gglib::ggdal::CJavaAdapter::Open())]                          : [/home/ogg/ogg21/replicat(ggs::gglib::ggdal::CDALAdapter::Open(ggs::gglib::ggunicode::UString const&amp;))]                          : [/home/ogg/ogg21/replicat(GenericImpl::Open(ggs::gglib::ggunicode::UString const&amp;))]                          : [/home/ogg/ogg21/replicat(odbc_param(char, char, ggs::gglib::ggapp::ReplicationContextParams const&amp;))]                          : [/home/ogg/ogg21/replicat(get_infile_params(ggs::gglib::ggapp::ReplicationContextParams&amp;, ggs::gglib::ggdatasource::DataSourceParams&amp;, ggs::gglib::ggdatatarget::DataTargetParams&amp;, ggs::gglib::ggmetadata::MetadataContext&amp;))]                          : [/home/ogg/ogg21/replicat()]                          : [/home/ogg/ogg21/replicat(ggs::gglib::MultiThreading::MainThread::ExecMain())]                          : [/home/ogg/ogg21/replicat(ggs::gglib::MultiThreading::Thread::RunThread(ggs::gglib::MultiThreading::Thread::ThreadArgs))]                          : [/home/ogg/ogg21/replicat(ggs::gglib::MultiThreading::MainThread::Run(int, char**))]                          : [/home/ogg/ogg21/replicat(main)]                          : [/lib64/libc.so.6(__libc_start_main)]                          : [/home/ogg/ogg21/replicat()]2025-02-26 22:07:46  ERROR   OGG-15051  Java or JNI exception:java.lang.NoClassDefFoundError: org/apache/kafka/clients/producer/Producer.2025-02-26 22:07:46  ERROR   OGG-01668  PROCESS ABENDING.~~~解决方法1. 确认 Kafka 客户端 JAR 文件存在  操作步骤：          登录到 OGG 服务器，检查 Kafka 客户端 JAR 文件路径：        ls /opt/datasophon/kafka-2.4.1/libs/kafka-clients-*.jar                    如果文件不存在，需下载匹配的 Kafka 客户端 JAR（版本需与 Kafka 服务端一致）：                  从 Maven 仓库下载（例如 kafka-clients 2.4.1          将文件复制到目标路径：            cp kafka-clients-2.4.1.jar /opt/datasophon/kafka-2.4.1/libs/                                          2. 调整 OGG 的 Java 类路径配置  操作步骤：          编辑 OGG 的 Kafka Handler 配置文件 dirprm/kafka_wms_ftest.props，确保包含以下内容：        gg.classpath=/opt/datasophon/kafka-2.4.1/libs/*:/path/to/other/dependencies/*                示例：        gg.classpath=/opt/datasophon/kafka-2.4.1/libs/*:/home/ogg/ogg21/lib/*                    保存文件并重启 Replicat 进程。        我的原因是因为在配置文件中指定的类路径错误，导致无法加载Producer类  3. 验证 Kafka 客户端版本兼容性  操作步骤：          检查 OGG 21c 官方文档支持的 Kafka 版本                  如果版本不兼容，升级 Kafka 客户端 JAR 文件：            #wget https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.0.0/kafka-clients-3.0.0.jarcp kafka-clients-3.0.0.jar /opt/datasophon/kafka-2.4.1/libs/                                          4. 检查文件权限  操作步骤：          确认 OGG 安装的用户（如ogguser）对 Kafka JAR 文件有读取权限：        chmod -R 755 /opt/datasophon/kafka-2.4.1/libs/                    验证权限：        ls -l /opt/datasophon/kafka-2.4.1/libs/kafka-clients-*.jar                    5. 更新 GLOBALS 文件（可选）  操作步骤：          在 OGG 安装目录下的GLOBALS文件中，显式指定 Java 类路径：        JVMCLASSPATH /opt/datasophon/kafka-2.4.1/libs/*                    6. 验证环境变量  操作步骤：          设置环境变量（临时生效）：        export CLASSPATH=/opt/datasophon/kafka-2.4.1/libs/*:$CLASSPATH                    启动 Replicat 进程测试。      7. 重启 Replicat 进程  操作步骤：          在 GGSCI 命令行中停止并重启 Replicat：        GGSCI&gt; stop replicat r_ftestGGSCI&gt; start replicat r_ftest                    8. 查看详细日志  操作步骤：          检查 Replicat 日志文件（位于dirrpt/r_ftest.rpt）：        cat dirrpt/r_ftest.rpt                    根据日志中的具体错误调整配置。      总结  根本原因：OGG 的 Java 类路径未正确包含 Kafka 客户端 JAR 文件（如kafka-clients-xxx.jar），导致运行时无法加载Producer类。  关键解决步骤：          确认 Kafka 客户端 JAR 文件存在且版本兼容。      在 OGG 配置文件或GLOBALS中显式指定类路径。      检查权限和环境变量设置。      "
  },
  
  {
    "title": "OGG2KAFKA",
    "url": "/posts/OGG2KAFKA/",
    "categories": "DataBase, Oracle",
    "tags": "OGG",
    "date": "2025-02-27 15:15:02 +0800",
    





    
    "snippet": "前言Oracle GoldenGate（OGG）是 Oracle 公司的一款数据同步工具，支持多种数据库之间的数据同步，包括 Oracle 数据库、MySQL、SQL Server、DB2 等。本文主要介绍 OGG 与 Kafka 的集成，实现将 Oracle 的数据同步到 Kafka 的功能。文中的 ip 和表名是脱敏，参考的时候根据个人的实际情况修改项目环境源端Oracle ：19.3....",
    "content": "前言Oracle GoldenGate（OGG）是 Oracle 公司的一款数据同步工具，支持多种数据库之间的数据同步，包括 Oracle 数据库、MySQL、SQL Server、DB2 等。本文主要介绍 OGG 与 Kafka 的集成，实现将 Oracle 的数据同步到 Kafka 的功能。文中的 ip 和表名是脱敏，参考的时候根据个人的实际情况修改项目环境源端Oracle ：19.3.0OS：CentOS 7.7OGG：Oracle GoldenGate Command Interpreter for Oracle    Version 21.3.0.0.0 OGGCORE_21.3.0.0.0_PLATFORMS_210728.1047_FBO目标端Kafka：2.4.1kafka 集群 broker 地址：1.1.1.101:9092,1.1.1.102:9092,1.1.1.103:9092OS：CentOS 7.7OGG：Oracle GoldenGate for Big Data\t\t\tVersion 21.4.0.0.0 (Build 002)\tOracle GoldenGate Command Interpreter\t\tVersion 21.4.0.0.0 OGGCORE_21.4.0.0.0OGGRU_PLATFORMS_211022.1803安装 OGG源端下载 OGG 安装包官网地址，选择对应平台的版本下载。解压安装包   ogg_dir=/u01/ogg/ogg21   mkdir -pv $ogg_dir   unzip 213000_fbo_ggs_Linux_x64_Oracle_shiphome.zip -d $ogg_dir   cd $ogg_dir安装 OGG  准备响应文件    grep -v \"^#\" fbo_ggs_Linux_x64_Oracle_shiphome/Disk1/response/oggcore.rsp | sed  '/^$/d' &gt; oggcore.rsp        修改 oggcore.rsp 文件~~~shellvim oggcore.rsporacle.install.responseFileVersion=/oracle/install/rspfmt_ogginstall_response_schema_v21_1_0INSTALL_OPTION=ORA19CSOFTWARE_LOCATION=/u01/ogg/ogg21START_MANAGER=falseMANAGER_PORT=DATABASE_LOCATION=INVENTORY_LOCATION=UNIX_GROUP_NAME=3. 配置 ogg 环境变量如果你的环境变量在安装 Oracle 实例的时候已经配置好了，可以忽略 for oracle 部分~~~shellvim ~/.bash_profile#for oracleexport LD_LIBRARY_PATH=$ORACLE_HOME/lib:$ORACLE_HOME/rdbms/lib:$ORACLE_HOME/network/lib:/lib:/usr/libexport CLASSPATH=$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlib:$ORACLE_HOME/network/jlibexport NLS_LANG=\"SIMPLIFIED CHINESE_CHINA.AL32UTF8\"#for oggexport OGG_HOME=/u01/app/ogg/ogg21export PATH=$OGG_HOME/bin:$PATH:$ORACLE_HOME/binexport LD_LIBRARY_PATH=$OGG_HOME:$ORACLE_HOME/lib:/usr/libalias ggsci='cd $OGG_HOME;ggsci'  安装 OGG~~~shellsource ~/.bash_profile./runInstaller -silent -responseFile /u01/ogg/ogg21/oggcore.rsp#安装完成后，执行 ggsci 命令进入 OGG 管理界面ggsciOracle GoldenGate Command Interpreter for OracleVersion 21.3.0.0.0 OGGCORE_21.3.0.0.0_PLATFORMS_210728.1047_FBOOracle Linux 7, x64, 64bit (optimized), Oracle Database 21c and lower supported versions on Jul 29 2021 03:59:23操作系统字符集标识为 UTF-8。Copyright (C) 1995, 2021, Oracle and/or its affiliates. All rights reserved.## 目标端安装 OGG### 下载 OGG 安装包  [官网地址](https://www.oracle.com/middleware/technologies/goldengate-downloads.html)，选择对应平台的版本下载，需要注意的要选择 Big Data 版本### 解压安装  bigdata 版本的 OGG 安装就很简单了，解压即可~~~shell## 创建目录mkdir /oggscp $ogg_software /ogg/## 解压pushd /oggunzip 214000_ggs_Linux_x64_BigData_64bit.zip -d ogg21tar xf ../ggs_Linux_x64_BigData_64bit.tar## 删除指定文件之外的所有文件## [root@bigdata01 ogg]# rm -rf !(214000_ggs_Linux_x64_BigData_64bit.zip)[root@bigdata01 ogg21]# ./ggsci./ggsci: error while loading shared libraries: libjvm.so: cannot open shared object file: No such file or directory[root@bigdata01 ogg21]#[root@bigdata01 ogg21]# locate libjvm.so/home/module/jdk1.8.0_333/jre/lib/amd64/server/libjvm.so/module/jre/lib/amd64/server/libjvm.so/opt/module/jdk1.8/jre/lib/amd64/server/libjvm.so[root@bigdata01 ogg21]#[root@bigdata01 ogg21]# env | grep LIBRARYLD_LIBRARY_PATH=/opt/module/oracle_instant_client:/opt/module/oracle_instant_client:/opt/module/oracle/instantclient_19_19## 配置 ogg 环境变量[root@bigdata01 ogg21]# pwd/ogg/ogg21[root@bigdata01 ogg21]# export LD_LIBRARY_PATH=/ogg/ogg21/lib:/home/module/jdk1.8.0_333/jre/lib/amd64/server/[root@bigdata01 ogg21]### vim ~/.bash_profileexport GGATE=/ogg/ogg21export LD_LIBRARY_PATH=/ogg/ogg21/lib:/home/module/jdk1.8.0_333/jre/lib/amd64/server/[root@bigdata01 ogg21]# ./ggsciOracle GoldenGate for Big DataVersion 21.4.0.0.0 (Build 002)Oracle GoldenGate Command InterpreterVersion 21.4.0.0.0 OGGCORE_21.4.0.0.0OGGRU_PLATFORMS_211022.1803Oracle Linux 7, x64, 64bit (optimized), Generic  on Oct 22 2021 23:14:43Operating system character set identified as UTF-8.Copyright (C) 1995, 2021, Oracle and/or its affiliates. All rights reserved.GGSCI (bigdata01) 1&gt;配置 OGG源端配置 OGG说明如果目标端需要每张表都单独保存为一个 topic 的话，在源端的抽取进程和传输进程也可以将多张表的信息配置为一个进程，只需要在目标端的恢复进程单独配置一个进程即可。添加 OGG 用户OGG 同步最好使用一个专门的用户，这样可以避免权限问题sqlplus / as sysdba-- 创建表空间，为 goldengate 用户创建指定的表空间 TBS_OGG，表空间并必须大于等于 1000mSQL&gt; create tablespace TBS_OGG datafile '/u01/app/oracle/oradata/gguser.dbf' size 2G autoextend on;-创建用户：SQL&gt; create user ogguser identified by \"OGG_user_123\" default tablespace TBS_OGG temporary tablespace TEMP quota unlimited on TBS_OGG;--授权给 ogguser 用户：SQL &gt; GRANT CONNECT TO ogguser;SQL &gt; GRANT DBA TO ogguser;-- 如果安全需要不能直接给 dba 权限，可能需要如下权限grant SELECT ANY DICTIONARY to ogguser;GRANT EXECUTE ON SYS.DBMS_LOCK TO ogguser;grant select any transaction to ogguser;grant select any table to ogguser;grant flashback any table to ogguser;grant alter any table to ogguser;设置归档ogg 同步 oracle 数据库需要开启归档模式，如果数据库没有开启归档模式，需要先开启归档模式--启用归档SQL&gt; archive log listDatabase log mode              No Archive ModeAutomatic archival             DisabledArchive destination            /oracle/products/10.2/db/dbs/archOldest online log sequence     213Current log sequence           215--修改归档目录，更改前确认/arch_qd/logs 目录，oracle 账号有完全的读写权限。SQL&gt; show parameter name -- 查看实例名称，避免搞错实例NAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------db_file_name_convert                 stringdb_name                              stringdb_unique_name                       stringglobal_names                         booleaninstance_name                        stringlock_name_space                      stringlog_file_name_convert                stringprocessor_group_name                 stringservice_names                        stringSQL&gt; show parameter destNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------log_archive_dest                     stringlog_archive_dest_1                   string      LOCATION=/oracle/arch02/CRMDB2-- 修改归档格式SQL&gt; show parameter log_archive_format;NAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------log_archive_format                   string      %t_%s_%r.dbfSQL&gt;SQL&gt; alter system set log_archive_format = \"archive_%t_%s_%r.arch\" scope=spfile; -- 需要重启--启用归档--修改归档目录，更改前确认/arch_qd/logs 目录，oracle 账号有完全的读写权限。SQL&gt; alter system set log_archive_dest_1='LOCATION=/arch_qd/logs' sid='cdrdb'  SCOPE=BOTH;-- 停止监听lsnrctl stop--然后关闭数据库，注意打开 alert*log 后台日志SQL&gt; shut immediate;-- 如果长时间关闭不了，日志没有异常，可能是会话未关闭-- 杀掉非本地进程ps -ef|grep LOCAL=NO |awk '{print $2}' |xargs kill -15-- 如果 -15 无法关闭，可以使用 -9 强制关闭ps -ef|grep LOCAL=NO |awk '{print $2}' |xargs kill -9SQL&gt; startup mount;SQL&gt; alter database archivelog;-- ALTER DATABASE NOARCHIVELOG; -- 切换到非归档模式SQL&gt; alter database open;--查看更改后的归档，应该类似下面的输出SQL&gt; archive log listDatabase log mode              Archive ModeAutomatic archival             EnabledArchive destination            /arch_qd/logsOldest online log sequence     2967Next log sequence to archive   2973Current log sequence           2973-- 切换归档日志SQL&gt; alter system switch logfile;查看归档日志是否正常产生--ls 检查归档目录，是否产生归档日志cd /arch2/logsls -rltls -lt 按照时间排序，倒序ls -lrt 按照时间排序，正序--ls 单行显示文件，利用数字 1 参数项，这样一行只会显示一列文件的文件名，不会显示其他信息，方便编辑例如：CRM-DDB:/oracle/arch01/rmag$ls -t1 *dbf| head2_1885370_909562248.dbf1_1534588_909562248.dbf1_1534587_909562248.dbf2_1885369_909562248.dbf2_1885368_909562248.dbf1_1534586_909562248.dbf2_1885367_909562248.dbf1_1534585_909562248.dbf2_1885366_909562248.dbf1_1534584_909562248.dbf以下是 RAC 开启归档，供参考。1修改 1 节点chown oracle:oinstall /arch1chmod 755 /arch1chown oracle:oinstall logs修改 2 节点chown oracle:oinstall /arch2chown oracle:oinstall logs2修改 1 节点参数alter system set log_archive_dest_1=\"LOCATION=/arch1/logs\" sid='ora11'修改 2 节点参数alter system set log_archive_dest_1=\"LOCATION=/arch2/logs\" sid='ora12';ALTER SYSTEM SET CLUSTER_DATABASE=FALSE SCOPE=spfile;3 开启shutdown immediate   --1 节点shutdown immediate   --2 节点startup mount        --1 节点alter database archivelog;  --1 节点alter database open; --1 节点shutdown immediate   --1 节点startup mount        --2 节点alter database archivelog; --2 节点alter database open; --2 节点 ALTER SYSTEM SET CLUSTER_DATABASE=TRUE SCOPE=spfile;  --2 节点shutdown immediate   --2 节点开启附加日志OGG 基于附加日志等进行实时传输，故需要打开相关日志确保可获取事务内容，通过下面的命令查看该状态select force_logging,supplemental_log_data_min from v$database;--若输出都为 NO，则需要通过命令修改，这里为了方便直接对数据库级别进行强制日志和增加附加日志，如果只需要对某个表增加附加日志，可以使用 alter table 命令，这样对数据库的影响较小alter database force logging;alter database add supplemental log data;设置参数如果要正常使用 OGG，需要设置参数 enable_goldengate_replication。这个参数在 11.2.0.4 和 12.1.0.2 以后才出现，用于启用 GoldenGate 复制功能。默认值为 FALSE，设置为 TRUE 后，数据库会启用 GoldenGate 复制功能，这样可以在数据库中创建 GoldenGate 复制配置。这个参数是动态参数，可以在数据库运行时设置。否则无法使用 OGG该参数主要控制支持新数据类型和操作逻辑复制所需的补充日志记录。由于重做日志文件（redo log file）设计用于物理方式应用到数据库，因此其默认内容通常不包含足够信息将记录的变更转换为 SQL 语句。补充日志（supplemental logging）会在重做日志文件中添加额外信息，使得复制系统无需为每个变更访问数据库即可将日志变更转换为 SQL 语句。此前这些额外变更由补充日志 DDL 控制，现在必须设置该参数才能为任何新数据类型或操作启用所需的补充日志记录。ENABLE_GOLDENGATE_REPLICATION支持逻辑复制所需的所有补充日志增强功能也由此参数控制。该参数控制的 RDBMS 服务包括（但不限于）：  GoldenGate Extract 使用的透明数据加密（Transparent Data Encryption，含表空间加密）工具  GoldenGate Extract 读取重做日志的服务  GoldenGate Replicat 抑制触发器触发的服务  GoldenGate Replicat 处理瞬时重复记录的服务  GoldenGate Replicat 绕过参照完整性检查的服务  在集成抽取（Integrated Extract）和集成复制（Integrated Replicat）模式下运行 Oracle GoldenGate 所需的服务--设置参数SQL&gt; alter system set enable_goldengate_replication=true scope=both;-- 也可以仅对指定的 ogg 用户设置exec dbms_goldengate_auth.grant_admin_privilege('ogguser','*',TRUE);-- streams_pool 根据需要设置大小，如果不清楚效果可以不用设置SQL&gt; alter system set streams_pool_size=2048M scope=both;配置 MGR在源端配置 MGR 进程，用于管理抽取进程和传输进程-- 进入 OGG 管理界面ggsci-- 创建目录GGSCI &gt; CREATE SUBDIRS-- 创建 MGR 进程GGSCI &gt; edit param mgr-- ogg 配置文件使用两个减号 -- 表示注释PORT 7809DYNAMICPORTLIST 8000-8050-- AUTOSTART extract-- AUTORESTART extract,retries 4,waitminutes 4STARTUPVALIDATIONDELAY 5-- 限制 ip port 的访问，如果不需要可以注释掉-- ACCESSRULE, PROG *, IPADDR 17X.1X.*, ALLOW-- ACCESSRULE, PROG *, IPADDR *, ALLOW-- ACCESSRULE, PROG SERVER, ALLOWACCESSRULE, PROG *, IPADDR *, ALLOWPURGEOLDEXTRACTS /u01/ogg/ogg21/dirdat/*, USECHECKPOINTS,MINKEEPFILES 3-- 启动GGSCI &gt; start mgr配置全局检查点表在 GLOBALS 参数文件中使用 CHECKPOINTTABLE 参数，可以指定一个默认的检查点表（checkpoint table）名称，该表可供一个或多个 Oracle GoldenGate 实例中的所有 Replicat 组使用。除非在创建 Replicat 组时使用 ADD REPLICAT 命令的 CHECKPOINTTABLE 选项覆盖此设置，否则所有通过 ADD REPLICAT 命令创建的 Replicat 组都将默认使用此表。要创建检查点表，请在 GGSCI 中使用 ADD CHECKPOINTTABLE 命令。Oracle 支持并建议为集成复制（Integrated Replicat）创建检查点表。GGSCI &gt; edit param ./GLOBALSggschema oggusercheckpointtable ogguser.ckpoint添加同步的表在源端添加需要同步的表，可以直接利用 sql 拼接sqlplus / as sysdbaset linesize 300 pagesize 300select 'add trandate '||owner||'.'||table_name from dba_tables where table_name in ('TABLE_NAME1','TABLE_NAME2');在 GGSCI 中执行上面的 sql 查询输出的结果，添加需要同步的表-- 需要注意的是，结尾没有分号ggsciGGSCI &gt; add trandata needtable.TABLE_NAME1配置抽取进程在源端配置抽取进程，用于抽取源端的数据-- e_uat_ka 是抽取进程的名字，可以自定义。 TRANLOG 是抽取的方式，BEGIN NOW 是从当前时间开始抽取。 BEGIN NOW 可以替换为 SCN 或者 TIMESTAMP。ggsci &gt; add extract e_uat_ka,TRANLOG, BEGIN NOW--ggsci &gt; ADD EXTTRAIL ./dirdat/ka,EXTRACT e_uat_ka, MEGABYTES 200-- 配置抽取进程的参数ggsci &gt; edit param e_uat_kaextract e_uat_kasetenv (NLS_LANG = \"american_america.UTF8\")setenv (ORACLE_HOME = \"/erp/uat/db/tech_st/11.2.0\")setenv (ORCLE_SID = \"orcl\")userid goldengate@orcl password \"OGG_user_123\"discardfile ./dirrpt/e_uat_ka.dsc,purge,megabytes 1024-- 如果源端和目标端的版本不一致，需要设置 FORMAT RELEASE 参数，如果一直可以不设置-- exttrail ./dirdat/ka, FORMAT RELEASE 12.2exttrail ./dirdat/kastatoptions reportfetchreportcount every 1 minutes,ratewarnlongtrans 1H,checkinterval 5mTABLE WMS_F.ACTTION_DETAILS;TABLE WMS_F.BASTION          ;配置传输进程在源端配置传输进程，用于传输抽取的数据到目标端-- p_uat_ka 是传输进程的名字，可以自定义。 EXTTRAILSOURCE 是抽取进程的 trail 文件路径ADD EXTRACT p_uat_ka,EXTTRAILSOURCE ./dirdat/kaADD RMTTRAIL /ogg/ogg21/dirdat/ka,EXTRACT p_uat_ka, MEGABYTES 200-- 配置传输进程的参数edit param p_uat_kaEXTRACT p_uat_kasetenv (NLS_LANG = \"american_america.UTF8\")setenv (ORACLE_HOME = \"/erpt2/uat/db/tech_st/11.2.0\")setenv (ORCLE_SID = \"U\")userid goldengate@orcl password \"OGG_user_123\"RMTHOST 12.2.1.11,MGRPORT 7809-- 如果源端和目标端的版本不一致，需要设置 FORMAT RELEASE 参数，如果一直可以不设置-- RMTTRAIL /ogg/ogg21/dirdat/ka FORMAT RELEASE 12.2RMTTRAIL /ogg/ogg21/dirdat/kadiscardfile  ./dirrpt/p_uat_ka.dsc,PURGE,megabytes 1024TABLE WMS_F.ACTTION_DETAILS;TABLE WMS_F.BASTION          ;生成表结构文件在源端生成表结构文件vi ./dirprm/mapping_uat_ka.prmdefsfile ./dirdef/mapping_uat_ka.def,purgeuserid goldengate@orcl password \"OGG_user_123\"TABLE WMS_F.ACTTION_DETAILS;TABLE WMS_F.BASTION          ; ./defgen paramfile ./dirprm/mapping_uat_ka.prm ## Definitions generated for 2 tables in ./dirdef/mapping_uat_ka.def.将生成的表结构文件传输到目标端scp ./dirdef/mapping_uat_ka.def root@12.2.19.11:/ogg/ogg21/dirdef/目标端配置 OGG配置 MGR– 在目标端配置 MGR 进程，用于管理恢复进程GGSCI &gt; CREATE SUBDIRSGGSCI &gt; edit param mgrPORT 7809DYNAMICPORTLIST 8000-8050STARTUPVALIDATIONDELAY 5ACCESSRULE, PROG *, IPADDR *, ALLOWPURGEOLDEXTRACTS ./dirdat/*, USECHECKPOINTS,MINKEEPFILES 3全局检查点表####### 经过测试如果只是在GGSCI &gt; edit  param  ./GLOBALSCHECKPOINTTABLE  okafka.checkpoint配置复制进程恢复至同一个 topic在恢复之前不需要手动先创建 topic，ogg 在恢复数据的时候会自动创建 topic，但是默认只会有一个分区，如果需要多个分区就需要提前手动创建 topic。如果恢复至一个 topic 的话，所有的数据都在一起。可以在验证阶段查看数据。设置输出格式Using the Pluggable Formatters (oracle.com)在 ogg21.7 之后已经不支持insertOpKey | updateOpKey | deleteOpKey | truncateOpKey | includeTableName | includeOpTimestamp | includeOpType | includePosition | includeCurrentTimestamp, useIso8601Format，仅支持通过参数gg.handler.name.format.metaColumnsTemplate配置。这里需要注意，和低版本的配置不同As of Oggbd 21.7.x, we have the following metaColumnsTemplategg.handler.name.format.metaColumnsTemplate=${objectname[table]},${optype[op_type]},${timestamp[op_ts]},${currenttimestamp[current_ts]},${position[pos]},${primarykeycolumns[primary_keys]},${alltokens[tokens]}Would like to get the replicat name/ groupname also added复制进程配置edit param r_uat_kaREPLICAT r_uat_kasourcedefs ./dirdef/mapping_uat_ka.defTARGETDB LIBFILE libggjava.so SET property=dirprm/kafka.propsREPORTCOUNT EVERY 1 MINUTES, RATEGROUPTRANSOPS 10000MAP auser.ftablename, TARGET okafka_all.ftablename;MAP AR.hz_parties, TARGET okafka_all.hz_parties;### 关于 gg.handler.kafkahandler.format.metaColumnsTemplate 高版本和低版本的写法不一样，如果 flink 的版本较低的话，只能识别旧的写法，op_ts，op_type 之类的简写，从 21c 开始同时支持单次全拼或简写，且vim dirprm/kafka.propsgg.handlerlist=kafkahandlergg.handler.kafkahandler.type=kafkagg.handler.kafkahandler.KafkaProducerConfigFile=custom_kafka_producer.propertiesgg.handler.kafkahandler.topicMappingTemplate=okafka_allgg.handler.kafkahandler.format=jsongg.handler.kafkahandler.mode=opgg.handler.kafkahandler.format.insertOpKey = Igg.handler.kafkahandler.format.updateOpKey = Ugg.handler.kafkahandler.format.deleteOpKey = Dgg.handler.kafkahandler.format.metaColumnsTemplate=${optype[op_type]},${objectname[table]},${timestamp[op_ts]},${currenttimestampmicro[current_ts]},${position[pos]},${primarykeycolumns[primary_keys]}goldengate.userexit.timestamp=utc+8goldengate.userexit.writers=javawriterjavawriter.stats.display=truejavawriter.stats.full=truegg.classpath=dirprm/:/usr/bigtop/3.2.0/usr/lib/kafka/libs/*:/ogg/ogg21/:/ogg/ogg21/lib/*#####vim custom_kafka_producer.propertiesbootstrap.servers=bigdata01:9092acks=1compression.type=gzipreconnect.backoff.ms=1000value.serializer=org.apache.kafka.common.serialization.ByteArraySerializerkey.serializer=org.apache.kafka.common.serialization.ByteArraySerializerbatch.size=102400linger.ms=10000####add replicat r_uat_ka exttrail ./dirdat/ka,checkpointtable okafka.checkpoint恢复至多个 topic将每张表的数据恢复至单独的一个 topic，这样可以更好的管理数据，不过配置步骤多一些auser.ftablename## auser.ftablenameedit param r_ka01REPLICAT r_ka01sourcedefs ./dirdef/mapping_uat_ka.defTARGETDB LIBFILE libggjava.so SET property=dirprm/kafka01.propsREPORTCOUNT EVERY 1 MINUTES, RATEGROUPTRANSOPS 10000MAP auser.ftablename, TARGET applsys_ftablename.ftablename;###vim dirprm/kafka01.propsgg.handlerlist=kafkahandlergg.handler.kafkahandler.type=kafkagg.handler.kafkahandler.KafkaProducerConfigFile=custom_kafka_producer.propertiesgg.handler.kafkahandler.topicMappingTemplate=applsys_ftablename ## 这里需要替换为实际的 topic 名称gg.handler.kafkahandler.format=jsongg.handler.kafkahandler.mode=opgg.handler.kafkahandler.format.insertOpKey = Igg.handler.kafkahandler.format.updateOpKey = Ugg.handler.kafkahandler.format.deleteOpKey = Dgg.handler.kafkahandler.format.metaColumnsTemplate=${optype[op_type]},${objectname[table]},${timestamp[op_ts]},${currenttimestampmicro[current_ts]},${position[pos]},${primarykeycolumns[primary_keys]}goldengate.userexit.timestamp=utc+8goldengate.userexit.writers=javawriterjavawriter.stats.display=truejavawriter.stats.full=truegg.classpath=dirprm/:/usr/bigtop/3.2.0/usr/lib/kafka/libs/*:/ogg/ogg21/:/ogg/ogg21/lib/*#####vim custom_kafka_producer.propertiesbootstrap.servers=bigdata01:9092acks=1compression.type=gzipreconnect.backoff.ms=1000value.serializer=org.apache.kafka.common.serialization.ByteArraySerializerkey.serializer=org.apache.kafka.common.serialization.ByteArraySerializerbatch.size=102400linger.ms=10000####add replicat r_ka01 exttrail ./dirdat/ka,checkpointtable okafka.checkpointAR.hz_parties## AR.hz_partiesedit param r_ka02REPLICAT r_ka02sourcedefs ./dirdef/mapping_uat_ka.defTARGETDB LIBFILE libggjava.so SET property=dirprm/kafka02.propsREPORTCOUNT EVERY 1 MINUTES, RATEGROUPTRANSOPS 10000MAP AR.hz_parties, TARGET ar_hz_parties.hz_parties;###vim dirprm/kafka02.propsgg.handlerlist=kafkahandlergg.handler.kafkahandler.type=kafkagg.handler.kafkahandler.KafkaProducerConfigFile=custom_kafka_producer.propertiesgg.handler.kafkahandler.topicMappingTemplate=ar_hz_partiesgg.handler.kafkahandler.format=jsongg.handler.kafkahandler.mode=opgg.handler.kafkahandler.format.insertOpKey = Igg.handler.kafkahandler.format.updateOpKey = Ugg.handler.kafkahandler.format.deleteOpKey = Dgg.handler.kafkahandler.format.metaColumnsTemplate=${optype[op_type]},${objectname[table]},${timestamp[op_ts]},${currenttimestampmicro[current_ts]},${position[pos]},${primarykeycolumns[primary_keys]}goldengate.userexit.timestamp=utc+8goldengate.userexit.writers=javawriterjavawriter.stats.display=truejavawriter.stats.full=truegg.classpath=dirprm/:/usr/bigtop/3.2.0/usr/lib/kafka/libs/*:/ogg/ogg21/:/ogg/ogg21/lib/*#####vim custom_kafka_producer.propertiesbootstrap.servers=bigdata01:9092acks=1compression.type=gzipreconnect.backoff.ms=1000value.serializer=org.apache.kafka.common.serialization.ByteArraySerializerkey.serializer=org.apache.kafka.common.serialization.ByteArraySerializerbatch.size=102400linger.ms=10000####add replicat r_ka02 exttrail ./dirdat/ka,checkpointtable okafka.checkpoint全量恢复启动对应的进程在恢复之前需要先启动对应的进程## 源端和目标端先开启 mgrstart mgr## 源端开启抽取和传输进程start E_UAT_KAstart P_UAT_KA源端抽取数据## 全量 在源端的 OGG 中抽取数据ggsci&gt; edit params ei_kaSOURCEISTABLEsetenv (NLS_LANG = \"american_america.UTF8\")setenv (ORACLE_HOME = \"/erttdb02/uat/db/tech_st/11.2.0\")setenv (ORCLE_SID = \"orcl\")userid goldengate@ password \"OGG_user_123\"RMTHOST 1.1.1.1,MGRPORT 7809RMTFILE /ogg/ogg21/dirdat/ka,maxfiles 100,megabytes 1024,purgeTABLE AYS.fup_values;TABLE A.hzties;#### 启动并查看抽取进程正常shell&gt; nohup ./extract paramfile ./dirprm/ei_ka.prm reportfile ./dirrpt/ei_ka.rpt &amp;目标端恢复数据恢复至同一个 topicshell&gt; ggsciggsci&gt; edit params ri_uat_kaSPECIALRUNEND RUNTIMEtargetdb  LIBFILE libggjava.so SET property=dirprm/kafka.propsREPORTCOUNT EVERY 1 MINUTES, RATEEXTFILE ./dirdat/kaDISCARDFILE ./dirrpt/ri_uat_ka.dsc,purgeGROUPTRANSOPS 10000MAP AP.fnd_values, TARGET okafka_all.fnkup_values;MAP AR.hpties, TARGET okafka_all.hzties;#### 启动并查看回放进程是否正常shell&gt; nohup ./replicat paramfile ./dirprm/ri_uat_ka.prm reportfile ./dirrpt/ri_uat_ka.rpt &amp;分开恢复如果需要将每张表的数据恢复至单独的一个 topic，需要单独配置恢复进程。例如按照不同的 schema 恢复数据，或者不同的表恢复数据APS.fnd_lvalueshell&gt; ggsciggsci&gt; edit params ri_uat_ka01SPECIALRUNEND RUNTIMEtargetdb  LIBFILE libggjava.so SET property=dirprm/kafka01.propsREPORTCOUNT EVERY 1 MINUTES, RATEEXTFILE ./dirdat/kaDISCARDFILE ./dirrpt/ri_uat_ka01.dsc,purgeGROUPTRANSOPS 10000MAP APS.fnd_values, TARGET apps_fndup_values.f_loup_vaes;#### 启动并查看回放进程是否正常shell&gt; nohup ./replicat paramfile ./dirprm/ri_uat_ka01.prm reportfile ./dirrpt/ri_uat_ka01.rpt &amp;AR.hz_rtiesshell&gt; ggsciggsci&gt; edit params ri_uat_ka02SPECIALRUNEND RUNTIMEtargetdb  LIBFILE libggjava.so SET property=dirprm/kafka02.propsREPORTCOUNT EVERY 1 MINUTES, RATEEXTFILE ./dirdat/kaDISCARDFILE ./dirrpt/ri_uat_ka02.dsc,purgeGROUPTRANSOPS 10000MAP AR.hz_parties, TARGET ar_hz_parties.hz_parties;#### 启动并查看回放进程是否正常shell&gt; nohup ./replicat paramfile ./dirprm/ri_uat_ka02.prm reportfile ./dirrpt/ri_uat_ka02.rpt &amp;数据验证如果多张表的数据都在同一个 topic，查看的时候只需要指定 topic 就行，数据是按照更新的时间排序的。查看内容在命令行查看 topic 的内容时，默认会持续打印数据，只能手动结束（crtl+c），可以将数据重定向至一个文件方便查看。## 查看所有 topickafka-topics.sh --list --zookeeper localhost:2181## 查看数据shell1&gt; kafka-console-consumer.sh --bootstrap-server bigdata01:9092  --topic okafka_all --from-beginning &gt; /tmp/kafka_okafka_all.txtshell2&gt; [root@bigdata01 ogg21]# tail -2 /tmp/kafka_okafka_all.txt格式在第一次全量恢复数据或者复制进程恢复数据的时候并没有 before 属性，只有在更新/删除操作发生之后才会有 before 属性信息。低版本默认格式            flink 格式仅支持低版本的简写：[Ogg      Apache Flink](https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/connectors/table/formats/ogg/)      {  \"before\": {    \"id\": 111,    \"name\": \"scooter\",    \"description\": \"Big 2-wheel scooter\",    \"weight\": 5.18  },  \"after\": {    \"id\": 111,    \"name\": \"scooter\",    \"description\": \"Big 2-wheel scooter\",    \"weight\": 5.15  },  \"op_type\": \"U\",  \"op_ts\": \"2020-05-13 15:40:06.000000\",  \"current_ts\": \"2020-05-13 15:40:07.000000\",  \"primary_keys\": [    \"id\"  ],  \"pos\": \"00000000000000000000143\",  \"table\": \"PRODUCTS\"}高版本格式使用单词全拼gg.handler.kafkahandler.format.metaColumnsTemplate=${optype},${objectname},${timestamp},${currenttimestampmicro},${position},${primarykeycolumns}{    \"after\": {        \"CONTENT\": \"ttt\",        \"ID\": 5    },    \"before\": {        \"CONTENT\": \"tessst\",        \"ID\": 5    },    \"currenttimestampmicro\": 1694662000110000,    \"objectname\": \"wxj.TEST_OGG\",    \"optype\": \"U\",    \"position\": \"00000000000000003225\",    \"primarykeycolumns\": [        \"ID\"    ],    \"timestamp\": \"2023-09-14 11:26:34.369566\"}兼容低版本简写gg.handler.kafkahandler.format.metaColumnsTemplate=${optype[op_type]},${objectname[table]},${timestamp[op_ts]},${currenttimestampmicro[current_ts]},${position[pos]},${primarykeycolumns[primary_keys]}{    \"after\": {        \"CONTENT\": \"ttt\",        \"ID\": 6    },    \"before\": {        \"CONTENT\": \"tessst\",        \"ID\": 6    },    \"current_ts\": 1694670588735000,    \"op_ts\": \"2023-09-14 13:49:43.433581\",    \"op_type\": \"U\",    \"pos\": \"00000000000000003539\",    \"primary_keys\": [        \"ID\"    ],    \"table\": \"wxj.TEST_OGG\"}"
  },
  
  {
    "title": "Oracle-编译-bbed",
    "url": "/posts/Oracle-%E7%BC%96%E8%AF%91-bbed/",
    "categories": "DataBase, Oracle",
    "tags": "bbed",
    "date": "2025-02-26 15:53:42 +0800",
    





    
    "snippet": "前言记录一下 Oracle 编译 bbed 的过程，方便后续查询Oracle 11g  编译 bbed通过 ins_rdbms.mk 编译 bbed ，Oracle 的很多工具都是通过 ins_rdbms.mk 编译的┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/lib]└──╼ $ cd $ORACLE_HO...",
    "content": "前言记录一下 Oracle 编译 bbed 的过程，方便后续查询Oracle 11g  编译 bbed通过 ins_rdbms.mk 编译 bbed ，Oracle 的很多工具都是通过 ins_rdbms.mk 编译的┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/lib]└──╼ $ cd $ORACLE_HOME/rdbms/lib┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ ll ins_rdbms.mk-rw-r--r-- 1 oracle oinstall 40983 Aug 24  2013 ins_rdbms.mk┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ locate ins_rdbms.mk/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/ins_rdbms.mk编译的时候生成的文件必须在$ORACLE_HOME/rdbms/lib/路径下，否则会提示错误，可以在编译完成之后移动位置┌─[✗]─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ make -f ins_rdbms.mk $ORACLE_HOME/rdbms/lib/bbedLinking BBED utility (bbed)rm -f /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/bbedgcc -o /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/bbed -m64 -z noexecstack -L/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/ -L/u01/app/oracle/product/11.2.0/dbhome_1/lib/ -L/u01/app/oracle/product/11.2.0/dbhome_1/lib/stubs/  /u01/app/oracle/product/11.2.0/dbhome_1/lib/s0main.o /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/ssbbded.o /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/sbbdpt.o `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -ldbtools11 -lclntsh  `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -lnro11 `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -lnnz11 -lzt11 -lztkg11 -lclient11 -lnnetd11  -lvsn11 -lcommon11 -lgeneric11 -lmm -lsnls11 -lnls11  -lcore11 -lsnls11 -lnls11 -lcore11 -lsnls11 -lnls11 -lxml11 -lcore11 -lunls11 -lsnls11 -lnls11 -lcore11 -lnls11 `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -lnro11 `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -lclient11 -lnnetd11  -lvsn11 -lcommon11 -lgeneric11   -lsnls11 -lnls11  -lcore11 -lsnls11 -lnls11 -lcore11 -lsnls11 -lnls11 -lxml11 -lcore11 -lunls11 -lsnls11 -lnls11 -lcore11 -lnls11 -lclient11 -lnnetd11  -lvsn11 -lcommon11 -lgeneric11 -lsnls11 -lnls11  -lcore11 -lsnls11 -lnls11 -lcore11 -lsnls11 -lnls11 -lxml11 -lcore11 -lunls11 -lsnls11 -lnls11 -lcore11 -lnls11   `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/sysliblist` -Wl,-rpath,/u01/app/oracle/product/11.2.0/dbhome_1/lib -lm    `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/sysliblist` -ldl -lm   -L/u01/app/oracle/product/11.2.0/dbhome_1/libgcc: error: /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/ssbbded.o: No such file or directorygcc: error: /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/sbbdpt.o: No such file or directorymake: *** [/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/bbed] Error 1只有在 Oracle 10g 的安装包才提供相关的 ssbbded.o 依赖包，在 10g 之后的版本都没有提供相关的依赖包，所以需要去 Oracle 10g 的安装包中找到相关的依赖包。在这里也可以下载┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ cp /mnt/h/BaiduNetdiskDownload/OraclePackages/编译需要的 10g 依赖包/* .┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ ll /mnt/h/BaiduNetdiskDownload/OraclePackages/编译需要的 10g 依赖包/total 64-rwxrwxrwx 1 oracle oinstall  8704 Feb 23 17:53 bbedus.msb-rwxrwxrwx 1 oracle oinstall 10270 Feb 23 17:53 bbedus.msg-rwxrwxrwx 1 oracle oinstall  3976 Feb 23 17:53 sbbdpt.o-rwxrwxrwx 1 oracle oinstall  3306 Feb 23 17:53 ssbbded.o┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $# 后续发现 bbedus.msb 和 bbedus.msg 文件需要放到 $ORACLE_HOME/rdbms/mesg 目录下下载好相关的依赖包之后，再次编译就可以了┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ make -f ins_rdbms.mk $ORACLE_HOME/rdbms/lib/bbedLinking BBED utility (bbed)rm -f /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/bbedgcc -o /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/bbed -m64 -z noexecstack -L/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/ -L/u01/app/oracle/product/11.2.0/dbhome_1/lib/ -L/u01/app/oracle/product/11.2.0/dbhome_1/lib/stubs/  /u01/app/oracle/product/11.2.0/dbhome_1/lib/s0main.o /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/ssbbded.o /u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib/sbbdpt.o `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -ldbtools11 -lclntsh  `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -lnro11 `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -lnnz11 -lzt11 -lztkg11 -lclient11 -lnnetd11  -lvsn11 -lcommon11 -lgeneric11 -lmm -lsnls11 -lnls11  -lcore11 -lsnls11 -lnls11 -lcore11 -lsnls11 -lnls11 -lxml11 -lcore11 -lunls11 -lsnls11 -lnls11 -lcore11 -lnls11 `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -lnro11 `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/ldflags`    -lncrypt11 -lnsgr11 -lnzjs11 -ln11 -lnl11 -lclient11 -lnnetd11  -lvsn11 -lcommon11 -lgeneric11   -lsnls11 -lnls11  -lcore11 -lsnls11 -lnls11 -lcore11 -lsnls11 -lnls11 -lxml11 -lcore11 -lunls11 -lsnls11 -lnls11 -lcore11 -lnls11 -lclient11 -lnnetd11  -lvsn11 -lcommon11 -lgeneric11 -lsnls11 -lnls11  -lcore11 -lsnls11 -lnls11 -lcore11 -lsnls11 -lnls11 -lxml11 -lcore11 -lunls11 -lsnls11 -lnls11 -lcore11 -lnls11   `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/sysliblist` -Wl,-rpath,/u01/app/oracle/product/11.2.0/dbhome_1/lib -lm    `cat /u01/app/oracle/product/11.2.0/dbhome_1/lib/sysliblist` -ldl -lm   -L/u01/app/oracle/product/11.2.0/dbhome_1/lib┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ ll bbed-rwxr-xr-x 1 oracle oinstall 261816 Feb 23 17:56 bbed┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $默认密码为 blockedit执行 bbed 报错┌─[✗]─[oracle@TheDarkStar]─[~]└──╼ $ bbedMessage 112 not found; No message file for product=RDBMS, facility=BBEDBBED-00113: file not found如果执行 bbed 报错，需要将两个bbedus.ms*  文件放到 $ORACLE_HOME/rdbms/mesg 目录下参考┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ mv bbedus.msbbedus.msb  bbedus.msg┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ mv bbedus.ms* ../mesg/Display all 203 possibilities? (y or n)┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ mv bbedus.ms* $ORACLE_HOME/rdbms/mesg/┌─[oracle@TheDarkStar]─[/u01/app/oracle/product/11.2.0/dbhome_1/rdbms/lib]└──╼ $ bbed ## 密码是 blockeditPassword:BBED: Release 2.0.0.0.0 - Limited Production on Sun Feb 23 21:29:10 2025Copyright (c) 1982, 2011, Oracle and/or its affiliates.  All rights reserved.************* !!! For Oracle Internal Use only !!! ***************BBED&gt; quit"
  },
  
  {
    "title": "ojdbc-连接 Oracle 实例提示 ora-01034 和 ora-27101",
    "url": "/posts/ojdbc-%E8%BF%9E%E6%8E%A5Oracle%E5%AE%9E%E4%BE%8B%E6%8F%90%E7%A4%BAora-01034%E5%92%8Cora-27101/",
    "categories": "DataBase, Oracle",
    "tags": "ojdbc",
    "date": "2025-02-22 22:24:34 +0800",
    





    
    "snippet": "前言同事反馈连接 Oracle 实例时提示 ora-01034 和 ora-27101 错误，这个问题通常是由于 Oracle 实例没有启动引起的处理过程检查 Oracle 实例状态检查 Oracle 实例是否已经启动，可以通过以下命令查看 Oracle 实例状态：# 查看 Oracle 实例状态ps -ef | grep pmon# 查看 Oracle 实例监听状态lsnrctl stat...",
    "content": "前言同事反馈连接 Oracle 实例时提示 ora-01034 和 ora-27101 错误，这个问题通常是由于 Oracle 实例没有启动引起的处理过程检查 Oracle 实例状态检查 Oracle 实例是否已经启动，可以通过以下命令查看 Oracle 实例状态：# 查看 Oracle 实例状态ps -ef | grep pmon# 查看 Oracle 实例监听状态lsnrctl status# 直接 sqlplus 连接sqlplus / as sysdba检查发现 Oracle 实例状态运行正常，alert 日志也没有异常信息，但是程序连接 Oracle 实例时提示 ora-01034 和 ora-27101 错误。查看监听和服务状态也是正常的。这里就不贴图了自己尝试利用 SQL plus 远程连接 Oracle 实例，发现可以正常连接，但是程序连接时还是报错。这个问题就比较奇怪了，因为程序连接 Oracle 实例和 SQL plus 连接 Oracle 实例是一样的，为什么程序连接时会报错呢？询问得知开发同事使用的工具是 工具 datagrip，驱动 ojdbc8在我的电脑上没有这个工具，所有尝试直接使用 ojedbc8 连接 Oracle 实例，发现可以正常连接。进一步得知测试环境可以正常连接，只有生产环境连接时才会报错。这个问题就比较奇怪了，因为生产环境和测试环境的 Oracle 实例是一样的，不同的是测试环境使用的是 Oracle 19c 的 no-cdb 模式，生产环境使用的是 Oracle 19c 的 cdb 模式。因为最初的环境并不是我搭建的，突然反馈说有问题才介入排查使用 ojdbc8 连接 Oracle 19c 实例因为没有对应的工具，所以这里直接使用 ojdbc8 驱动连接 Oracle 19c 实例，连接代码如下：import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;import oracle.jdbc.OracleDriver;public class OracleConnection {    public static void main(String[] args) {        String jdbcUrl = \"jdbc:oracle:thin:@//192.168.200.207:1521/orclpdb1\";        String username = \"testuser\";        String password = \"Qu32-8Sdf\";        try {            // 注册驱动            DriverManager.registerDriver(new OracleDriver());            // 建立连接            Connection conn = DriverManager.getConnection(jdbcUrl, username, password);            System.out.println(\"连接成功！\");            // 关闭连接            conn.close();        } catch (SQLException e) {            System.err.println(\"连接失败：\");            e.printStackTrace();        }    }}编译运行ojdbc8.jar 驱动不需要单独下载，直接在 ll $ORACLE_HOME/jdbc/lib/ojdbc.jar 中拷贝到代码所在的目录即可，如果不确定位置可以使用 locate ojdbc8.jar 查找javac -cp ojdbc8.jar OracleConnection.javajava -cp .:ojdbc8.jar OracleConnection尝试更换工具因为已经尝试使用使用 SQL plus 和 ojdbc8 连接 Oracle 19c 实例是可以正常连接的，所以这里尝试更换工具。为什么 datagrip 连接 Oracle 19c 实例会报错，怀疑是工具的问题，因为需要通过堡垒机配置环境才能使用图形工具，比较麻烦，所以就让开发同事自己更换工具测试一下第二天更换工具 navicat 之后，发现还是无法正常连接实例。之前也已经检查过监听和 sqlnet.ora 文件配置正常，如果有问题我使用 ojdbc8 连接 Oracle 19c 实例也应该无法连接。查找了一些资料，基本都是无法实例异常才会有这个问题，但是环境中的实例都是正常的，日志也是正常，这个时候开发同事反馈说其实什么工具不重要，重要的抽数工具能够使用就行。询问抽数工具使用的是 flink，本质上也是通过 jdbc 连接 Oracle 实例让开发同事提供了 flink 连接报错的截图如下发现数据库连接串的 url 貌似存在问题，让开发同事将连接串从 jdbc:oracle:thin:@192.168.200.207:1521:orclpdb1 修改为 jdbc:oracle:thin:@//192.168.200.207:1521/orclpdb1 之后，flink 就可以正常连接 Oracle 19c 实例了，19c 多租户模式需要通过服务名连接，而不是 sid。默认情况下，在 PDB 创建时就会为 PDB 生成对应的服务。总结一开始的截图遮挡住了 url 信息，导致没有发现问题，这个问题就是 url 连接串的问题，连接串的格式不对，导致连接失败。这个问题也是比较常见的，连接串的格式不对，导致连接失败。以为 url 是通过配置自动生成的，所以没有怀疑 url 的问题，但是 url 的格式不对，导致连接失败。后续查看到新的截图才发现问题JDBC 连接 ORACLE 的三种 URL 格式  SID 格式：    jdbc:oracle:thin:@&lt;host&gt;:&lt;port&gt;:&lt;sid&gt;        Service Name 格式：    jdbc:oracle:thin:@//&lt;host&gt;:&lt;port&gt;/&lt;service_name&gt;        TNS 格式：    jdbc:oracle:thin:@&lt;tns_name&gt;      "
  },
  
  {
    "title": "Fedora-升级之后-setlocale-错误",
    "url": "/posts/Fedora-%E5%8D%87%E7%BA%A7%E4%B9%8B%E5%90%8E-setlocale-%E9%94%99%E8%AF%AF/",
    "categories": "Linux, Fedora",
    "tags": "locale",
    "date": "2025-02-22 21:48:35 +0800",
    





    
    "snippet": "前言fedora 40 升级 fedora 41 之后，出现了 setlocale 错误。这个问题通常是由于缺少相应的 locale 配置引起的，可能会导致一些特定命令或应用无法正常工作。升级前已经安装配置了字符集，可能是升级之后执行了 autoremove 之后自动清理了-bash: warning: setlocale: LC_CTYPE: cannot change locale (e...",
    "content": "前言fedora 40 升级 fedora 41 之后，出现了 setlocale 错误。这个问题通常是由于缺少相应的 locale 配置引起的，可能会导致一些特定命令或应用无法正常工作。升级前已经安装配置了字符集，可能是升级之后执行了 autoremove 之后自动清理了-bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory-bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory-bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory-bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory-bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory-bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory解决方法检查 locale 配置检查系统上是否已经安装了所需的 locale。可以通过以下命令查看已安装的 locale：locale -a┌─[wxj@DarkStar]─[~]└──╼ $ locale -aCC.utf8POSIX确保在输出中能够找到 “en_US.UTF-8”，如果没有，我们需要添加这个 locale。安装缺失的 locale使用以下命令安装缺失的 locale（以”en_US.UTF-8”为例），提示缺少什么字符集就安装什么：# 安装缺失的 localesudo dnf install glibc-langpack-en┌─[wxj@DarkStar]─[~]└──╼ $ sudo dnf install -y glibc-langpack-enUpdating and loading repositories:Repositories loaded.Package                                                             Arch            Version                                                              Repository                                 SizeInstalling: glibc-langpack-en                                                  x86_64          2.40-21.fc41                                                         updates                                 5.7 MiBTransaction Summary: Installing:         1 packageTotal size of inbound packages is 641 KiB. Need to download 641 KiB.After this operation, 6 MiB extra will be used (install 6 MiB, remove 0 B).[1/1] glibc-langpack-en-0:2.40-21.fc41.x86_64                                                                                                                   100% | 862.2 KiB/s | 640.6 KiB |  00m01s[1/1] Total                                                                                                                                                     100% | 667.3 KiB/s | 640.6 KiB |  00m01sRunning transaction[1/3] Verify package files                                                                                                                                      100% | 333.0   B/s |   1.0   B |  00m00s[2/3] Prepare transaction                                                                                                                                       100% |   6.0   B/s |   1.0   B |  00m00s[3/3] Installing glibc-langpack-en-0:2.40-21.fc41.x86_64                                                                                                        100% |  42.5 MiB/s |   5.8 MiB |  00m00sComplete!安装之后重新登陆就不会再提示错误，如果想要指定对应的系统 locale，可以按照以下步骤设置，保持默认的配置就不需要再执行以下操作了更新配置更新系统配置，使新的 locale 生效：sudo localectl set-locale LANG=en_US.UTF-8重启系统为了确保 locale 的改变生效，重新启动系统：sudo reboot验证重新登录系统后，再次运行 locale 命令，确保 “en_US.UTF-8” 出现在列表中。locale之后就不会收到 “cannot change locale” 的错误提示"
  },
  
  {
    "title": "fedora41 编译 Linux 内核 6.6.75.1 提示“openssl engine.h No such file or directory”",
    "url": "/posts/fedora41%E7%BC%96%E8%AF%91Linux%E5%86%85%E6%A0%B86.6.75.1%E6%8F%90%E7%A4%BA-openssl-engine.h-No-such-file-or-directory/",
    "categories": "Linux, kenel",
    "tags": "openssl",
    "date": "2025-02-22 21:10:18 +0800",
    





    
    "snippet": "前言在 wsl Fedora 41 上编译 Linux 内核提示 openssl/engine.h: No such file or directory 错误。┌─[wxj@DarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1]└──╼ $ make -j$(nproc) KCONFIG_CONFIG=Micro...",
    "content": "前言在 wsl Fedora 41 上编译 Linux 内核提示 openssl/engine.h: No such file or directory 错误。┌─[wxj@DarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1]└──╼ $ make -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl...........rm -f /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/bpf/resolve_btfids/libsubcmd/libsubcmd.a &amp;&amp; ar rcs /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/bpf/resolve_btfids/libsubcmd/libsubcmd.a /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/bpf/resolve_btfids/libsubcmd/libsubcmd-in.o  HOSTCC  scripts/selinux/genheaders/genheaders  YACC    scripts/genksyms/parse.tab.[ch]  HOSTCC  scripts/selinux/mdp/mdp  LEX     scripts/genksyms/lex.lex.c  HOSTCC  scripts/genksyms/parse.tab.o  HOSTCC  scripts/genksyms/lex.lex.o  HOSTLD  scripts/genksyms/genksyms  HOSTCC  scripts/kallsyms  HOSTCC  scripts/sorttable  HOSTCC  scripts/asn1_compiler  HOSTCC  scripts/sign-filescripts/sign-file.c:30:10: fatal error: openssl/engine.h: No such file or directory   30 | #include &lt;openssl/engine.h&gt;      |          ^~~~~~~~~~~~~~~~~~compilation terminated.make[2]: *** [scripts/Makefile.host:114: scripts/sign-file] Error 1make[1]: *** [/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/Makefile:1185: scripts] Error 2make[1]: *** Waiting for unfinished jobs....gcc /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/objtool/objtool-in.o -lelf /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/objtool/libsubcmd/libsubcmd.a   -o /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/objtool/objtoolrm -f -f /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/bpf/resolve_btfids/libbpf/libbpf.a; ar rcs /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/bpf/resolve_btfids/libbpf/libbpf.a /software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1/tools/bpf/resolve_btfids/libbpf/staticobjs/libbpf-in.omake: *** [Makefile:234: __sub-make] Error 2通过 dnf provides */engine.h 查找到 openssl-devel 包提供了 engine.h 文件。通过官方的升级文档将 fedora 40 升级到 fedora 41 后，编译 Linux 内核遇到的错误。自己编译 wsl 的 Linux 内核方法可以参考之前的一篇文章编译 wsl 内核。解决方法安装 openssl-devel-engine 包。寻找提供头文件的包# 已经确认 openssl-devel 包已经安装rpm -qa | grep openssl-devel# 查找 engine.h 文件sudo updates┌─[wxj@DarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1]└──╼ $ locate engine.h | grep openssl┌─[✗]─[wxj@DarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1]└──╼ $# 寻找提供 engine.h 文件的包┌─[wxj@DarkStar]─[/data/myself-blog]└──╼ $  dnf provides */engine.hUpdating and loading repositories: Fedora 41 openh264 (From Cisco) - x86_64                                                                                                                       100% |   1.4 KiB/s |   6.3 KiB |  00m05s Fedora 41 - x86_64                                                                                                                                             100% |   4.4 MiB/s |  62.0 MiB |  00m14s Microsoft Production                                                                                                                                           100% | 111.2 KiB/s |  11.6 MiB |  01m46s Fedora 41 - x86_64 - Updates                                                                                                                                   100% |   3.0 MiB/s |  26.5 MiB |  00m09sRepositories loaded.openssl-devel-engine-1:3.2.4-1.fc41.x86_64 : Files for development of applications which will use OpenSSL and use deprecated ENGINE API.Repo         : @SystemMatched From :Filename     : /usr/include/openssl/engine.harm-none-eabi-gcc-cs-1:14.1.0-2.fc41.x86_64 : GNU GCC for cross-compilation for arm-none-eabi targetRepo         : fedoraMatched From :Filename     : /usr/lib/gcc/arm-none-eabi/14.1.0/plugin/include/analyzer/engine.hastrometry-devel-0.96-2.fc41.x86_64 : Development files for astrometryRepo         : fedoraMatched From :Filename     : /usr/include/astrometry/engine.havr-gcc-1:14.2.0-1.fc41.x86_64 : Cross Compiling GNU GCC targeted at avrRepo         : fedoraMatched From :...........Filename     : /usr/include/pgm/engine.hopenssl-devel-engine-1:3.2.2-9.fc41.i686 : Files for development of applications which will use OpenSSL and use deprecated ENGINE API.Repo         : fedoraMatched From :Filename     : /usr/include/openssl/engine.hopenssl-devel-engine-1:3.2.2-9.fc41.x86_64 : Files for development of applications which will use OpenSSL and use deprecated ENGINE API.Repo         : fedoraMatched From :Filename     : /usr/include/openssl/engine.hpython3-torch-2.4.0-7.fc41.x86_64 : PyTorch AI/ML frameworkRepo         : fedoraMatched From :Filename     : /usr/lib64/python3.13/site-packages/torch/include/torch/csrc/autograd/engine.hpython3-torch-rocm-gfx9-2.4.0-7.fc41.x86_64 : python-torch for ROCm gfx9Repo         : fedoraMatched From :Filename     : /usr/lib64/rocm/gfx9/lib64/python3.13/site-packages/torch/include/torch/csrc/autograd/engine.hqpid-proton-c-devel-0.38.0-9.fc41.i686 : Development libraries for writing messaging apps with Qpid ProtonRepo         : fedoraMatched From :# 可以看到很多文件都提供了 engine.h 文件，但是我们需要的是 openssl 的 engine.h 文件└──╼ $  dnf provides */engine.h | grep -i opensslUpdating and loading repositories:Repositories loaded.openssl-devel-engine-1:3.2.4-1.fc41.x86_64 : Files for development of applications which will use OpenSSL and use deprecated ENGINE API.Filename     : /usr/include/openssl/engine.hmingw32-openssl-3.2.2-2.fc41.noarch : MinGW port of the OpenSSL toolkitFilename     : /usr/i686-w64-mingw32/sys-root/mingw/include/openssl/engine.hmingw64-openssl-3.2.2-2.fc41.noarch : MinGW port of the OpenSSL toolkitFilename     : /usr/x86_64-w64-mingw32/sys-root/mingw/include/openssl/engine.hopenssl-devel-engine-1:3.2.2-9.fc41.i686 : Files for development of applications which will use OpenSSL and use deprecated ENGINE API.Filename     : /usr/include/openssl/engine.hopenssl-devel-engine-1:3.2.2-9.fc41.x86_64 : Files for development of applications which will use OpenSSL and use deprecated ENGINE API.Filename     : /usr/include/openssl/engine.hucrt64-openssl-3.2.2-2.fc41.noarch : MinGW port of the OpenSSL toolkitFilename     : /usr/x86_64-w64-mingw32ucrt/sys-root/mingw/include/openssl/engine.hopenssl-devel-engine-1:3.2.4-1.fc41.i686 : Files for development of applications which will use OpenSSL and use deprecated ENGINE API.Filename     : /usr/include/openssl/engine.hopenssl-devel-engine-1:3.2.4-1.fc41.x86_64 : Files for development of applications which will use OpenSSL and use deprecated ENGINE API.Filename     : /usr/include/openssl/engine.h┌─[wxj@DarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1]└──╼ $ dnf search openssl-devel-engineUpdating and loading repositories:Repositories loaded.Matched fields: name (exact) openssl-devel-engine.i686: Files for development of applications which will use OpenSSL and use deprecated ENGINE API. openssl-devel-engine.x86_64: Files for development of applications which will use OpenSSL and use deprecated ENGINE API.┌─[✗]─[wxj@DarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1]└──╼ $ sudo dnf install openssl-devel-engine -yUpdating and loading repositories:Repositories loaded.Package                                                             Arch            Version                                                              Repository                                 SizeInstalling: openssl-devel-engine                                               x86_64          1:3.2.4-1.fc41                                                       updates                                52.8 KiBTransaction Summary: Installing:         1 packageTotal size of inbound packages is 43 KiB. Need to download 43 KiB.After this operation, 53 KiB extra will be used (install 53 KiB, remove 0 B).[1/1] openssl-devel-engine-1:3.2.4-1.fc41.x86_64                                                                                                                100% |  96.9 KiB/s |  43.0 KiB |  00m00s--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------[1/1] Total                                                                                                                                                     100% |  44.8 KiB/s |  43.0 KiB |  00m01sRunning transaction[1/3] Verify package files                                                                                                                                      100% |   1.0 KiB/s |   1.0   B |  00m00s[2/3] Prepare transaction                                                                                                                                       100% |  10.0   B/s |   1.0   B |  00m00s[3/3] Installing openssl-devel-engine-1:3.2.4-1.fc41.x86_64                                                                                                     100% | 921.4 KiB/s |  68.2 KiB |  00m00sComplete!安装完成后，再次编译内核即可┌─[wxj@DarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1]└──╼ $ nohup make -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl &amp;&gt; make.log &amp;[1] 9209┌─[wxj@DarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.75.1]└──╼ $[1]+  Done                    nohup make -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl &amp;&gt; make.log处理过程  确认 openssl-devel 已经安装  环境中已经安装了 openssl-devel，但是没有 engine.h 文件，可以通过 locate 查找文件位置，发现确实没有 engine.h 文件  通过 dnf provides */engine.h 查找到 openssl-devel-engine 包提供了 engine.h 文件。虽然有很多输出，但是找到对应的 openssl-devel*的包即可，毕竟提示就是 openssl/engine.h: No such file or directory  安装 openssl-devel-engine 包之后重新编译内核总结缺少依赖包的头文件时，可以通过 dnf provides */filename 查找对应的包dnf  的 provides 选项 作用就是查找 Find what package provides the given value"
  },
  
  {
    "title": "vim 插入行号",
    "url": "/posts/vim-%E6%8F%92%E5%85%A5%E8%A1%8C%E5%8F%B7/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-10-15 15:47:47 +0800",
    





    
    "snippet": "前言vim/nvim 可以显示行号，但是有的时候需要添加行号到文本中，这里记录一些方法## 例如原文件：abcde## 修改后的文件：1.a2.b3.c4.d获取行号vim内部有内置命令如 line() 获取当前行号:echo line('.')获取所在行的行号 “.”，小数点”.”表示当前行为当前行插入行号可以在插入模式下使用 C-r+=line(‘.’) 插入行号为每一行插入行号在每一行...",
    "content": "前言vim/nvim 可以显示行号，但是有的时候需要添加行号到文本中，这里记录一些方法## 例如原文件：abcde## 修改后的文件：1.a2.b3.c4.d获取行号vim内部有内置命令如 line() 获取当前行号:echo line('.')获取所在行的行号 “.”，小数点”.”表示当前行为当前行插入行号可以在插入模式下使用 C-r+=line(‘.’) 插入行号为每一行插入行号在每一行的行首插入行号:%s/^/\\=line(\".\")/## 通过小数点拼接分隔符，不然行号和文字直接挨着了:%s/^/\\=line(\".\") . '、'/在可视 view 模式下插入行号有的时候只需要为部分文本插入行号，可以先选中文本之后在进行操作:'&lt;,'&gt;s/^/\\=line('.') - line(\"'&lt;\") + 1/:'&lt;,'&gt;s/^/\\=line('.') - line(\"'&lt;\") + 1 . '.'/利用 g&lt;C-a&gt; 添加行号如果觉得通过 line() 函数设置行号太麻烦，或者行数不多的情况下可以尝试使用 g&lt;C-a&gt; 的方式添加行号首先给行首添加 0 ，或者 1:%s/^/0./也可以 &lt;c-v&gt; 或 &lt;c-q&gt; 进入块选择模式，按列选择需要加行号的位置，然后 I0 ，分格符也可以一并输入。完成后键入 ESC 就能在每行中加入0选中要加行号的区域，执行 norm I0, (仅在每行开头加入）之后要重新选中之前选中的区域，直接按下 gv，或者 &lt;C-v&gt; 重新选择行。然后键入 g&lt;C-a&gt; 会自动增加数字其他办法也可以直接使用外部工具 cat、awk 等实现:%!cat -n   字数最少的方法    :%s/^/\\=line(\".\").\",\\t\"/  最正规的方法 :let i=0|g/^/s//\\=i.','/ |let i+=1 不用函数的方法:g/^/exec \"s/^/\".strpart(line(\".\").\"   \", 0, 4)  :g/^/exec \"s/^/\".line(\".\").\"\\t\":%!awk '{print 1000+NR*10,$0}'删除行号添加行号之后可以按照以下方法删除行号:%s/^[0-9]*//总结最简单的方法还是直接利用 vim/nvim 自带的 line() 函数设置行号如果在 Linux 环境也可以利用 cat、awk 外部工具后续发现有一个帖子讨论过这个问题，可以查看这里stackoverflowcsdn上也有一些方法可以参考"
  },
  
  {
    "title": "Oracle 获取表的变更记录",
    "url": "/posts/Oracle-%E8%8E%B7%E5%8F%96%E8%A1%A8%E7%9A%84%E5%8F%98%E6%9B%B4%E8%AE%B0%E5%BD%95/",
    "categories": "DataBase, Oracle",
    "tags": "Oracle",
    "date": "2024-09-27 15:04:52 +0800",
    





    
    "snippet": "前言有的时候需要统计实例中表的变更记录，除了创建触发器统计，也可以直接利用内部的 DBA_TAB_MODIFICATIONS 视图获取变更信息DBA_TAB_MODIFICATIONS视图概述DBA_TAB_MODIFICATIONS 记录了自上次收集表统计信息以来对数据库中所有表的修改操作，包括增删改查。系统后台调用 DBMS_STATS.FLUSH_DATABASE_MONITORING...",
    "content": "前言有的时候需要统计实例中表的变更记录，除了创建触发器统计，也可以直接利用内部的 DBA_TAB_MODIFICATIONS 视图获取变更信息DBA_TAB_MODIFICATIONS视图概述DBA_TAB_MODIFICATIONS 记录了自上次收集表统计信息以来对数据库中所有表的修改操作，包括增删改查。系统后台调用 DBMS_STATS.FLUSH_DATABASE_MONITORING_INFO 更新，当然也可以手工调用更新信息SQL&gt; desc DBA_TAB_MODIFICATIONS Name                                      Null?    Type ----------------------------------------- -------- ---------------------------- TABLE_OWNER                                        VARCHAR2(30) TABLE_NAME                                         VARCHAR2(30) PARTITION_NAME                                     VARCHAR2(30) SUBPARTITION_NAME                                  VARCHAR2(30) INSERTS                                            NUMBER UPDATES                                            NUMBER DELETES                                            NUMBER TIMESTAMP                                          DATE TRUNCATED                                          VARCHAR2(3) DROP_SEGMENTS                                      NUMBER            Column      Datatype      NULL      Description                  TABLE_OWNER      VARCHAR2(128)             Owner of the modified table              TABLE_NAME      VARCHAR2(128)             Name of the modified table              PARTITION_NAME      VARCHAR2(128)             Name of the modified partition              SUBPARTITION_NAME      VARCHAR2(128)             Name of the modified subpartition              INSERTS      NUMBER             Approximate number of inserts since the last  time statistics were gathered              UPDATES      NUMBER             Approximate number of updates since the last  time statistics were gathered              DELETES      NUMBER             Approximate number of deletes since the last  time statistics were gathered              TIMESTAMP      DATE             Indicates the last time the table was modified              TRUNCATED      VARCHAR2(3)             Indicates whether the table has been truncated since  the last analyze (YES) or not (NO)              DROP_SEGMENTS      NUMBER             Number of partition and subpartition segments  dropped since the last analyze      手动更新 DBA_TAB_MODIFICATIONS 视图的信息：除了系统后台自动更新信息，也可以手动更新视图信息exec DBMS_STATS.FLUSH_DATABASE_MONITORING_INFO查看表的变更信息需要注意的是，如果不加条件的话查询结果返回为空alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss';SQL&gt; select count(1) from DBA_TAB_MODIFICATIONS;  COUNT(1)----------      3280SQL&gt; select * from DBA_TAB_MODIFICATIONS;no rows selectedSQL&gt; select * from v$version;BANNER--------------------------------------------------------------------------------Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit ProductionPL/SQL Release 11.2.0.4.0 - ProductionCORE    11.2.0.4.0      ProductionTNS for Linux: Version 11.2.0.4.0 - ProductionNLSRTL Version 11.2.0.4.0 - ProductionSQL&gt;SQL&gt; select TABLE_OWNER, TABLE_NAME, count(1) from DBA_TAB_MODIFICATIONS group by TABLE_OWNER, TABLE_NAME;no rows selected可以按照用户名分组查看每个用户涉及的多少张表变更，在逐步添加条件，如果一开始就确定需要查询表名就可以省略这一步，直接带入表名和用户名查询对应的信息就行：SQL&gt; select TABLE_OWNER, count(1) from DBA_TAB_MODIFICATIONS  group by TABLE_OWNER;TABLE_OWNER                      COUNT(1)------------------------------ ----------x rows selected.select TABLE_OWNER, TABLE_NAME, count(1) from DBA_TAB_MODIFICATIONS where TABLE_OWNER='&amp;owner' group by TABLE_OWNER, TABLE_NAME;select * from DBA_TAB_MODIFICATIONS where TABLE_OWNER='&amp;owner' group by TABLE_OWNER, TABLE_NAME;也可以按照时间筛选，如果需要导出 csv 的话，可以按照以下语句拼接导出结果alter session set nls_date_format='yyyy-mm-dd';select table_owner||','||TABLE_NAME||','|| TIMESTAMP || ',' || INSERTS||','||  UPDATES ||','||  DELETES ||','||  TRUNCATED ||','||  DROP_SEGMENTS from dba_tab_modifications where table_owner = '&amp;owner' order by table_owner,TABLE_NAME,TIMESTAMP;如果需要更加复杂的分析或者过滤，有的表已经被删除了，在 dba_tab_modifications 视图中记录的是以 ‘BIN’ 前缀的对象名（类似：BIN$HyvQLM+oPHjgY6oLCgoy2A==$0 ），如果没有关闭回收站的话，可以结合回收站获取原始表名create table recdml as select * from dba_tab_modifications where table_owner = '&amp;owner';alter table recdml add source_name VARCHAR2(30) default null ;update recdml set source_name = (select  ORIGINAL_NAME from DBA_RECYCLEBIN   where TABLE_NAME = OBJECT_NAME and table_owner = owner);select 'table_owner,TABLE_NAME,TIMESTAMP,source_name,INSERTS,UPDATES,DELETES,TRUNCATED,DROP_SEGMENTS' from dual ;select '用户,表名,日期,原始表名,插入记录数,更新记录,删除记录,truncate,drop记录' from dual;select table_owner||','||TABLE_NAME||','|| TIMESTAMP || ',' || source_name || ',' || INSERTS||','||  UPDATES ||','||  DELETES ||','||  TRUNCATED ||','||  DROP_SEGMENTS from recdml where table_owner = '&amp;owner' and TIMESTAMP &gt; '2024-07-31' order by table_owner,TABLE_NAME,TIMESTAMP;查看表是否开启 monitor只有对表开启了 monitor 才会有记录：select MONITORING from dba_tables t where t.table_name='&amp;table_name';一般默认都会开启的，如果开启了 monitor 但是查询表却没有信息，可以手动刷新 DBA_TAB_MODIFICATIONS 的信息。需要注意如果对应的表执行了统计收集，在 DBA_TAB_MODIFICATIONS 视图上的记录会消失，因为视图记录的是自最近一次统计收集之后表变更信息关闭/开启 monitor通过修改隐藏参数 _dml_monitoring_enabled 可以关闭该功能alter system set \"_dml_monitoring_enabled\"=false scope=memory;关闭 monitor 之后对表的变更操作记录，就不会在记录在 DBA_TAB_MODIFICATIONS 视图中了-- 开启 monitoralter system set \"_dml_monitoring_enabled\"=true scope=memory;总结      create table创建的表，插入的数据不会被记录。        即使执行了 dml 操作,且没有 commit ，在刷新后 exec DBMS_STATS.FLUSH_DATABASE_MONITORING_INFO ，sys.dba_tab_modifications 也会存在记录。        收集表统计信息后，该视图里对应的表的变更记录会消失，因为视图中的采集信息是自最近一次统计收集之后的变更信息。        通过隐含参数 _dml_monitoring_enabled 可以关闭 monitor        对于已经删除的表名信息可以结合回收站获取  参考dba_tab_modificationshttps://mwidlake.wordpress.com/2010/07/02/dba_tab_modifications/https://www.itpub.net/thread-1306609-1-1.html可以根据这个做测试"
  },
  
  {
    "title": "nmcli 管理网络",
    "url": "/posts/nmcli-%E7%AE%A1%E7%90%86%E7%BD%91%E7%BB%9C/",
    "categories": "Linux, Network",
    "tags": "nmcli",
    "date": "2024-09-26 17:13:10 +0800",
    





    
    "snippet": "前言一般 Linux 管理网络都是通过直接编辑网卡文件或者 ip 、ifconfig  命令，不过自从用了 nmcli 之后觉得方便不少。而且在 Redhat8+ 之后也不推荐直接修改网卡配置文件。这里记录一下自己安装 fedora server 之后完了设置自动连接，以为会默认自动连接😂详细的可以参考这里，本来想自己总结一下的，发现这篇文章已经写的很详细了，这里就简单记录一下配置自动连接网...",
    "content": "前言一般 Linux 管理网络都是通过直接编辑网卡文件或者 ip 、ifconfig  命令，不过自从用了 nmcli 之后觉得方便不少。而且在 Redhat8+ 之后也不推荐直接修改网卡配置文件。这里记录一下自己安装 fedora server 之后完了设置自动连接，以为会默认自动连接😂详细的可以参考这里，本来想自己总结一下的，发现这篇文章已经写的很详细了，这里就简单记录一下配置自动连接网卡的命令连接网络如果插上网卡之后，发现无法连接网络，可以使用 ip a 查看网卡是否启动。如果启动但是没有连接，可以使用以下命令：sudo nmcli device connect enp2s0 ## 最后面是网卡的名字，根据自己的名称修改设置好之后就可以上网了，在自己的家或者没有限制 ip 的环境中，保持默认就行了，如果有 ip 限制，可以根据以下命令手动设置：nmcli dev mod em1 ipv4.method manual ipv4.addr \"192.168.1.2/24, 10.10.1.5/8\"nmcli dev mod em1 +ipv4.dns 8.8.4.4nmcli dev mod em1 -ipv4.dns 1nmcli dev mod em1 -ipv6.addr \"abbe::cafe/56\"最后一定要注意设置自动连接，如果是服务器的话，重启之后没有自动连接网络还要在接鼠标显示器。。nmcli -f name,autoconnect connection通过以上命令查看是否是自动连接，如果不是一定要记得修改：sudo nmcli device ens3 set autoconnect yessudo nmcli con mod ens3 connection.autoconnect yes总结用了 nmcli 之后发现节约了不少时间，不需要单独修改配置文件。更多的使用方法可以使用 nmcli --help 查看，如果在 fedora 上直接按两次 tab 键会自动补全，更加便捷。更多详细的可以查看：https://docs.rockylinux.org/gemstones/network/nmcli/https://zhuanlan.zhihu.com/p/395236748https://networkmanager.pages.freedesktop.org/NetworkManager/NetworkManager/nm-settings-nmcli.html"
  },
  
  {
    "title": "Oracle 分区和分区索引",
    "url": "/posts/Oracle-%E5%88%86%E5%8C%BA%E5%92%8C%E5%88%86%E5%8C%BA%E7%B4%A2%E5%BC%95/",
    "categories": "DataBase, Oracle",
    "tags": "index",
    "date": "2024-09-19 10:14:01 +0800",
    





    
    "snippet": "前言记录一下 Oracle 的分区表和索引官方文档位置，以及分区索引的失效操作记录，方便后续查询分区表和分区索引Index PartitioningAbout Merging Partitions and Subpartitions测试样例-- 创建分区表（按范围分区）CREATE TABLE part_tab (  id NUMBER,  col3 NUMBER,  create_date...",
    "content": "前言记录一下 Oracle 的分区表和索引官方文档位置，以及分区索引的失效操作记录，方便后续查询分区表和分区索引Index PartitioningAbout Merging Partitions and Subpartitions测试样例-- 创建分区表（按范围分区）CREATE TABLE part_tab (  id NUMBER,  col3 NUMBER,  create_date DATE)PARTITION BY RANGE (col3) (  PARTITION p1 VALUES LESS THAN (10000),  PARTITION p2 VALUES LESS THAN (20000),  PARTITION p_max VALUES LESS THAN (MAXVALUE));-- 插入测试数据-- 落入 p1INSERT INTO part_tab VALUES (1, 5000, SYSDATE);-- 落入 p2INSERT INTO part_tab VALUES (2, 15000, SYSDATE);-- 落入 p_maxINSERT INTO part_tab VALUES (3, 25000, SYSDATE);COMMIT;-- 创建全局索引和局部索引CREATE /* 全局索引 */ INDEX gidx_part_id ON part_tab(id) GLOBAL;CREATE /* 局部索引 */INDEX lidx_part_col3 ON part_tab(col3) LOCAL;测试场景Truncate-- 执行 Truncate 分区（不更新索引）ALTER TABLE part_tab TRUNCATE PARTITION p1;-- 验证全局索引状态SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME----------------------------------------------------------------------------------------------------STATUS--------GIDX_PART_IDUNUSABLEElapsed: 00:00:00.05WXJ@pdb1 19,1109022 SQL&gt; set linesize 300WXJ@pdb1 19,1109022 SQL&gt;WXJ@pdb1 19,1109022 SQL&gt; /INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     UNUSABLE-- 验证局部索引状态SELECT index_name, partition_name, statusFROM user_ind_partitionsWHERE index_name = 'LIDX_PART_COL3'AND partition_name = 'P1';WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, partition_name, status  2  FROM user_ind_partitions  3  WHERE index_name = 'LIDX_PART_COL3'  4  AND partition_name = 'P1';INDEX_NAME                                                                                                                       PARTITION_NAME                                                          STATUS-------------------------------------------------------------------------------------------------------------------------------- -------------------------------------------------------------------------------------------------------------------------------- --------LIDX_PART_COL3                                                                                                                   P1                                                                      USABLE-- 手动重建/更新全局索引alter index WXJ.GIDX_PART_ID rebuild ;WXJ@pdb1 19,1109022 SQL&gt; alter index WXJ.GIDX_PART_ID rebuild ;Index altered.Elapsed: 00:00:00.04WXJ@pdb1 19,1109022 SQL&gt;WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALID可以看出，Truncate 分区后，全局索引失效，局部索引不受影响。如果避免全局索引失效，可以在 Truncate 分区时指定UPDATE GLOBAL INDEXES-- 避免失效操作（重新执行并更新索引）ALTER TABLE part_tab TRUNCATE PARTITION p1 UPDATE GLOBAL INDEXES;-- 再次验证全局索引状态（预期：VALID）WXJ@pdb1 19,1109022 SQL&gt; ALTER TABLE part_tab TRUNCATE PARTITION p1 UPDATE GLOBAL INDEXES;Table truncated.Elapsed: 00:00:00.01WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALIDElapsed: 00:00:00.01Drop 分区--查询分区表详情col OWNER for a10col SEGMENT_NAME for a25col PARTITION_NAME for a30set lin 200 pagesize 500select OWNER,SEGMENT_NAME,PARTITION_NAME from dba_segments where OWNER in ('WXJ') and SEGMENT_NAME in ('PART_TAB') order by 2,3;WXJ@pdb1 19,1109022 SQL&gt; select OWNER,SEGMENT_NAME,PARTITION_NAME from dba_segments where OWNER in ('WXJ') and SEGMENT_NAME in ('PART_TAB') order by 2,3;OWNER      SEGMENT_NAME              PARTITION_NAME---------- ------------------------- ------------------------------WXJ        PART_TAB                  P1WXJ        PART_TAB                  P2WXJ        PART_TAB                  P_MAX-- 执行 Drop 分区（不更新索引）ALTER TABLE part_tab DROP PARTITION p2;WXJ@pdb1 19,1109022 SQL&gt; ALTER TABLE part_tab DROP PARTITION p2;Table altered.Elapsed: 00:00:00.02WXJ@pdb1 19,1109022 SQL&gt;WXJ@pdb1 19,1109022 SQL&gt; select OWNER,SEGMENT_NAME,PARTITION_NAME from dba_segments where OWNER in ('WXJ') and SEGMENT_NAME in ('PART_TAB') order by 2,3;OWNER      SEGMENT_NAME              PARTITION_NAME---------- ------------------------- ------------------------------WXJ        PART_TAB                  P1WXJ        PART_TAB                  P_MAX-- 验证全局索引状态（预期：UNUSABLE）SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     UNUSABLE-- 查看全局索引情况WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     UNUSABLEElapsed: 00:00:00.00WXJ@pdb1 19,1109022 SQL&gt; -- 验证局部索引状态WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, partition_name, status FROM user_ind_partitions WHERE index_name = 'LIDX_PART_COL3' ;INDEX_NAME                                                                                                                       PARTITION_NAME                 STATUS-------------------------------------------------------------------------------------------------------------------------------- ------------------------------ --------LIDX_PART_COL3                                                                                                                   P1                             USABLELIDX_PART_COL3                                                                                                                   P_MAX                          USABLE-- 重新添加分区-- ALTER TABLE part_tab ADD PARTITION p2 VALUES LESS THAN (20000);ALTER TABLE part_tabSPLIT PARTITION p_max AT (30000)INTO (PARTITION p2, PARTITION p_max);WXJ@pdb1 19,1109022 SQL&gt; select OWNER,SEGMENT_NAME,PARTITION_NAME from dba_segments where OWNER in ('WXJ') and SEGMENT_NAME in ('PART_TAB') order by 2,3;OWNER      SEGMENT_NAME              PARTITION_NAME---------- ------------------------- ------------------------------WXJ        PART_TAB                  P1WXJ        PART_TAB                  P2WXJ        PART_TAB                  P_MAX-- 再次检查索引状态WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, partition_name, status FROM user_ind_partitions WHERE index_name = 'LIDX_PART_COL3' ;INDEX_NAME                                                                                                                       PARTITION_NAME                 STATUS-------------------------------------------------------------------------------------------------------------------------------- ------------------------------ --------LIDX_PART_COL3                                                                                                                   P1                             USABLELIDX_PART_COL3                                                                                                                   P2                             USABLE -- 重建后的本地索引状态正常LIDX_PART_COL3                                                                                                                   P_MAX                          USABLEWXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     UNUSABLE-- 重建全局索引WXJ@pdb1 19,1109022 SQL&gt; alter index WXJ.GIDX_PART_ID rebuild ;Index altered.Elapsed: 00:00:00.01WXJ@pdb1 19,1109022 SQL&gt;WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALID-- 避免失效操作（带 UPDATE GLOBAL INDEXES）ALTER TABLE part_tab DROP PARTITION p2 UPDATE GLOBAL INDEXES;WXJ@pdb1 19,1109022 SQL&gt; ALTER TABLE part_tab DROP PARTITION p2 UPDATE GLOBAL INDEXES;Table altered.Elapsed: 00:00:00.02WXJ@pdb1 19,1109022 SQL&gt;WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALIDElapsed: 00:00:00.00-- 验证全局索引状态（预期：VALID）Split 分区（有记录的 MAX 分区）-- 确保 p_max 有数据SELECT * FROM part_tab PARTITION (p_max);WXJ@pdb1 19,1109022 SQL&gt; SELECT * FROM part_tab PARTITION (p_max);no rows selectedElapsed: 00:00:00.00-- 上面 split p2 的时候搞错了范围，重新插入新的数据INSERT INTO part_tab VALUES (4, 30000, SYSDATE);INSERT INTO part_tab VALUES (5, 50000, SYSDATE);INSERT INTO part_tab VALUES (6, 60000, SYSDATE);INSERT INTO part_tab VALUES (7, 70000, SYSDATE);COMMIT;-- 执行 Split 分区ALTER TABLE part_tabSPLIT PARTITION p_max AT (40000)INTO (PARTITION p3, PARTITION p_max);WXJ@pdb1 19,1109022 SQL&gt; select OWNER,SEGMENT_NAME,PARTITION_NAME from dba_segments where OWNER in ('WXJ') and SEGMENT_NAME in ('PART_TAB') order by 2,3;OWNER      SEGMENT_NAME              PARTITION_NAME---------- ------------------------- ------------------------------WXJ        PART_TAB                  P1WXJ        PART_TAB                  P3WXJ        PART_TAB                  P_MAX-- 验证全局索引状态（预期：UNUSABLE）SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     UNUSABLE-- 验证局部索引状态（预期：UNUSABLE）SELECT index_name, partition_name, statusFROM user_ind_partitionsWHERE index_name = 'LIDX_PART_COL3'AND partition_name IN ('P3', 'P_MAX');INDEX_NAME                                                                                                                       PARTITION_NAME                 STATUS-------------------------------------------------------------------------------------------------------------------------------- ------------------------------ --------LIDX_PART_COL3                                                                                                                   P3                             UNUSABLELIDX_PART_COL3                                                                                                                   P_MAX                          UNUSABLE-- 重建全局索引WXJ@pdb1 19,1109022 SQL&gt; alter index WXJ.GIDX_PART_ID rebuild ;Index altered.-- 重建局部索引ALTER INDEX lidx_part_col3 REBUILD PARTITION p3;ALTER INDEX lidx_part_col3 REBUILD PARTITION p_max;WXJ@pdb1 19,1109022 SQL&gt; ALTER INDEX lidx_part_col3 REBUILD PARTITION p3;Index altered.Elapsed: 00:00:00.02WXJ@pdb1 19,1109022 SQL&gt; ALTER INDEX lidx_part_col3 REBUILD PARTITION p_max;Index altered.Elapsed: 00:00:00.02-- 查看索引状态SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';SELECT index_name, partition_name, statusFROM user_ind_partitionsWHERE index_name = 'LIDX_PART_COL3' ;WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALIDElapsed: 00:00:00.00WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, partition_name, status FROM user_ind_partitions WHERE index_name = 'LIDX_PART_COL3' ;INDEX_NAME                                                                                                                       PARTITION_NAME                 STATUS-------------------------------------------------------------------------------------------------------------------------------- ------------------------------ --------LIDX_PART_COL3                                                                                                                   P1                             USABLELIDX_PART_COL3                                                                                                                   P3                             USABLELIDX_PART_COL3                                                                                                                   P_MAX                          USABLEElapsed: 00:00:00.04-- 使用 UPDATE GLOBAL INDEXES 避免失效ALTER TABLE part_tabSPLIT PARTITION p_max AT (50000)INTO (PARTITION p4, PARTITION p_max)UPDATE GLOBAL INDEXES;-- 验证全局索引状态（预期：VALID）WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALIDElapsed: 00:00:00.00WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, partition_name, status FROM user_ind_partitions WHERE index_name = 'LIDX_PART_COL3' ;INDEX_NAME                                                                                                                       PARTITION_NAME                 STATUS-------------------------------------------------------------------------------------------------------------------------------- ------------------------------ --------LIDX_PART_COL3                                                                                                                   P1                             USABLELIDX_PART_COL3                                                                                                                   P3                             USABLELIDX_PART_COL3                                                                                                                   P4                             USABLELIDX_PART_COL3                                                                                                                   P_MAX                          USABLEElapsed: 00:00:00.00Add 分区已经存在 max 分区，无法直接通过 add partition 来添加分区，需要通过 split 分区来添加分区。可以新建一张表，然后 add partition 来测试。为了方便直接将 max 分区删除，然后重新添加分区-- 删除 MAX 分区ALTER TABLE part_tab DROP PARTITION p_max;-- drop 分区会使全局索引失效，需要重建alter index WXJ.GIDX_PART_ID rebuild ;-- 验证状态WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, partition_name, status  2  FROM user_ind_partitions  3  WHERE index_name = 'LIDX_PART_COL3'  4  ;INDEX_NAME                                                                                                                       PARTITION_NAME                 STATUS-------------------------------------------------------------------------------------------------------------------------------- ------------------------------ --------LIDX_PART_COL3                                                                                                                   P1                             USABLELIDX_PART_COL3                                                                                                                   P3                             USABLELIDX_PART_COL3                                                                                                                   P4                             USABLEElapsed: 00:00:00.04WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALIDElapsed: 00:00:00.01-- 执行 Add 分区ALTER TABLE part_tabADD PARTITION p6 VALUES LESS THAN (60000);-- 验证全局索引和局部索引状态（预期：VALID）SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';SELECT index_name, partition_name, statusFROM user_ind_partitionsWHERE index_name = 'LIDX_PART_COL3' ;WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALIDElapsed: 00:00:00.00WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, partition_name, status  2  FROM user_ind_partitions  3  WHERE index_name = 'LIDX_PART_COL3' ;INDEX_NAME                                                                                                                       PARTITION_NAME                 STATUS-------------------------------------------------------------------------------------------------------------------------------- ------------------------------ --------LIDX_PART_COL3                                                                                                                   P1                             USABLELIDX_PART_COL3                                                                                                                   P3                             USABLELIDX_PART_COL3                                                                                                                   P4                             USABLELIDX_PART_COL3                                                                                                                   P6                             USABLE-- 可以看到，Add 分区后，全局索引和局部索引状态都是正常的Exchange 分区-- 创建普通表并插入数据CREATE TABLE normal_tab (id NUMBER, col3 NUMBER, create_date DATE);INSERT INTO normal_tab VALUES (4, 7000, SYSDATE);COMMIT;create index idx_normal_col3 on normal_tab(col3);-- 执行 Exchange 分区（不更新索引）ALTER TABLE part_tabEXCHANGE PARTITION p1WITH TABLE normal_tab INCLUDING INDEXES;-- 验证全局索引状态（预期：UNUSABLE）SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     UNUSABLE-- 避免失效操作（带 UPDATE GLOBAL INDEXES）WXJ@pdb1 19,1109022 SQL&gt; alter index WXJ.GIDX_PART_ID rebuild ;ALTER TABLE part_tabEXCHANGE PARTITION p1WITH TABLE normal_tab INCLUDING INDEXESUPDATE GLOBAL INDEXES;-- 验证全局索引状态（预期：VALID）WXJ@pdb1 19,1109022 SQL&gt; SELECT index_name, status FROM user_indexes WHERE index_name = 'GIDX_PART_ID';INDEX_NAME                                                                                                                       STATUS-------------------------------------------------------------------------------------------------------------------------------- --------GIDX_PART_ID                                                                                                                     VALIDElapsed: 00:00:00.00总结不同的版本操作方法和影响会存在差异，最好查询官网文档如果涉及的分区或子分区包含数据，则索引可能会被标记为 UNUSABLE，如下表所述：            Table Type      Index Behavior                  Regular (Heap)      Unless you specify UPDATE INDEXES as part of the ALTER TABLE statement:- The database marks UNUSABLE all resulting corresponding local index partitions or subpartitions. - Global indexes, or all partitions of partitioned global indexes, are marked UNUSABLE and must be rebuilt.              Index-organized      The database marks UNUSABLE all resulting corresponding local index partitions.All global indexes remain usable.      会造成分区表索引失效的操作            操作动作      操作命令      全局索引      分区索引                  Truncate      ALTER TABLE part_tab_trunc TRUNCATE PARTITION p1;      是否失效: 失效 如何避免: UPDATE GLOBAL INDEXES;      是否失效: 无影响 如何避免: 无需操作              Drop      ALTER TABLE part_tab_drop DROP PARTITION p1;      是否失效: 失效 如何避免: UPDATE GLOBAL INDEXES;      是否失效: 无影响 如何避免: 无需操作              Split      ALTER TABLE part_tab_split SPLIT PARTITION p_max AT (30000) INTO (PARTITION p3, PARTITION p_max);      是否失效: 失效 如何避免: UPDATE GLOBAL INDEXES;      是否失效: 失效（若 MAX 分区有记录） 如何避免: 重建局部索引 ALTER INDEX idx_part_split_col3 REBUILD;              Add      ALTER TABLE part_tab_add ADD PARTITION p6 VALUES LESS THAN (60000);      是否失效: 无影响 如何避免: 无需操作      是否失效: 无影响 如何避免: 无需操作              Exchange      ALTER TABLE part_tab_exch EXCHANGE PARTITION p1 WITH TABLE normal_tab INCLUDING INDEXES;      是否失效: 失效 如何避免: UPDATE GLOBAL INDEXES;      是否失效: 无影响 如何避免: 无需操作      "
  },
  
  {
    "title": "统计博客网站访问数据",
    "url": "/posts/%E7%BB%9F%E8%AE%A1%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99%E6%95%B0%E6%8D%AE/",
    "categories": "Web, blog",
    "tags": "blog",
    "date": "2024-09-11 15:21:43 +0800",
    





    
    "snippet": "前言搭建好博客网站之后，如果更加细致的分析访问数据数据，可以利用 Google、cloudflare 等站点为自己的网站分析流量我的网站基于 GitHub Pages 、cloudflare 、 jekyll-theme-chirpy 搭建Google Analytics使用 Google Analytics 监听网站页面访问量，可以参考 这里将 Google Analytics 提供的 i...",
    "content": "前言搭建好博客网站之后，如果更加细致的分析访问数据数据，可以利用 Google、cloudflare 等站点为自己的网站分析流量我的网站基于 GitHub Pages 、cloudflare 、 jekyll-theme-chirpy 搭建Google Analytics使用 Google Analytics 监听网站页面访问量，可以参考 这里将 Google Analytics 提供的 id 信息填入 chirpy 或者其他支持网站分析的主题配置文件中，以 chirpy 为例配置文件就在仓库根目录 _config.yml 文件中 analytics 代码块中，支持多个分析网站需要将 Google Analytics 提供的 js 代码配置在自己的网站 html 文件中才可以采集到数据cloudflarecloudflare 也提供 Web Analytics，登录自己的 cloudflare 大盘，选择左边栏的 分析和日志 -&gt; Web Analytics ，然后点击 添加站点配置自己的站点地址，如果站点是通过 cloudflare 托管的，支持 自动设置，不需要自己手动添加 js 代码块在 html 中了配置完成之后返回 Web Analytics 页面，然后访问自己的博客地址，等几分钟就可以查看到网站的访问信息了busuanzi除了 Jekyll 或者主题提供的网站分析之外，还可以利用 busuanzi 手动在网站的页面中配置访问量统计，参考这里在页面的 html 文件中的合适位置添加如下代码：本站总访问量&lt;span id=\"busuanzi_value_site_pv\"&gt;&lt;/span&gt;次本站访客数&lt;span id=\"busuanzi_value_site_uv\"&gt;&lt;/span&gt;人次本文总阅读量&lt;span id=\"busuanzi_value_page_pv\"&gt;&lt;/span&gt;次如果您和我一样使用 chirpy 主题，可以在根目录下的 _includes/footer.html 文件中的合适位置添加以下内容：&lt;p&gt;  &lt;script async src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"&gt;  &lt;/script&gt;  [本站总访问量&lt;span id=\"busuanzi_value_site_pv\"&gt;&lt;/span&gt;次]  [本站访客数&lt;span id=\"busuanzi_value_site_uv\"&gt;&lt;/span&gt;人次]  [本文总阅读量&lt;span id=\"busuanzi_value_page_pv\"&gt;&lt;/span&gt;次]&lt;/p&gt;总结可以利用 Google、cloudflare 分析统计网站的流量，也可以利用 busuanzi 统计网站的访问量。"
  },
  
  {
    "title": "CentOS9 升级内核",
    "url": "/posts/CentOS9-%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/",
    "categories": "Linux, CentOS",
    "tags": "CentOS9",
    "date": "2024-09-11 13:49:36 +0800",
    





    
    "snippet": "前言随着 CentOS 政策的调整，CentOS 官方宣布了停止维护 CentOS 的计划，并推出了 CentOS Stream （Stream 版为滚动更新版） 项目。直接从 Redhat 的下游变成了上游，尝试了一下 CentOS Stream 9，一些软件不能直接通过默认的镜像源更新了（例如vim），而且内核默认也比较低，才 5.14.0 ，而且也不能像 fedora 直接 dnf u...",
    "content": "前言随着 CentOS 政策的调整，CentOS 官方宣布了停止维护 CentOS 的计划，并推出了 CentOS Stream （Stream 版为滚动更新版） 项目。直接从 Redhat 的下游变成了上游，尝试了一下 CentOS Stream 9，一些软件不能直接通过默认的镜像源更新了（例如vim），而且内核默认也比较低，才 5.14.0 ，而且也不能像 fedora 直接 dnf update 的方式升级到最新内核，记录一下手动升级内核的过程百度百科维基百科升级内核想要升级内核，需要到第三方仓库进行下载，默认的仓库中没有新的内核。可以通过 ELRepo 仓库安装使用的版内核，导入仓库后就可以通过 yum/dnf 命令进行安装了  查看现有内核      uname -r        导入 ELRepo 镜像源      ## 导入密钥  rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org  ## 安装镜像源  yum install https://www.elrepo.org/elrepo-release-9.el9.elrepo.noarch.rpm        安装内核      yum install --enablerepo=elrepo-kernel kernel-ml            kernel-ml: 稳定主线版，支持周期短，更新速度快，更快体验新特性        kernel-lt: 长期维护版，支持周期长，更新速度慢，更加稳定  安装完成后重启系统，CentOS会自动使用最新安装的内核进行启动。卸载旧的内核新旧内核可同时存在，如果希望系统中存在两个内核，或者后续需要切换不同的内核使用，可不执行清理操作  确认使用新内核      uname -a        查看已安装的内核      rpm -qa | grep kernel  ll /lib/modules  ll /usr/src/kernels/        软件包名称由 kernel-ml 或 kernel-lt 开头的为新版软件包，其余为旧版软件包。    卸载内核      ##  旧的内核名称需要根据自己的环境修改  yum remove kernel-core-5.14.0-205.el9.x86_64 kernel-tools-5.14.0-205.el9.x86_64  # 检查无误可以使用以下语句卸载，慎用，会卸载一些依赖 例如 gcc 之类的，在不确定影响的情况下还是手动删除指定的内核就行  rpm -qa | grep kernel | grep -v kernel-ml | xargs -n 1 yum remove -y      "
  },
  
  {
    "title": "Linux 函数说明",
    "url": "/posts/Linux-%E5%87%BD%E6%95%B0%E8%AF%B4%E6%98%8E/",
    "categories": "Linux, man",
    "tags": "document",
    "date": "2024-09-10 13:52:25 +0800",
    





    
    "snippet": "前言在 strace 进程的时候会显示出来调用的函数，有的时候查看数据库进程的时候方便查看，在这里记录一下一些函数的说明函数以下内容结合 chatgpt 和 google 翻译truncate描述truncate, ftruncate 函数作用是将文件截断为指定长度，函数原型定义#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;int ...",
    "content": "前言在 strace 进程的时候会显示出来调用的函数，有的时候查看数据库进程的时候方便查看，在这里记录一下一些函数的说明函数以下内容结合 chatgpt 和 google 翻译truncate描述truncate, ftruncate 函数作用是将文件截断为指定长度，函数原型定义#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;int truncate(const char *path, off_t length);int ftruncate(int fd, off_t length);truncate() 和 ftruncate() 函数导致由路径命名或由 fd 引用的常规文件被截断为精确长度字节的大小。如果文件以前大于此大小，则多余的数据将丢失。如果文件以前较短，则会对其进行扩展，并且扩展部分读取为空字节 (‘\\0’)。文件偏移量不会更改。如果大小发生变化，则文件的 st_ctime 和 st_mtime 字段（分别为上次状态更改时间和上次修改时间；请参阅 stat(2)）被更新，并且 set-user-ID 和 set-group-ID权限位可以被清除。使用 ftruncate() 时，文件必须打开才能写入；使用 truncate() 时，文件必须可写。返回值成功后，返回零。出错时，返回 -1，并适当设置 errno。epoll_wait描述epoll_wait – 等待 epoll 文件描述符上的 I/O 事件函数定义#include &lt;sys/epoll.h&gt;int epoll_wait(int epfd, struct epoll_event *events,                              int maxevents, int timeout);int epoll_pwait(int epfd, struct epoll_event *events,                               int maxevents, int timeout,                               const sigset_t *sigmask);epoll_wait() 系统调用等待文件描述符 epfd 引用的 epoll(7) 实例上的事件。事件指向的内存区域将包含调用者可用的事件。 epoll_wait() 最多返回 maxevents。 maxevents 参数必须大于零。timeout 参数指定 epoll_wait() 将阻塞的最小毫秒数。 （此间隔将向上舍入到系统时钟粒度，内核调度延迟意味着阻塞间隔可能会小幅超出。）指定超时为 -1 会导致 epoll_wait() 无限期阻塞，而指定超时等于零会导致 epoll_wait() 立即返回，即使没有可用的事件。返回值成功时，epoll_wait() 返回为请求的 I/O 做好准备的文件描述符的数量，如果在请求的超时毫秒内没有文件描述符准备就绪，则返回零。当发生错误时，epoll_wait()返回-1，并适当设置errno。recvfrom描述recv、recvfrom、recvmsg - 从套接字接收消息定义#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;ssize_t recv(int sockfd, void *buf, size_t len, int flags);ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,                                  struct sockaddr *src_addr, socklen_t *addrlen);ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);recvfrom() 和 recvmsg() 调用用于从套接字接收消息，并且可以用于接收套接字上的数据，无论它是否是面向连接的。如果src_addr不为NULL，且底层协议提供了源地址，则填写该源地址。当src_addr为NULL时，不填写任何内容；在这种情况下，addrlen 不被使用，并且也应该为 NULL。参数 addrlen 是一个值-结果参数，调用者应在调用与 src_addr 关联的缓冲区大小之前对其进行初始化，并在返回时进行修改以指示源地址的实际大小。如果提供的缓冲区太小，返回的地址将被截断；在这种情况下，addrlen 将返回一个大于提供给调用的值。返回值这些调用返回接收到的字节数，如果发生错误则返回 -1。当对等方执行有序关闭时，返回值为 0。pwrite64 / pread描述pread、pwrite - 在给定偏移处读取或写入文件描述符定义#include &lt;unistd.h&gt;ssize_t pread(int fd, void *buf, size_t count, off_t offset);ssize_t pwrite(int fd, const void *buf, size_t count, off_t offset);Feature Test Macro Requirements for glibc (see feature_test_macros(7)):pread(), pwrite():_XOPEN_SOURCE &gt;= 500|| /* Since glibc 2.12: */ _POSIX_C_SOURCE &gt;= 200809Lpread() 从文件描述符 fd 中以偏移量 offset（从文件开头）读取最多 count 个字节到从 buf 开始的缓冲区中。文件偏移量未更改。pwrite() 将从 buf 开始的缓冲区中写入 count 个字节到文件描述符 fd 的偏移量 offset 处。文件偏移量未更改。fd 引用的文件必须能够查找。返回值成功时，返回读取或写入的字节数（在 pwrite() 的情况下为零表示未写入任何内容，在 pread() 的情况下表示文件末尾），或在错误时返回 -1，其中case errno 设置为指示错误。access描述access - 检查真实用户对文件的权限定义#include &lt;unistd.h&gt;int access(const char *pathname, int mode);access() 检查调用进程是否可以访问文件路径名。如果路径名是符号链接，则取消引用它。返回值成功时（授予所有请求的权限），返回零。出错时（模式中至少有一位请求的权限被拒绝，或者发生了其他错误），返回 -1，并适当设置 errno。chdir描述chdir、fchdir - 更改工作目录定义#include &lt;unistd.h&gt;int chdir(const char *path);int fchdir(int fd);chdir() 将调用进程的当前工作目录更改为 path 中指定的目录。fchdir() 与 chdir() 相同；唯一的区别是目录作为打开的文件描述符给出。返回值成功后，返回零。出错时，返回 -1，并适当设置 errno。close描述close - 关闭文件描述符定义#include &lt;unistd.h&gt;int close(int fd);close() 关闭文件描述符，以便它不再引用任何文件并且可以重用。与其关联且由进程拥有的文件上持有的任何记录锁（请参阅 fcntl(2)）都将被删除（无论用于获取锁的文件描述符是什么）。如果 fd 是引用底层打开文件描述的最后一个文件描述符（请参阅 open(2)），则释放与打开文件描述关联的资源；如果描述符是对已使用 unlink(2) 删除的文件的最后一个引用，则文件将被删除。返回值close() 成功时返回零。出错时，返回 -1，并适当设置 errno。exit_group描述exit_group - 退出进程中的所有线程定义#include &lt;linux/unistd.h&gt;void exit_group(int status);此系统调用等效于 exit(2)，只不过它不仅终止调用线程，而且终止调用进程的线程组中的所有线程。返回值该系统调用没有返回值fdatasync描述fsync、fdatasync - 将文件的核心状态与存储设备同步定义#include &lt;unistd.h&gt;int fsync(int fd);int fdatasync(int fd);fsync() 将文件描述符 fd 引用的文件的所有修改的核心数据（即修改的缓冲区高速缓存页面）传输（“刷新”）到磁盘设备（或其他永久存储设备），以便所有更改的信息即使系统崩溃或重新启动后也可以检索。这包括写入或刷新磁盘缓存（如果存在）。该调用将阻塞，直到设备报告传输已完成。它还刷新与文件关联的元数据信息（请参阅 stat(2)）。调用 fsync() 不一定确保包含该文件的目录中的条目也已到达磁盘。为此，还需要目录的文件描述符上的显式 fsync()。fdatasync() 与 fsync() 类似，但不会刷新修改的元数据，除非需要该元数据以便正确处理后续数据检索。例如，对 st_atime 或 st_mtime（分别是上次访问时间和上次修改时间；请参阅 stat(2)）的更改不需要刷新，因为正确处理后续数据读取不需要它们。另一方面，文件大小的更改（st_size，如 ftruncate(2) 所做的）将需要元数据刷新。fdatasync() 的目的是减少不需要所有元数据与磁盘同步的应用程序的磁盘活动。返回值成功后，这些系统调用返回零。出错时，返回 -1，并适当设置 errno。futex描述futex - 快速用户空间锁定定义#include &lt;linux/futex.h&gt;#include &lt;sys/time.h&gt;int futex(int *uaddr, int op, int val, const struct timespec *timeout,                    int *uaddr2, int val3);系统调用 futex() 提供了一种方法，使程序可以等待给定地址处的值发生变化，并提供一种方法来唤醒等待该特定地址的任何进程（尽管在不同进程中相同内存的地址可能不同，但内核会将它们内部映射，使得映射到不同位置的相同内存可以在 futex() 调用中对应）。此系统调用通常用于在共享内存中实现锁的争用情况，如 futex(7) 所描述的。当 futex(7) 操作未能在用户空间无争用地完成时，需要调用内核进行仲裁。仲裁可能意味着将调用进程置于休眠状态，或者相反地唤醒等待的进程。调用此函数的用户应遵守 futex(7) 中规定的语义。由于这些语义涉及编写不可移植的汇编指令，这意味着大多数用户实际上是库作者，而不是普通应用程序开发者。uaddr 参数需要指向一个对齐的整数，该整数存储计数器。要执行的操作通过 op 参数传递，同时传递一个值 val。目前定义了五种操作：      FUTEX_WAIT该操作原子地验证 futex 地址 uaddr 是否仍然包含值 val，并在该地址上休眠，等待 FUTEX_WAKE。如果 timeout 参数不为 NULL，则其内容描述最小等待时间，否则为无限。uaddr2 和 val3 参数被忽略。对于 futex(7)，如果递减计数给出了负值（表示争用），则会执行此调用并休眠，直到另一个进程释放 futex 并执行 FUTEX_WAKE 操作。        FUTEX_WAKE此操作最多唤醒 val 个在该 futex 地址上等待的进程（即，在 FUTEX_WAIT 中）。timeout、uaddr2 和 val3 参数被忽略。对于 futex(7)，当递增计数显示有等待者时，一旦 futex 值被设置为 1（表示可用），就会执行此操作。        FUTEX_FD（适用于 Linux 2.6.25 及之前版本）为支持异步唤醒，此操作将文件描述符与 futex 关联。如果另一个进程执行 FUTEX_WAKE，则进程将收到传递给 val 的信号号。调用进程在使用后必须关闭返回的文件描述符。timeout、uaddr2 和 val3 参数被忽略。为防止竞态条件，调用方应在 FUTEX_FD 返回后测试 futex 是否已被提升。    由于其本质上的竞争问题，FUTEX_FD 自 Linux 2.6.26 起被移除。        FUTEX_REQUEUE（自 Linux 2.5.70 起）引入此操作是为了避免使用 FUTEX_WAKE 时的“雷鸣般的”效果，因为所有被唤醒的进程都需要获取另一个 futex。此调用唤醒 val 个进程，并将其他等待者重新排队到 uaddr2 地址上的 futex。timeout 和 val3 参数被忽略。        FUTEX_CMP_REQUEUE（自 Linux 2.6.7 起）FUTEX_REQUEUE 的预期使用中存在竞态，因此引入了 FUTEX_CMP_REQUEUE。此操作类似于 FUTEX_REQUEUE，但首先检查位置 uaddr 是否仍然包含值 val3。如果没有，则操作失败并返回错误 EAGAIN。timeout 参数被忽略。  返回值如果发生错误，所有操作都返回-1，并设置 errno 来指示错误。成功时的返回值取决于操作，如下列表所述：  FUTEX_等待如果进程被 FUTEX_WAKE 调用唤醒，则返回 0。请参阅 ERRORS 了解各种可能的错误返回。  FUTEX_唤醒返回唤醒的进程数。  FUTEX_FD返回与 futex 关联的新文件描述符。  FUTEX_REQUEUE返回唤醒的进程数。  FUTEX_CMP_REQUEUE返回唤醒的进程数。getpid描述getpid, getppid - 获取进程标识定义#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;pid_t getpid(void);pid_t getppid(void);getpid() 返回调用进程的进程 ID。 （这通常由生成唯一临时文件名的例程使用。）getppid() 返回调用进程的父进程的进程 ID。返回值kill描述Kill - 向一个进程或一组进程发送信号定义#include &lt;signal.h&gt;int kill(pid_t pid, int sig);kill() 函数将向由 pid 指定的进程或进程组发送信号。要发送的信号由 sig 指定，可以是 &lt;signal.h&gt; 中列出的信号之一，也可以是 0。如果 sig 为 0（空信号），则只执行错误检查而不发送任何信号。空信号可用于检查 pid 的有效性。要允许一个进程向由 pid 指定的进程发送信号，除非发送进程具有适当的权限，否则发送进程的真实用户 ID 或有效用户 ID 必须与接收进程的真实用户 ID 或保存的设置用户 ID 匹配。  如果 pid 大于 0，则信号将发送给进程 ID 等于 pid 的进程。  如果 pid 为 0，信号将发送给所有进程（不包括某些未指定的系统进程），其进程组 ID 等于发送者的进程组 ID，并且该进程有权限发送信号。  如果 pid 为 -1，信号将发送给所有进程（不包括某些未指定的系统进程），对于这些进程，发送者有权限发送信号。  如果 pid 为负值但不等于 -1，信号将发送给所有进程组 ID 等于 pid 绝对值的进程（不包括某些未指定的系统进程），并且发送者有权限发送信号。如果 pid 的值导致信号生成给发送进程，并且该信号未被调用线程阻塞，且没有其他线程解除阻塞或正在等待该信号，则在 kill() 返回之前，信号或至少一个未阻塞的待处理信号将被传递给发送线程。在发送 SIGCONT 信号给与发送进程属于同一会话的进程时，不应用上述的用户 ID 检查。实现提供的扩展安全控制可能会对发送信号施加进一步的实现定义的限制，包括空信号。系统可能会拒绝某些或全部由 pid 指定的进程的存在。如果 kill() 函数成功，表示进程有权限向任何由 pid 指定的进程发送信号。如果 kill() 失败，则不会发送任何信号。返回值成功完成后，返回0。否则，应返回-1并设置errno以指示错误。lseek描述lseek - 重新定位读/写文件偏移定义#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;off_t lseek(int fd, off_t offset, int whence);lseek() 函数用于重新定位与文件描述符 fd 关联的打开文件的偏移量，依据参数 whence 指定的指令调整 offset，具体如下：  SEEK_SET: 将偏移量设置为 offset 字节。  SEEK_CUR: 将偏移量设置为当前位置加上 offset 字节。  SEEK_END: 将偏移量设置为文件大小加上 offset 字节。lseek() 允许将文件偏移量设置到文件末尾之后，但不会改变文件的实际大小。如果稍后在此位置写入数据，那么在这个位置之前的 “空洞” 中读取到的数据将返回空字节（即 '\\0'），直到真正有数据写入这些 “空洞”。搜索文件数据和空洞自 Linux 3.1 版起，支持以下 whence 选项：  SEEK_DATA: 将文件偏移量调整到文件中大于或等于 offset 的下一个包含数据的位置。如果 offset 指向数据位置，则将偏移量设置为 offset。  SEEK_HOLE: 将文件偏移量调整到文件中大于或等于 offset 的下一个空洞的位置。如果 offset 指向空洞中间，则将偏移量设置为 offset。如果在 offset 之后没有空洞，偏移量将调整为文件末尾（文件末尾隐含一个空洞）。在这两种情况下，如果 offset 超过文件末尾，lseek() 将失败。这些操作允许应用程序在稀疏分配的文件中映射空洞。例如，文件备份工具可以利用这一功能来节省空间，通过发现空洞来保留这些稀疏部分。关于空洞的定义对于这些操作来说，空洞是指在底层文件存储中尚未分配的全零字节序列。然而，文件系统并没有义务报告空洞，因此这些操作并不能保证准确映射文件实际分配的存储空间（而且，已经写入底层存储的零字节序列可能不会被视为空洞）。在最简单的实现中，文件系统可以通过以下方式支持这些操作：使 SEEK_HOLE 总是返回文件末尾的偏移量，而 SEEK_DATA 总是返回 offset，即使 offset 指向空洞，该位置也可以被视为数据（全零字节序列）。返回值成功完成后，lseek() 返回结果偏移位置（从文件开头开始以字节为单位）。出错时，返回值 (off_t) -1，并设置 errno 来指示错误。mkdir描述mkdir - 创建目录定义返回值munmap描述mmap、munmap - 将文件或设备映射或取消映射到内存中定义#include &lt;sys/mman.h&gt;void *mmap(void *addr, size_t lengthint \" prot \", int \" flags ,                      int fd, off_t offset);int munmap(void *addr, size_t length);mmap() 在调用进程的虚拟地址空间中创建一个新的映射。新映射的起始地址在 addr 中指定。长度参数指定映射的长度。返回值成功时，mmap() 返回指向映射区域的指针。出错时，返回值 MAP_FAILED（即 (void *) -1），并适当设置 errno。成功时，munmap() 返回 0，失败时返回 -1，并且设置 errno（可能为 EINVAL）。newfstatat描述newfstatatstat、fstat、lstat、fstatat - 获取文件状态定义返回值openat描述openat - 打开相对于目录文件描述符的文件定义#include &lt;fcntl.h&gt;int openat(int dirfd, const char *pathname, int flags);int openat(int dirfd, const char *pathname, int flags, mode_t mode);返回值rt_sigaction描述sigaction - 检查并更改信号操作定义#include &lt;signal.h&gt;int sigaction(int signum, const struct sigaction *act,                            struct sigaction *oldact);sigaction() 系统调用用于更改进程在收到特定信号时所采取的操作。 （有关信号的概述，请参阅 signal(7)。）Signum 指定信号，可以是除 SIGKILL 和 SIGSTOP 之外的任何有效信号。如果 act 为非 NULL，则从 act 安装信号signum 的新操作。如果oldact非NULL，则前一个操作将保存在oldact中。返回值rt_sigreturn描述sigreturn - 从信号处理程序返回并清理堆栈帧定义int sigreturn(unsigned long __unused);当 Linux 内核为信号处理程序创建堆栈帧时，对 sigreturn() 的调用将插入到堆栈帧中，以便在从信号处理程序返回时调用 sigreturn()。返回值sendto描述send、sendto、sendmsg - 在套接字上发送消息定义#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;ssize_t send(int sockfd, const void *buf, size_t len, int flags);ssize_t sendto(int sockfd, const void *buf, size_t len, int flags,                              const struct sockaddr *dest_addr, socklen_t addrlen);ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);系统调用 send()、sendto() 和 sendmsg() 用于将消息传输到另一个套接字。返回值setitimer描述getitimer、setitimer - 获取或设置间隔计时器的值定义#include &lt;sys/time.h&gt;int getitimer(int which, struct itimerval *curr_value);int setitimer(int which, const struct itimerval *new_value,                            struct itimerval *old_value);系统为每个进程提供三个间隔计时器，每个计时器在不同的时域内递减。当任何计时器到期时，都会向进程发送一个信号，并且计时器（可能）重新启动。返回值write描述write - 写入文件描述符定义#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t count);write() 将 buf 指向的缓冲区中最多 count 个字节写入文件描述符 fd 引用的文件。返回值writev描述readv、writev、preadv、pwritev - 将数据读取或写入多个缓冲区定义#include &lt;sys/uio.h&gt;ssize_t readv(int fd, const struct iovec *iov, int iovcnt);ssize_t writev(int fd, const struct iovec *iov, int iovcnt);ssize_t preadv(int fd, const struct iovec *iov, int iovcnt,                              off_t offset);ssize_t pwritev(int fd, const struct iovec *iov, int iovcnt,                                off_t offset);readv() 系统调用将 iovcnt 缓冲区从与文件描述符 fd 关联的文件读取到 iov （“分散输入”）描述的缓冲区中。writev() 系统调用将 iov 描述的数据的 iovcnt 缓冲区写入与文件描述符 fd 关联的文件（“收集输出”）。返回值参考https://linux.die.net/https://www.kernel.org/doc/html/latest/https://www.kernel.org/doc/html/latest/_CNhttps://www.linuxdoc.org/https://tldp.org/guides.htmlhttps://helpmanual.io/man2/newfstatat/http://man.he.net/man2/newfstatathttps://github.com/torvalds/linux"
  },
  
  {
    "title": "PostgreSQL OID",
    "url": "/posts/PostgreSQL-OID/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-09-10 11:47:22 +0800",
    





    
    "snippet": "前言在 PostgreSQL 内部，所有的数据库对象都通过相应的对象标识符（Object Identifiers, OID）进行管理，这些标识符是无符号的 4 字节整型。数据库对象与相应 OID 之间的关系存储在相应的系统目录中，依具体的对象类型而异。 例如数据库和堆表对象的 OID 分别存储在 pg_database 和 pg_class 中，如果需要获取 OID 时，可以执行以下查询：S...",
    "content": "前言在 PostgreSQL 内部，所有的数据库对象都通过相应的对象标识符（Object Identifiers, OID）进行管理，这些标识符是无符号的 4 字节整型。数据库对象与相应 OID 之间的关系存储在相应的系统目录中，依具体的对象类型而异。 例如数据库和堆表对象的 OID 分别存储在 pg_database 和 pg_class 中，如果需要获取 OID 时，可以执行以下查询：SELECT datname, oid FROM pg_database WHERE datname = '&amp;dbname';SELECT relname, oid FROM pg_class WHERE relname = '&amp;relname';SELECT pg_relation_filepath('&amp;tabname');注意rename table/database 对表或者 db 进行重命名操作都不会变更 relfilenode127.0.0.1:54323; wxj@demo &gt; select schemaname, tablename, pg_relation_filepath(tablename::text) from pg_tables where schemaname = 'bookings';+------------+-----------------+----------------------+| schemaname |    tablename    | pg_relation_filepath |+------------+-----------------+----------------------+| bookings   | ticket_flights  | base/16417/16467     || bookings   | boarding_passes | base/16417/16440     || bookings   | aircrafts_data  | base/16417/16421     || bookings   | flights         | base/16417/16446     || bookings   | airports_data   | base/16417/16431     || bookings   | seats           | base/16417/16463     || bookings   | tickets         | base/16417/16472     || bookings   | bookings        | base/16417/16443     |+------------+-----------------+----------------------+127.0.0.1:54323; wxj@demo &gt; alter database demo rename to demo01;ERROR:  current database cannot be renamedTime: 1.187 ms127.0.0.1:54323; wxj@demo &gt; \\c testdbYou are now connected to database \"testdb\" as user \"wxj\".127.0.0.1:54323; wxj@testdb &gt; alter database demo rename to demo01;ALTER DATABASETime: 2.038 ms127.0.0.1:54323; wxj@testdb &gt; select schemaname, tablename, pg_relation_filepath(tablename::text) from pg_tables where schemaname = 'bookings';+------------+-----------+----------------------+| schemaname | tablename | pg_relation_filepath |+------------+-----------+----------------------++------------+-----------+----------------------+(0 rows)Time: 75.493 ms127.0.0.1:54323; wxj@testdb &gt; \\c demo01You are now connected to database \"demo01\" as user \"wxj\".127.0.0.1:54323; wxj@demo01 &gt; select schemaname, tablename, pg_relation_filepath(tablename::text) from pg_tables where schemaname = 'bookings';+------------+-----------------+----------------------+| schemaname |    tablename    | pg_relation_filepath |+------------+-----------------+----------------------+| bookings   | ticket_flights  | base/16417/16467     || bookings   | boarding_passes | base/16417/16440     || bookings   | aircrafts_data  | base/16417/16421     || bookings   | flights         | base/16417/16446     || bookings   | airports_data   | base/16417/16431     || bookings   | seats           | base/16417/16463     || bookings   | tickets         | base/16417/16472     || bookings   | bookings        | base/16417/16443     |+------------+-----------------+----------------------+(8 rows)Time: 7.055 ms"
  },
  
  {
    "title": "PostgreSQL 硬性限制",
    "url": "/posts/PostgreSQL-%E7%A1%AC%E6%80%A7%E9%99%90%E5%88%B6/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-09-06 15:43:17 +0800",
    





    
    "snippet": "https://www.postgresql.org/docs/current/limits.html在使用 pg 的时候，需要注意一些硬性限制，例如代码中写死的，这里记录一下，方便自己查阅，有的时候直接查阅官网反而因为内容太多导致忘记这些关键内容            Item      Upper Limit      Comment                  database ...",
    "content": "https://www.postgresql.org/docs/current/limits.html在使用 pg 的时候，需要注意一些硬性限制，例如代码中写死的，这里记录一下，方便自己查阅，有的时候直接查阅官网反而因为内容太多导致忘记这些关键内容            Item      Upper Limit      Comment                  database size      unlimited                     number of databases      4,294,950,911                     relations per database      1,431,650,303                     relation size      32 TB      with the default BLCKSZ of 8192 bytes              rows per table      limited by the number of tuples that can fit onto 4,294,967,295 pages                     columns per table      1,600      further limited by tuple size fitting on a single page; see note below              columns in a result set      1,664                     field size      1 GB                     indexes per table      unlimited      constrained by maximum relations per database              columns per index      32      can be increased by recompiling PostgreSQL              partition keys      32      can be increased by recompiling PostgreSQL              identifier length      63 bytes      can be increased by recompiling PostgreSQL              function arguments      100      can be increased by recompiling PostgreSQL              query parameters      65,535             "
  },
  
  {
    "title": "Linux 利用 wc 统计行数和字符长度",
    "url": "/posts/Linux-%E5%88%A9%E7%94%A8-wc-%E7%BB%9F%E8%AE%A1%E8%A1%8C%E6%95%B0%E5%92%8C%E5%AD%97%E7%AC%A6%E9%95%BF%E5%BA%A6/",
    "categories": "Linux, tools",
    "tags": "wc",
    "date": "2024-09-05 16:18:22 +0800",
    





    
    "snippet": "前言在 Linux 环境中可以利用 wc 工具统计行数和字符长度等统计行数和字符长度wc 使用特别简单，可以使用 wc --help 查看使用帮助，本文主要记录一下统计行数和字符长度的时候遇到的一个小问题，统计字符的长度不准在统计一个字符长度的时候明明是 24 位，但是 wc 的结果却是 25┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ ech...",
    "content": "前言在 Linux 环境中可以利用 wc 工具统计行数和字符长度等统计行数和字符长度wc 使用特别简单，可以使用 wc --help 查看使用帮助，本文主要记录一下统计行数和字符长度的时候遇到的一个小问题，统计字符的长度不准在统计一个字符长度的时候明明是 24 位，但是 wc 的结果却是 25┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo 000000010000000000000001 | wc -m25还好我记得长度是 24 ，wc 统计的结果却是 25，多出来一个字符长度，这是什么原因呢？┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo 1 | wc -m2┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo | wc -m1可以看到，即便统计空的字符也会有一个字符长度，难道闹鬼了？肯定不是，在现代主义国家，这是不可能的事。这个时候可以利用 cat 工具的 -A 选项查看所有的(隐藏)字符：┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo 1 | cat -A1$可以发现末尾有一个 ‘$’ ，这怎么处理呢，总不能还要单独处理这个字符吧。因为 echo 会自动换行，所以才会多出来一个 ‘$’ 字符，可以使用选项 -n 避免换行┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo -n 1 | cat -A1┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo -n 1 | wc -m1使用 wc -l 统计行数的时候也是同理：┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo | wc -l1┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo -n | wc -l0┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ echo | cat -A$总结其实这不是 wc 工具的问题，是 echo 自动换行/添加新行导致的。如果需要统计 echo 展示的内容行数和字符数量，需要使用 ‘echo -n’ 避免自动添加新行后续测试发现通过管道符或者直接读取文件中内容都会因为 ‘$’ 字符导致统计字符数量不准确，之前没怎么注意，这次发现这个问题在此记录一下：┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ basename /Postgres/pg10data/pg_wal/000000010000000000000001000000010000000000000001┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ basename /Postgres/pg10data/pg_wal/000000010000000000000001 | wc -m25┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ basename /Postgres/pg10data/pg_wal/000000010000000000000001 | cat -A000000010000000000000001$┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ basename /Postgres/pg10data/pg_wal/000000010000000000000001 &gt; tmp.txt┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ wl -m tmp.txt-bash: wl: command not found┌─[✗]─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ wc -m tmp.txt25 tmp.txt┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ &gt; tmp.txt┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ vim tmp.txt┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ ┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $┌─[postgres@darkstarc]─[/Postgres/tools]└──╼ $ wc -m tmp.txt25 tmp.txt"
  },
  
  {
    "title": "PostgreSQL Write Ahead Logging WAL",
    "url": "/posts/PostgreSQL-Write-Ahead-Logging-WAL/",
    "categories": "DataBase, PostgreSQL",
    "tags": "WAL",
    "date": "2024-09-05 15:15:35 +0800",
    





    
    "snippet": "前言WAL 是 Write Ahead Log 的缩写，预写式日志。WAL log 也被称为 xlog 。WalWriter 进程就是写 WAL 日志的进程。预写式日志的概念就是在修改数据之前，必须要把这些修改操作记录到磁盘中，这样后面更新实际数据时，就不需要实时地把数据持久化到文件中了。即使机器突然宕机或数据库异常退出，导致一部分内存中的脏数据没有及时地刷新到文件中，在数据库重启后，通过读...",
    "content": "前言WAL 是 Write Ahead Log 的缩写，预写式日志。WAL log 也被称为 xlog 。WalWriter 进程就是写 WAL 日志的进程。预写式日志的概念就是在修改数据之前，必须要把这些修改操作记录到磁盘中，这样后面更新实际数据时，就不需要实时地把数据持久化到文件中了。即使机器突然宕机或数据库异常退出，导致一部分内存中的脏数据没有及时地刷新到文件中，在数据库重启后，通过读取 WAL 日志，并把最后一部分的 WAL 日志重新执行一遍，就可以恢复到宕机时的状态。作用WAL 可以理解为 pg 数据库的重做日志与 Oracle 的Redo Log 的功能是一样的。因为 WAL 的存在，所以日志类型的文件系统对于 pg 来说不是必须的。例如 zfs 就是日志类型的文件系统，在持久化之前会记录日志，保证数据的原子性。（而且每当新数据写入 ZFS 时，它都会为该数据创建校验和（checksum）。当读取该数据时，校验和被验证。如果校验和不匹配，则 ZFS 知道已检测到错误。然后 ZFS 将自动尝试更正错误。）日志文件系统 在日志记录开销会降低性能，特别是当日志记录导致文件系统数据被刷新到磁盘时。不过，日志记录期间的数据刷新通常可以通过文件系统挂载选项禁用，例如在Linux ext3文件系统上。但是日志文件系统可以提高崩溃后的启动速度。使用 WAL 可以显著减少磁盘写入次数，因为只需要将日志文件刷新到磁盘以保证提交事务，而不是事务更改的每个数据文件。日志文件是按顺序写入的，因此同步日志的成本远低于刷新数据页的成本。对于处理许多涉及数据存储不同部分的小事务的服务器来说，尤其如此。此外，当服务器正在处理许多小型并发事务时，其中一个日志文件可能足以提交许多事务。WAL 还可以支持在线备份和时间点恢复。通过存档 WAL 数据，我们可以支持恢复到可用 WAL 数据所覆盖的任何时间：我们只需安装数据库的先前物理备份，并在所需时间重放 WAL 日志。更重要的是，物理备份不必是数据库状态的实时快照。 如果它是在一段时间内进行的，那么重放该时间段的 WAL 日志将解决任何内部数据不一致的问题。文件位置WAL 文件在 PostgreSQL9.X 及以下版本是在 pg_xlog 目录下的，而在 PostgreSQL10.X 及以上版本是在 pg_wal 目录下的。查看 WAL 文件所在的目录，会看到如下文件列表:## 文件名为24个字母长度的都是WAL文件pg15@TheDarkStar:/data_dir/PostgreSQL/data$ ll pg15/pg_wal/total 16388-rw------- 1 pg15 pg15 16777216 Sep  9 19:30 000000010000000000000001drwx------ 2 pg15 pg15     4096 Sep  8 16:18 archive_statusWAL 日志保存在 pg_xlog/pg_wal 下。每个 xlog 文件默认是 16MB，为了满足恢复要求，在 xlog 目录下会产生多个 WAL 日志，这样就可保证在宕机后，未持久化的数据都可以通过 WAL 日志来恢复，那些不需要的 WAL 日志将会被自动覆盖WAL 文件名的意义WAL 文件名的长度是固定的 24 位，由三部分组成，每一个部分 8 个字符长度：  时间线:英文为 timeline，是以 1 开始的递增数字，如 1，2，3……  LogId: 32 bit 长的一个数字，是以 0 开始递增的，如 0，1，2 实际为 LSN 的高 32 bit。  LogSeg: 32 bit 长的一个数字，是以 0 开始递增的，如 0，1，2, 3，···。LogSeg 是 LSN 的低 32 bit 的值再除以 WAL 文件大小 (通常为 16 MB) 的结果。注意: 当 LogId 为 0 时，LogSeg 是从 1 开始的。 WAL日志文件默认大小为16MB，如果想改变其大小，在PostgreSQL10.X及之前的版本中需要重新编译程序，在PostgreSQL11.X版本之后，可以在Initdb初始化数据库实例时指定WAL文件的大小。如果WAL文件是默认大小，即16MB时，LogSeg最大为FF，即000000~0000FF，即在文件名中，最后8字节中前6字节总是0。这是因为LSN的低32bit的值再除以WAL文件大小[2^32/(16*1024*1024)=256]最大只能是256，换算成十六进制，即FF。总结WAL 相当于 Oracle 的 redo log，用于 pg 实例崩溃恢复是保证数据完整一致。WAL 采用顺序写入的方式，而且在数据的变更刷盘之前先行写入可以参考官网描述"
  },
  
  {
    "title": "PostgreSQL WAL 相关参数",
    "url": "/posts/PostgreSQL-WAL-%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0/",
    "categories": "DataBase, PostgreSQL",
    "tags": "WAL",
    "date": "2024-09-05 15:09:00 +0800",
    





    
    "snippet": "前言WAL 是 PostgreSQL 的关键组件，用于保证崩溃恢复时数据完整一致，在这里记录一下相关的参数WAL 参数不同的版本可能参数不一样，具体可以查询官网或者进入实例之后查询：-- PostgreSQL 15.8 -- 如果需要参数描述和范围可以查看 short_desc, extra_desc, context 字段127.0.0.1:54323; wxj@demo &gt; sel...",
    "content": "前言WAL 是 PostgreSQL 的关键组件，用于保证崩溃恢复时数据完整一致，在这里记录一下相关的参数WAL 参数不同的版本可能参数不一样，具体可以查询官网或者进入实例之后查询：-- PostgreSQL 15.8 -- 如果需要参数描述和范围可以查看 short_desc, extra_desc, context 字段127.0.0.1:54323; wxj@demo &gt; select name, setting, unit from pg_settings where name like '%wal%';+-------------------------------+-----------+------+|             name              |  setting  | unit |+-------------------------------+-----------+------+| max_slot_wal_keep_size        | -1        | MB   || max_wal_senders               | 10        | NULL || max_wal_size                  | 1024      | MB   || min_wal_size                  | 80        | MB   || track_wal_io_timing           | off       | NULL || wal_block_size                | 8192      | NULL || wal_buffers                   | 512       | 8kB  || wal_compression               | off       | NULL || wal_consistency_checking      |           | NULL || wal_decode_buffer_size        | 524288    | B    || wal_init_zero                 | on        | NULL || wal_keep_size                 | 0         | MB   || wal_level                     | replica   | NULL || wal_log_hints                 | off       | NULL || wal_receiver_create_temp_slot | off       | NULL || wal_receiver_status_interval  | 10        | s    || wal_receiver_timeout          | 60000     | ms   || wal_recycle                   | on        | NULL || wal_retrieve_retry_interval   | 5000      | ms   || wal_segment_size              | 16777216  | B    || wal_sender_timeout            | 60000     | ms   || wal_skip_threshold            | 2048      | kB   || wal_sync_method               | fdatasync | NULL || wal_writer_delay              | 200       | ms   || wal_writer_flush_after        | 128       | 8kB  |+-------------------------------+-----------+------+(25 rows)以下内容参考文档翻译描述Replication 流复制相关max_slot_wal_keep_size指定主库实例可以支持的最大复制槽数量，详情参考。默认值为  10 。此参数只能在实例启动时设置。将其设置为低于当前现有复制槽数量的值将无法启动实例。另外，wal_level 必须设置为 replica  或更高才能允许使用复制槽。在订阅端，指定可以同时跟踪多少个复制源，参考，从而有效限制可以在实例中创建的逻辑复制订阅数量。将其设置为低于当前跟踪的复制源数量（可以通过 pg_replication_origin_status 查询，请注意并不是 pg_replication_origin ）的值将阻止实例启动。max_wal_senders指定来自备库或流基础备份客户端的最大并发连接数（即同时运行的 WAL 发送进程的最大数量）。默认值为 10。取值为 0 表示禁用复制。流客户端的突然断开连接可能会留下孤立的连接槽，直到达到超时为止，因此该参数应设置为略高于预期客户端的最大数量，以便断开连接的客户端可以立即重新连接。该参数只能在服务器启动时设置。此外，wal_level 必须设置为 replica 或更高，以允许来自备库的连接。运行备库时，必须将此参数设置为与主库相同或更高的值。否则，备库将不允许查询。wal_keep_size指定保留在 pg_wal 目录中的过去日志文件段的最小大小，以防备用服务器需要获取它们以进行流复制。如果连接到发送服务器的备用服务器落后超过 wal_keep_size 兆字节，则发送服务器可能会删除备用服务器仍需要的 WAL 段，在这种情况下，复制连接将终止。下游连接最终也将因此失败。 （但是，如果正在使用 WAL 归档，备用服务器可以通过从归档中获取段来恢复。）这仅设置 pg_wal 中保留的段的最小大小；系统可能需要保留更多的段用于 WAL 归档或从检查点恢复。如果 wal_keep_size 为零（默认值），系统不会保留任何额外的段用于备用目的，因此备用服务器可用的旧 WAL 段的数量是前一个检查点的位置和 WAL 归档状态的函数。如果指定该值时没有单位，则以兆字节为单位。该参数只能在 postgresql.conf 文件或服务器命令行中设置。wal_levelwal_level 决定了写入 WAL（预写日志）的信息量。默认值为 replica，记录足够的数据以支持 WAL 归档和复制，包括在备用服务器上运行只读查询。minimal 则删除所有日志记录，除了恢复崩溃或立即关闭所需的信息。最后，logical 添加了支持逻辑解码所需的信息。每个级别都包含所有较低级别记录的信息。此参数只能在服务器启动时设置。minimal 级别生成最少的 WAL 量。对于创建或重写永久关系的事务，它不会记录行信息。这可以显著加快操作（参考）。发起此优化的操作包括：ALTER … SET TABLESPACECLUSTERCREATE TABLEREFRESH MATERIALIZED VIEW（不带 CONCURRENTLY）REINDEXTRUNCATE然而，minimal WAL 不包含足够的信息来进行时间点恢复，因此需要使用 replica 或更高的级别来启用连续归档（archive_mode）和流式二进制复制。实际上，如果 max_wal_senders 不为零，服务器甚至无法以该模式启动。请注意，将 wal_level 更改为 minimal 会使先前的基本备份无法用于时间点恢复和备用服务器。在 logical 级别，记录与 replica 相同的信息，外加从 WAL 中提取逻辑更改集所需的信息。使用 logical 级别会增加 WAL 量，特别是当许多表配置为 REPLICA IDENTITY FULL 并执行大量的 UPDATE 和 DELETE 语句时。在 9.6 之前的版本中，此参数还允许使用 archive 和 hot_standby 作为值。这些值仍然被接受，但会映射到 replica。wal_receiver_timeout终止超过该时间段未活动的复制连接。这对于接收备用服务器检测主节点崩溃或网络中断非常有用。如果此值未指定单位，则默认以毫秒计算。默认值为 60 秒。值为 0 则禁用超时机制。此参数只能在 postgresql.conf 文件中或通过服务器命令行设置。wal_retrieve_retry_interval指定当从任何来源（流复制、本地 pg_wal 或 WAL 归档）无法获取 WAL 数据时，备用服务器应等待多长时间再尝试检索 WAL 数据。如果此值未指定单位，则默认以毫秒计算。默认值为 5 秒。此参数只能在 postgresql.conf 文件或服务器命令行中设置。此参数在恢复节点需要控制等待新 WAL 数据可用的时间时非常有用。例如，在归档恢复中，通过减少此参数的值，可以使恢复对检测新 WAL 日志文件更加敏感。在 WAL 活动较少的系统上，增加此值可以减少访问 WAL 归档的请求次数，这在云环境中尤为有用，因为基础设施的访问次数会被考虑在内。wal_sender_timeout终止超过该时间段未活动的复制连接。这对于发送服务器检测备用服务器崩溃或网络中断非常有用。如果此值未指定单位，则默认以毫秒计算。默认值为 60 秒。值为 0 则禁用超时机制。在跨多个地理位置分布的集群中，为不同位置使用不同的值可以为集群管理带来更大的灵活性。对于具有低延迟网络连接的备用服务器，较小的值有助于更快地检测故障；对于位于远程位置且网络延迟较高的备用服务器，较大的值有助于更好地判断备用服务器的健康状况。wal-configurationmin_wal_size / max_wal_sizepg_wal 目录中的 WAL 段文件数量取决于 min_wal_size、max_wal_size 以及之前检查点周期生成的 WAL 数量。当不再需要旧的日志段文件时，它们将被删除或回收。如果由于日志输出率的短期峰值而超过 max_wal_size，则不需要的段文件将被删除，直到系统恢复到此限制以下。低于该限制，系统将回收足够的 WAL 文件以满足下一个检查点之前的估计需求，并删除其余文件。该估计基于先前检查点周期中使用的 WAL 文件数量的移动平均值。如果实际使用量超过估计值，移动平均值会立即增加，因此它在一定程度上适应了峰值使用量而不是平均使用量。 min_wal_size 设置了为将来使用而回收的 WAL 文件数量的最小值；即使系统空闲并且 WAL 使用量估计表明只需要很少的 WAL，那么多的 WAL 总是会被回收以供将来使用。只要 WAL 磁盘使用量保持在 min_wal_size 设置以下，旧的 WAL 文件总是会被回收以供将来在检查点使用，而不是被删除。这可用于确保保留足够的 WAL 空间来处理 WAL 使用量的峰值，例如在运行大型批处理作业时。如果指定该值时没有单位，则以兆字节为单位。默认值为 80 MB。该参数只能在 postgresql.conf 文件或服务器命令行中设置。max_wal_size 表示 WAL 在自动检查点期间增长的最大大小。这是一个软限制；在特殊情况下，WAL 大小可能会超过 max_wal_size，例如高负载、archive_command 或 archive_library 失败或较高的 wal_keep_size 设置。如果指定该值时没有单位，则以兆字节为单位。默认值为 1 GB。增加此参数可以增加崩溃恢复所需的时间。该参数只能在 postgresql.conf 文件或服务器命令行中设置。track_wal_io_timing有两个内部函数将 WAL 数据写入磁盘：XLogWrite 和 issue_xlog_fsync 。当 track_wal_io_timing 启用时，XLogWrite 写入和 issue_xlog_fsync 将 WAL 数据同步到磁盘的总时间分别计为 pg_stat_wal 中的 wal_write_time 和 wal_sync_time 。 XLogWrite  通常由 XLogInsertRecord （当 WAL 缓冲区中没有空间容纳新记录时）、 XLogFlush 和 WAL writer 调用，以将 WAL 缓冲区写入磁盘并调用 issues_xlog_fsync。 issues_xlog_fsync 通常由 XLogWrite 调用以将 WAL 文件同步到磁盘。如果 wal_sync_method 是 open_datasync 或 open_sync，则 XLogWrite 中的写入操作保证将写入的 WAL 数据同步到磁盘，而 issues_xlog_fsync 不执行任何操作。如果 wal_sync_method 是 fdatasync、fsync 或 fsync_writethrough，则写入操作会将 WAL 缓冲区移动到内核缓存，并通过 issues_xlog_fsync 将它们同步到磁盘。无论 track_wal_io_timing 如何设置，XLogWrite 写入和 issue_xlog_fsync 将 WAL 数据同步到磁盘的次数也分别计为 pg_stat_wal 中的 wal_write 和 wal_sync 。启用 WAL I/O 调用的计时。该参数默认关闭，因为它会重复查询操作系统当前时间，这可能会在某些平台上造成很大的开销。您可以使用 pg_test_timing 工具来测量系统上的计时开销。 I/O 计时信息显示在 pg_stat_wal 中。只有超级用户和具有适当 SET 权限的用户才能更改此设置。wal_block_size设置 WAL block 大小。早期在编译时通过 --with-wal-blocksize 指定，现在可以在 initdb 初始化的时候指定，可以查看源码（src/include/catalog/pg_control.h）中 XLOG_BLCKSZ 的描述。默认值为 8192 字节。/* Size of a WAL file block. This need have no particular relation to BLCKSZ.                       XLOG_BLCKSZ must be a power of 2, and if your system supports O_DIRECT I/O,                       XLOG_BLCKSZ must be a multiple of the alignment requirement for direct-I/O                       buffers, else direct I/O may fail. Changing XLOG_BLCKSZ requires an initdb.                       */wal_buffers用于尚未写入磁盘的 WAL 数据的共享内存量。默认取值为 ‘-1’ ，这会自动调整选择等于 shared_buffers 的 1/32（约3%）的大小，但不小于 64kB 也不大于一个 WAL 段的大小，通常为 16MB 。如果自动选择太大或太小，可以手动设置该值，但任何小于 32kB  的正值都将被视为 32kB。如果指定该值时不带单位，则将其视为 WAL  块，即 XLOG_BLCKSZ 字节，通常为 8kB。该参数只能在服务器启动时设置。WAL 缓冲区的内容在每次事务提交时都会写入磁盘，因此极大的值不太可能提供显着的好处。但是，将此值设置为至少几兆字节可以提高许多客户端同时提交的繁忙服务器上的写入性能。在大多数情况下，默认设置 -1 选择的自动调整应该会给出合理的结果。wal_compression该参数允许使用指定的压缩方法来压缩 WAL。启用后，当 full_page_writes 开启或在基本备份期间，PostgreSQL 服务器会压缩写入 WAL 的全部 page image。压缩的 page image将在 WAL 重放期间被解压缩。支持的方法是 pglz、lz4（如果 PostgreSQL 是使用 –with-lz4 编译的）和 zstd（如果 PostgreSQL 是使用 –with-zstd 编译的）。默认值是关闭。只有超级用户和具有适当 SET 权限的用户才能更改此设置。启用压缩可以减少 WAL 体积，而不会增加不可恢复的数据损坏的风险，但代价是在 WAL 日志记录期间的压缩和 WAL 重放期间的解压缩上花费一些额外的 CPU。wal_consistency_checking在 src/test/recovery 下运行某些测试时使用 wal_consistency_checking=all。默认情况下不启用，因为它是资源密集型的。参考wal_decode_buffer_size对服务器可以在 WAL 中查找多远以查找要预取的块的限制。如果指定该值时没有单位，则将其视为字节。默认值为 512kB。恢复期间在WAL中提前读取的缓冲区大小在WAL中提前读取以预取引用数据块的最大距离wal_init_zero如果设置为打开（默认），此选项会导致新的 WAL 文件用零填充。在某些文件系统上，这可以确保在我们需要写入 WAL 记录之前分配空间。但是，写时复制 (COW) 文件系统可能无法从该技术中受益，因此可以选择跳过不必要的工作。如果设置为关闭，则在创建文件时仅写入最后一个字节，以使其具有预期的大小。wal_log_hints当该参数开启时，PostgreSQL 服务器在检查点后的第一次修改某个磁盘页时，会将该页的全部内容写入 WAL，甚至包括对所谓提示位（hint bits）的非关键修改。如果启用了数据校验和，提示位更新将始终记录在 WAL 中，并且该设置将被忽略。你可以使用此设置测试如果数据库启用了数据校验和，会产生多少额外的 WAL 日志。此参数只能在服务器启动时设置，默认值为 off。wal_recycle如果设置为 on（默认值），此选项会导致 WAL 文件通过重命名来回收，从而避免创建新文件。在 COW 文件系统上，创建新文件系统可能会更快，因此提供了禁用此行为的选项。wal_segment_sizewal segment 大小，默认 16MBwal_skip_threshold当 wal_level 设置为 minimal 且事务在创建或重写永久关系后提交时，此设置决定如何持久化新数据。如果数据小于此设置的值，则将其写入 WAL 日志；否则，使用受影响文件的 fsync。根据存储的特性，增大或减小此值可能有助于解决此类提交导致并发事务变慢的问题。如果此值未指定单位，则默认以千字节计算。默认值为两兆字节（2MB）。wal_sync_method用于强制将 WAL 更新写入磁盘的方法。如果 fsync 关闭，则此设置无关紧要，因为 WAL 文件的更新将不会被强制写出。可选值包括：  open_datasync（使用 open() 选项 O_DSYNC 写入 WAL 文件）  fdatasync（在每次提交时调用 fdatasync()）  fsync（在每次提交时调用 fsync()）  fsync_writethrough（在每次提交时调用 fsync()，强制写入磁盘写缓存）  open_sync（使用 open() 选项 O_SYNC 写入 WAL 文件）open_* 选项在可用时也使用 O_DIRECT。并非所有平台都支持这些选项。默认值为平台支持的上述方法中的第一个，但在 Linux 和 FreeBSD 上，默认值为 fdatasync。默认设置不一定是理想的；可能需要更改此设置或系统配置的其他方面，以创建崩溃安全的配置或实现最佳性能。关于这些方面的讨论参考。此参数只能在 postgresql.conf 文件中或通过服务器命令行设置。wal_writer_delay指定WAL写入器多久刷新一次WAL，以时间单位计。在刷新WAL后，写入器会根据wal_writer_delay指定的时间长度休眠，除非被异步提交的事务提前唤醒。如果最后一次刷新发生在wal_writer_delay之前，并且自那以后产生的WAL量少于wal_writer_flush_after所值得的量，则WAL只被写入到操作系统，而不是刷新到磁盘。如果这个值没有指定单位，它被当作毫秒。默认值是200毫秒（200ms）。请注意，在许多系统上，休眠延迟的有效分辨率是10毫秒；将wal_writer_delay设置为不是10的倍数的值可能会产生与设置为下一个更高的10的倍数相同的结果。这个参数只能在postgresql.conf文件或服务器命令行上设置。wal_writer_flush_after指定 WAL 写入器按数据量刷新的频率。如果上次刷新发生在 wal_writer_delay 规定的时间内，且自那时以来产生的 WAL 量少于 wal_writer_flush_after 的设定值，则 WAL 仅写入操作系统，而不会刷新到磁盘。如果 wal_writer_flush_after 设置为 0，则 WAL 数据始终会立即刷新。如果此值未指定单位，则默认以 WAL 块为单位，即 XLOG_BLCKSZ 字节，通常为 8kB。默认值为 1MB。此参数只能在 postgresql.conf 文件中或通过服务器命令行设置。参考WAL ConfigurationReplication也可以查看源码文件 src/backend/access/transam/xlog.c 中的定义和描述"
  },
  
  {
    "title": "Windows 利用 Netsh 管理 WiFi 连接",
    "url": "/posts/Windows-%E5%88%A9%E7%94%A8-Netsh-%E7%AE%A1%E7%90%86-WiFi-%E8%BF%9E%E6%8E%A5/",
    "categories": "Windows, Network",
    "tags": "WiFi",
    "date": "2024-09-05 10:33:43 +0800",
    





    
    "snippet": "前言基本现在的轻薄笔记本都已经没有网线接口了，除了拓展坞之外只能使用 WiFi 连接网络。当我们重装系统或者更换电脑的时候需要重新配置网络，手动配置的方式效率较低，可以利用 Windows 下的 netsh 工具备份已有的 WiFi 连接信息，然后在其他机器导入或者重装系统之后恢复 WiFi 信息。在 Windows 中可以通过 控制面板的网络管理，或者网卡属性查看 WiFi 信息。不过比较...",
    "content": "前言基本现在的轻薄笔记本都已经没有网线接口了，除了拓展坞之外只能使用 WiFi 连接网络。当我们重装系统或者更换电脑的时候需要重新配置网络，手动配置的方式效率较低，可以利用 Windows 下的 netsh 工具备份已有的 WiFi 连接信息，然后在其他机器导入或者重装系统之后恢复 WiFi 信息。在 Windows 中可以通过 控制面板的网络管理，或者网卡属性查看 WiFi 信息。不过比较麻烦，可以通过命令行的方式管理网络，主要命令是 netsh微软从 Windows 2000 开始便内置了一个 Netsh（Network Shell）命令行工具，以帮助用户执行本地或远程计算机上不同网卡的信息查看、配置及排错工作。因为涉及网络的管理配置，所以在使用 Netsh 的时候请使用管理员用户打开 cmd、powershell、或者 Windows terminal 等终端工具。亦或者安装 sudo、gsudo 等临时提升权限的工具查看已保存的 WiFi 配置对于我们已经连接过的 WiFi 连接都会生成一个配置文件，可以使用以下方式查看现有的 WiFi 配置文件Netsh WLAN show profiles以上命令会显示出所有无线网卡连接过的 WIFI 配置文件，如果你有多块无线网卡，还可以使用 interface 参数跟上网卡名称进行单独列出：Netsh WLAN show profiles interface=\"无线网卡名称\"查看无线网卡驱动信息要查看当前 Windows  的无线网卡驱动信息可以使用如下命令：Netsh WLAN show drivers查看无线网卡兼容性可以使用以下命令来查看当前无线网卡所支持及兼容的（系统及硬件）功能：Netsh WLAN show wirelesscapabilities查看无线网卡的接口信息如果需要查看无线网卡的：无线电类型、信道、传输速率、连接模式等信息时，可以使用以下命令：Netsh WLAN show interfaces默认查看所有的接口信息，也可以指定网卡名称Netsh WLAN show interface name=\"网卡名称\"查看 WIFI 密码## 需要使用关键字 key=clear ，否则会隐藏密码字段Netsh WLAN show profile name=\"无线名称\" key=clear关闭自动连接到某个 WIFI 无线网络通常连接 WiFi 的时候，都会默认勾选自动连接选项，但在有多个无线网络的情况下，系统自动选择连接的 WIFI 可能信号较差，或者并不是我们希望连接的网络，此时我们可以使用如下命令取消自动连接某个 WIFI 无线网络：Netsh WLAN set profileparameter name=\"无线名称\" connectionmode=manual开启自动连接到某个 WiFi 网络恢复自动连接，只需将最后的参数改为 auto 即可Netsh WLAN set profileparameter name=\"无线名称\" connectionmode=auto删除 WIFI 配置文件当你不需要再连接某个无线网络、更改了 SSID 或需要重置配置文件时，可以使用如下命令来删除指定的 WIFI 配置文件：Netsh WLAN delete profile name=\"无线名称\"注意：如果你使用 Microsoft Account 登录到 Windows 10 / 11 ，WIFI 的配置文件默认会在不同设备间进行同步，但删除 WIFI 配置文件的操作不会同步到其它设备上。备份/导出 WIFI 无线网络配置文件导出 WIFI 无线网络配置的 xml 文件：Netsh WLAN export profile key=clearNetsh WLAN export profile key=clear folder=\"存放路径\"如果不指定 folder 选项，默认会在当前路径生成对应的 xml 文件默认情况下会为每个 WIFI 连接都导出一个单独的配置文件，如果你只想导出单个配置文件，可以使用如下命令Netsh WLAN export profile name=\"无线名称\" key=clear folder=\"存放路径\"注意：导出的 XML 配置文件是明文存储，而且会导出 WIFI 连接密码，所以请一定妥善保存。如果不指定 key=clear 选项并不会导出密码信息，需要在连接的手动更新密码信息恢复/导入 WiFi 配置文件Netsh WLAN add profile filename=\"存放路径\"## 如果需要为所有用户恢复需要使用 user=all 选项Netsh WLAN add profile filename=\"存放路径\" user=all生成无线网卡报告可以使用如下命令来创建和生成详细的无线网卡报告：Netsh WLAN show WLANreport总结在 Windows 下可以使用 Netsh 工具管理配置 网络，更多的使用方法可以使用 netsh /? 查看，或者查看这里如果需要查看或者备份/导出 WiFi 密码，需要使用选项 key=clear管理有线网络的话，使用 Netsh LAN 操作如果需要按照用户管理，请使用选项 user=all 或者 user=$username"
  },
  
  {
    "title": "查看 g++编译器默认编译标准",
    "url": "/posts/%E6%9F%A5%E7%9C%8B-g++%E7%BC%96%E8%AF%91%E5%99%A8%E9%BB%98%E8%AE%A4%E7%BC%96%E8%AF%91%E6%A0%87%E5%87%86/",
    "categories": "gcc",
    "tags": "gcc",
    "date": "2024-09-04 14:24:27 +0800",
    





    
    "snippet": "简单记录下怎么查看当前 g++ 编译器默认支持的 cpp 标准，毕竟 cpp 20 都已经出来几年了，有些特性编译器还没有完全支持g++ -dM -E -x c++ /dev/null | grep __cplusplus如果要查看 g++ 是否支持 cpp 20 可以执行以下命令g++ -std=c++20 -E -x c++ - &lt;&lt;&lt; \"\"如果你的 g++ 版本支持 ...",
    "content": "简单记录下怎么查看当前 g++ 编译器默认支持的 cpp 标准，毕竟 cpp 20 都已经出来几年了，有些特性编译器还没有完全支持g++ -dM -E -x c++ /dev/null | grep __cplusplus如果要查看 g++ 是否支持 cpp 20 可以执行以下命令g++ -std=c++20 -E -x c++ - &lt;&lt;&lt; \"\"如果你的 g++ 版本支持 C++20，那么该命令将不会报错，而会输出一些编译的信息。如果你的 g++ 版本不支持 C++20，那么该命令将会提示错误信息，告诉你该标志不被支持。更多的信息可以参考以下网址：https://en.cppreference.com/w/cpp/compiler_support/20https://cplusplus.com/doc/tutorial/"
  },
  
  {
    "title": "PostgreSQL 单块读",
    "url": "/posts/PostgreSQL-%E5%8D%95%E5%9D%97%E8%AF%BB/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-09-03 11:37:34 +0800",
    





    
    "snippet": "前言什么是单块读？顾名思义，就是每次读取单个 block 。Oracle 是支持多块读，今天测试一下 PostgreSQL 是否支持多块读，虽然之前听说是不支持的，今天直接测试验证一下。测试使用的工具为：strace 、pg 15block_sizePostgreSQL 可以通过 block_size 设置 block 的大小。不过这个参数是只读的，在数据库安装之后就无法修改了。默认是 8K...",
    "content": "前言什么是单块读？顾名思义，就是每次读取单个 block 。Oracle 是支持多块读，今天测试一下 PostgreSQL 是否支持多块读，虽然之前听说是不支持的，今天直接测试验证一下。测试使用的工具为：strace 、pg 15block_sizePostgreSQL 可以通过 block_size 设置 block 的大小。不过这个参数是只读的，在数据库安装之后就无法修改了。默认是 8K，可以在编译的时候通过选项 --with-blocksize 指定大小，另一个关于 wal 的选项 wal_block_size 最好取值相同。127.0.0.1:54323; wxj@postgres &gt; select * from pg_settings where name like '%block_size%';+-[ RECORD 1 ]----+----------------------------------------------+| name            | block_size                                   || setting         | 8192                                         || unit            | NULL                                         || category        | Preset Options                               || short_desc      | Shows the size of a disk block.              || extra_desc      | NULL                                         || context         | internal                                     || vartype         | integer                                      || source          | default                                      || min_val         | 8192                                         || max_val         | 8192                                         || enumvals        | NULL                                         || boot_val        | 8192                                         || reset_val       | 8192                                         || sourcefile      | NULL                                         || sourceline      | NULL                                         || pending_restart | f                                            |+-[ RECORD 2 ]----+----------------------------------------------+| name            | wal_block_size                               || setting         | 8192                                         || unit            | NULL                                         || category        | Preset Options                               || short_desc      | Shows the block size in the write ahead log. || extra_desc      | NULL                                         || context         | internal                                     || vartype         | integer                                      || source          | default                                      || min_val         | 8192                                         || max_val         | 8192                                         || enumvals        | NULL                                         || boot_val        | 8192                                         || reset_val       | 8192                                         || sourcefile      | NULL                                         || sourceline      | NULL                                         || pending_restart | f                                            |+-----------------+----------------------------------------------+安装之后，block_size 无法修改127.0.0.1:54323; wxj@postgres &gt; set block_size=16384;ERROR:  parameter \"block_size\" cannot be changedTime: 0.355 ms127.0.0.1:54323; wxj@postgres &gt;block_size 8k首先测试 block_size 为 8K 的时候情况数据是之前 pgbench 压测的时候产生的，通过读取 pgbench 产生的数据验证 PostgreSQL 的读取动作pgbench -i -s 100 -U postgres testdb获取进程号127.0.0.1:54323; wxj@testdb &gt; show block_size;+------------+| block_size |+------------+| 8192       |+------------+(1 row)127.0.0.1:54323; wxj@testdb &gt; select pg_backend_pid();+----------------+| pg_backend_pid |+----------------+|         849955 |+----------------+新开一个窗口对进程 strace根据得到的进程号 strace/Postgres/tools/strace_pg.sh 849955执行查询语句select count(1)  from pgbench_branches;+-------+| count |+-------+|   100 |+-------+(1 row)检查 strace 日志## 因为日志内容不多就直接贴图呢vim /Postgres/stracelog/849955_read.log可以看到每次 pread64 函数偏移量都是 8192，刚好为 block_size 大小。block_size 16K接下来测试一下当 block_size=16K 的情况。获取进程号127.0.0.1:54324; postgres@testdb &gt; select pg_backend_pid();+----------------+| pg_backend_pid |+----------------+|        1391395 |+----------------+(1 row)127.0.0.1:54324; postgres@testdb &gt; show block_size;+------------+| block_size |+------------+| 16384      |+------------+(1 row)新开窗口进行 strace┌─[postgres@darkstarc]─[~]└──╼ $ /Postgres/tools/strace_pg.sh  1391395postgres 1416671 1416670  0 10:42 pts/3    00:00:00 strace -tt -Y -f -r -o /Postgres/stracelog/1391395_read.log -p 1391395执行全表查询127.0.0.1:54324; postgres@testdb &gt; select count(1) from pgbench_accounts;+----------+|  count   |+----------+| 10000000 |+----------+(1 row)检查 strace 日志可以看见 pread64 函数每次的偏移量为 16384（block_size）在表的数量稍微大点的时候可以看见还涉及到了锁，进程调用了 futex 函数└──╼ $ grep futex /Postgres/stracelog/1391395_read.log1391395&lt;postgres&gt; 10:43:32.700008 (+     0.000115) futex(0x7fc443a3f138, FUTEX_WAIT_BITSET|FUTEX_CLOCK_REALTIME, 0, NULL, FUTEX_BITSET_MATCH_ANY) = -1 EAGAIN (Resource temporarily unavailable)1391395&lt;postgres&gt; 10:43:33.023435 (+     0.001178) futex(0x7fc443a3f738, FUTEX_WAKE, 1) = 11391395&lt;postgres&gt; 10:43:33.046237 (+     0.000124) futex(0x7fc443a3f138, FUTEX_WAIT_BITSET|FUTEX_CLOCK_REALTIME, 0, NULL, FUTEX_BITSET_MATCH_ANY) = -1 EAGAIN (Resource temporarily unavailable)1391395&lt;postgres&gt; 10:43:34.440591 (+     0.000147) futex(0x7fc443a3f738, FUTEX_WAKE, 1) = 1说明查询也会涉及锁，调用了 Linux 的 futex 函数，只是对应 postgresql 中锁的等级不同block_size 大小对查询的影响-- block_size = 8K127.0.0.1:54323; wxj@testdb &gt; select count(1) from pgbench_accounts;+----------+|  count   |+----------+| 10000000 |+----------+(1 row)Time: 13835.084 ms (00:13.835)-- block_size = 16K127.0.0.1:54324; postgres@testdb &gt; select count(1) from pgbench_accounts;+----------+|  count   |+----------+| 10000000 |+----------+(1 row)Time: 2130.195 ms (00:02.130)可以看见全表扫描大表的时候 block_size 取值 16K 的效率要比 8K 的时候高，因为扫描的 block 的数量少了如果需要长期全表查询或者大数据量时，可以考虑调大 block_size ，单个 blok 可以容纳更多的数据，这样在读取的时候也可以减少需要扫描的 block 的数量提高效率也不是一味的增大 block_size ，根据业务的数据类型调整Oracle 多块读为了有一个对比，这里贴一下 Oracle 的多块读情况SPID                            SID------------------------ ----------756                             191SQL&gt; select count(1) from t3;  COUNT(1)----------   2821792SQL&gt; show parameter db_block_sizeNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------db_block_size                        integer     8192可以看到在单个 block 大小为 8K 的时候，pread 函数的偏移量存在 16K、32K 的情况，说明 Oracle 在扫描数据库块的时候单次扫描 block 的数量可以超过一个总结PostgreSQL 目前还不支持多块读。可以使用 uniq 简单去重看看进程在执行时涉及那些函数/操作。┌─[postgres@darkstarc]─[~]└──╼ $ awk '{print $5}' /Postgres/stracelog/1391395_read.log | awk -F'(' '{print $1}' |  uniqepoll_waitrecvfromlseekopenatrt_sigprocmaskftruncatefallocatert_sigprocmaskmmapcloselseekkill---rt_sigreturnkill---rt_sigreturnkillpread64futexpread64pselect6futexpread64futexpread64futexpread64pselect6pread64epoll_waitreadepoll_wait---rt_sigreturnreadepoll_wait---rt_sigreturn---rt_sigreturnreadmunmapunlinksendtorecvfromepoll_wait参考fetux1fetux2block_size教你区分 多块读、单块读、散列读、顺序读、索引扫描OS / linux / 互斥锁实现原理（futex）"
  },
  
  {
    "title": "Linux 虚拟内存参数 min_free_kbytes",
    "url": "/posts/Linux-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%8F%82%E6%95%B0-min_free_kbytes/",
    "categories": "Linux, Memory",
    "tags": "virtual memory",
    "date": "2024-08-30 11:51:27 +0800",
    





    
    "snippet": "前言Linux 的虚拟内存参数列在 /proc/sys/vm 目录中，可以直接查看对应的文件。前几天调整了 Oracle SGA 大小，结果运行没多久就挂掉了，检查日志发生了 OOM，虽然使用率比较高，可是检查内存还有 2G 的空闲，最开始以为是设置了 操作系统用户的内存使用限制，可是也不应该是 OOM，不过还是设置为了 unlimit 。重启之后运行两个小时之后又宕机了。还是提示 OOM，...",
    "content": "前言Linux 的虚拟内存参数列在 /proc/sys/vm 目录中，可以直接查看对应的文件。前几天调整了 Oracle SGA 大小，结果运行没多久就挂掉了，检查日志发生了 OOM，虽然使用率比较高，可是检查内存还有 2G 的空闲，最开始以为是设置了 操作系统用户的内存使用限制，可是也不应该是 OOM，不过还是设置为了 unlimit 。重启之后运行两个小时之后又宕机了。还是提示 OOM，检查系统的内存参数配置，发现设置了 vm.min_free_kbytes 换算之有 5G 大小。客户环境也不是自己搭建的，不清楚为什么设置这么大，减少大小或则直接取消改参数的配置，采用系统默认大小之后恢复正常。可以设置一定大小，避免在业务运行时系统因为内存问题宕机，不过也不建议设置太大。┌─[wxj@TheDarkStar]─[~]└──╼ $ cat /proc/sys/vm/min_free_kbytes45056┌─[wxj@TheDarkStar]─[~]└──╼ $ ll /proc/sys/vmtotal 0-rw-r--r-- 1 root root 0 Aug 30 11:53 admin_reserve_kbytes--w------- 1 root root 0 Aug 30 11:53 compact_memory-rw-r--r-- 1 root root 0 Aug 30 11:53 compact_unevictable_allowed-rw-r--r-- 1 root root 0 Aug 30 11:53 compaction_proactiveness-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_background_bytes-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_background_ratio-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_bytes-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_expire_centisecs-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_ratio-rw-r--r-- 1 root root 0 Aug 30 11:53 dirty_writeback_centisecs-rw-r--r-- 1 root root 0 Aug 30 11:53 dirtytime_expire_seconds--w------- 1 root root 0 Aug 30 11:53 drop_caches-rw-r--r-- 1 root root 0 Aug 30 11:53 extfrag_threshold-rw-r--r-- 1 root root 0 Aug 30 11:53 hugetlb_optimize_vmemmap-rw-r--r-- 1 root root 0 Aug 30 11:53 hugetlb_shm_group-rw-r--r-- 1 root root 0 Aug 30 11:53 laptop_mode-rw-r--r-- 1 root root 0 Aug 30 11:53 legacy_va_layout-rw-r--r-- 1 root root 0 Aug 30 11:53 lowmem_reserve_ratio设置 min_free_kbytes这用于强制 Linux VM 保持最少的可用的 kilobytes 。 VM 使用此数字来计算系统中每个 lowmem 区域的  watermark[WMARK_MIN] 的值。每个 lowmem zone 根据其大小按比例获得一定数量的保留空闲页面。需要一些最小量的内存来满足 PF_MEMALLOC 分配；如果设置为低于 1024KB ，在高负载下容易出现死锁。设置得太高会导致机器 OOM。设置保留可用页面池的大小。它还负责设置管理 Linux 内核页面回收算法行为的 min_page、low_page 和 high_page 阈值。它还指定在系统间保留的最小 KB 数。这会为每个低内存区计算一个特定值，每个值都会被分配一个保留的空闲页面的大小。  增加参数值可有效减少应用程序工作集可用内存。因此，可能希望将其仅用于内核驱动的工作负载，其中驱动程序缓冲区需要在原子上下文中分配。  减少参数值可能会导致内核无法服务系统请求，如果内存在系统中发生大量处理。vm.min_free_kbytes 参数还设置页面重新声明水位线，名为 min_pages。在确定两个其他内存水位线、low_pages 和 high_pages 时，这个水位线被用作一个因素，它管理页面重新声明算法。总结极端的值可能会降低系统性能。将 vm.min_free_kbytes 设置为非常低的值可防止系统有效地回收内存，这可能会导致系统崩溃并失败服务中断或其他内核服务。但是，设置 vm.min_free_kbytes 太大地增加系统回收活动，从而导致分配延迟因为假的直接重新声明状态而造成分配延迟。这可能导致系统立即进入内存不足状态。后续发现这篇文章写的挺详细的还有实验"
  },
  
  {
    "title": "PostgreSQL 常用函数（持续更新）",
    "url": "/posts/PostgreSQL-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-08-28 15:29:36 +0800",
    





    
    "snippet": "前言记录一些 PostgreSQL 的常用函数字符串字符串/字段拼接string_aggstring_agg：用于拼接字段，需要两个参数，第一个是需要进行拼接的字段名，第二个是用于拼接字符的拼接符号select string_agg(a,', ') from tab1;如果字段不是字符类型，例如字段是数字类型，需要先转换为字符才能进行拼接，否则会报错|| ：和 Oracle 一样，可以用于拼...",
    "content": "前言记录一些 PostgreSQL 的常用函数字符串字符串/字段拼接string_aggstring_agg：用于拼接字段，需要两个参数，第一个是需要进行拼接的字段名，第二个是用于拼接字符的拼接符号select string_agg(a,', ') from tab1;如果字段不是字符类型，例如字段是数字类型，需要先转换为字符才能进行拼接，否则会报错|| ：和 Oracle 一样，可以用于拼接字符或者字段，如果是不是拼接的字段，字符串需要在两个单引号内select a || ',' || b from tab1 ;select 'a' || ',' || 'b' ;类型转换https://www.postgresql.org/docs/current/sql-createcast.html可以使用 cast 函数或者双冒号 ::，在PG 的SQL中，会经常看到 “::” 的语法， “::” 符号其实是一个显示的类型转换符，作用等同于 CAST。select a::text from tab1;select 1::text;select cast(a as text) from tab1;select cast(1 as text);文件信息pg_relation_filepath() 根据OID或名称返回关系对应的文件路径select pg_relation_filepath('tab1');select schemaname, tablename, pg_relation_filepath(tablename::text) from pg_tables where schemaname = '&amp;schemaname';一般情况下对象的 oid 和 relfilenode 是相同的，但是表和索引的relfilenode值会被一些命令（例如TRUNCATE，REINDEX，CLUSTER）所改变。 例如对表  sampletbl 执行 TRUNCATE ， PostgreSQL 会为表分配一个新的 relfilenode 。127.0.0.1:54323; wxj@db1 &gt; select pg_relation_filepath('tab1');+----------------------+| pg_relation_filepath |+----------------------+| base/16389/16544     |+----------------------+127.0.0.1:54323; wxj@db1 &gt; alter table tab1 rename to t1;ALTER TABLETime: 16.013 ms127.0.0.1:54323; wxj@db1 &gt; select pg_relation_filepath('t1');+----------------------+| pg_relation_filepath |+----------------------+| base/16389/16544     |+----------------------+(1 row)Time: 0.968 ms127.0.0.1:54323; wxj@db1 &gt; create table tab1 as select * from t1;SELECT 6Time: 5.227 ms127.0.0.1:54323; wxj@db1 &gt; select pg_relation_filepath('tab1');+----------------------+| pg_relation_filepath |+----------------------+| base/16389/16547     |+----------------------+(1 row)127.0.0.1:54323; wxj@db1 &gt; select oid, relname, relfilenode from pg_class where relname in ('t1','tab1');+-------+---------+-------------+|  oid  | relname | relfilenode |+-------+---------+-------------+| 16544 | t1      |       16544 || 16547 | tab1    |       16547 |+-------+---------+-------------+(2 rows)127.0.0.1:54323; wxj@db1 &gt; TRUNCATE TABLE  t1;TRUNCATE TABLETime: 4.922 ms127.0.0.1:54323; wxj@db1 &gt; select oid, relname, relfilenode from pg_class where relname in ('t1','tab1');+-------+---------+-------------+|  oid  | relname | relfilenode |+-------+---------+-------------+| 16547 | tab1    |       16547 || 16544 | t1      |       16550 |+-------+---------+-------------+(2 rows)rename table/database 对表或者 db 进行重命名操作都不会变更 relfilenode127.0.0.1:54323; wxj@demo &gt; select schemaname, tablename, pg_relation_filepath(tablename::text) from pg_tables where schemaname = 'bookings';+------------+-----------------+----------------------+| schemaname |    tablename    | pg_relation_filepath |+------------+-----------------+----------------------+| bookings   | ticket_flights  | base/16417/16467     || bookings   | boarding_passes | base/16417/16440     || bookings   | aircrafts_data  | base/16417/16421     || bookings   | flights         | base/16417/16446     || bookings   | airports_data   | base/16417/16431     || bookings   | seats           | base/16417/16463     || bookings   | tickets         | base/16417/16472     || bookings   | bookings        | base/16417/16443     |+------------+-----------------+----------------------+127.0.0.1:54323; wxj@demo &gt; alter database demo rename to demo01;ERROR:  current database cannot be renamedTime: 1.187 ms127.0.0.1:54323; wxj@demo &gt; \\c testdbYou are now connected to database \"testdb\" as user \"wxj\".127.0.0.1:54323; wxj@testdb &gt; alter database demo rename to demo01;ALTER DATABASETime: 2.038 ms127.0.0.1:54323; wxj@testdb &gt; select schemaname, tablename, pg_relation_filepath(tablename::text) from pg_tables where schemaname = 'bookings';+------------+-----------+----------------------+| schemaname | tablename | pg_relation_filepath |+------------+-----------+----------------------++------------+-----------+----------------------+(0 rows)Time: 75.493 ms127.0.0.1:54323; wxj@testdb &gt; \\c demo01You are now connected to database \"demo01\" as user \"wxj\".127.0.0.1:54323; wxj@demo01 &gt; select schemaname, tablename, pg_relation_filepath(tablename::text) from pg_tables where schemaname = 'bookings';+------------+-----------------+----------------------+| schemaname |    tablename    | pg_relation_filepath |+------------+-----------------+----------------------+| bookings   | ticket_flights  | base/16417/16467     || bookings   | boarding_passes | base/16417/16440     || bookings   | aircrafts_data  | base/16417/16421     || bookings   | flights         | base/16417/16446     || bookings   | airports_data   | base/16417/16431     || bookings   | seats           | base/16417/16463     || bookings   | tickets         | base/16417/16472     || bookings   | bookings        | base/16417/16443     |+------------+-----------------+----------------------+(8 rows)Time: 7.055 ms"
  },
  
  {
    "title": "podman 修改仓库源",
    "url": "/posts/podman-%E4%BF%AE%E6%94%B9%E4%BB%93%E5%BA%93%E6%BA%90/",
    "categories": "containers, podman",
    "tags": "podman",
    "date": "2024-08-28 11:21:43 +0800",
    





    
    "snippet": "前言Podman 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用（Windows 下也可以运行，不过个人还没测试）。Podman 提供与 Docker 非常相似的功能。它不需要在你的系统上运行任何守护进程，并且它也可以在没有 root 权限的情况下运行。Podman 可以管理和运行任何符合 OCI（Open Container Initiative）规范的容器和容器镜像。Po...",
    "content": "前言Podman 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用（Windows 下也可以运行，不过个人还没测试）。Podman 提供与 Docker 非常相似的功能。它不需要在你的系统上运行任何守护进程，并且它也可以在没有 root 权限的情况下运行。Podman 可以管理和运行任何符合 OCI（Open Container Initiative）规范的容器和容器镜像。Podman 提供了一个与 Docker 兼容的命令行前端来管理 Docker 镜像。虽然目前容器化部署基本都采用 docker ，但是随着 RedHat 系列的 Linux 升级到 8 之后基本就采用 podman 作为自身的容器化产品之后，已经不能通过软件仓库安装 docker 了，虽然可以通过一些方法安装 docker ，但是个人还是比较喜欢使用 RedHat 系列，所以也就尝试使用 podman            Podman      Docker                  是无守护进程的      Docker 有一个守护进程 (containerd)。docker CLI 与守护进程交互以管理容器。              直接通过 runc 与 Linux 内核交互      守护进程拥有所有运行容器的子进程              可以部署具有多个容器的 pod。可以在 Kubernetes 中使用相同的 pod 清单。此外，可以将 K8s pod 清单部署为 Podman pod。      Docker 中没有 pod 的概念              无需任何额外配置即可运行无根容器( rootless)。可以使用 root 或非特权用户运行容器。      Docker 无根模式( rootless)需要额外的配置。      修改镜像源Podman 可以直接通过软件源安装，使用命令大部分也和 docker 一样，这里就不再赘述。Podman 有两种配置文件：  全局配置文件：/etc/containers/registries.conf  用户配置文件：~/.config/containers/registries.conf可以直接修改全局配置文件，也可以在不同的用户下配置不同的参数，可能当前用户没有 containers 路径，可以新建配置文件之后修改以修改全局配置文件为例：sudo cp /etc/containers/registries.conf /etc/containers/registries.conf.baksudo vim /etc/containers/registries.confunqualified-search-registries = [\"docker.io\"][[registry]]prefix = \"docker.io\"location = \"hub-mirror.c.163.com\"insecure = true[[registry.mirror]]# 百度镜像源location = \"mirror.baidubce.com\"insecure = true[[registry.mirror]]# 网易 163 镜像源location = \"hub-mirror.c.163.com\"insecure = true[[registry.mirror]]# 上海交大镜像源location = \"docker.mirrors.sjtug.sjtu.edu.cn\"insecure = true[[registry.mirror]]# 南京大学镜像源location = \"docker.nju.edu.cn\"insecure = true以上镜像源地址随着国内禁止访问 dockerhub 之后可能无法访问，需要自行搭建镜像源或者搜索其他人搭建的镜像源地址😂  prefix 是 pull 的时候指定的镜像前缀，如果不指定 prefix 则默认和 location 一致。  location 是获取镜像的地址；  insecure=true 表示允许通过 HTTP 协议来获取镜像，对于私有化部署/内网测试环境下无 https 证书的环境来说很有帮助。查看是否生效podman infoPodman 常用命令podman run         #创建并启动容器podman start       #启动容器podman ps          #查看容器podman stop        #终止容器podman restart     #重启容器podman attach      #进入容器podman exec        #进入容器podman export      #导出容器podman import      #导入容器快照podman rm          #删除容器podman logs        #查看日志podman search      #检索镜像podman pull         #获取镜像podman images      #列出镜像podman image Is    #列出镜像podman rmi         #删除镜像podman image rm    #删除镜像podman save        #导出镜像podman load        #导入镜像还能使用的镜像源unqualified-search-registries = [\"docker.io\"][[registry]]prefix = \"docker.io\"location = \"hub-mirror.c.163.com\"insecure = true[[registry.mirror]]location = \"hub.uuuadc.top\"insecure = true[[registry.mirror]]location = \"docker.anyhub.us.kg\"insecure = true[[registry.mirror]]location = \"dockerhub.jobcher.com\"insecure = true[[registry.mirror]]location = \"dockerhub.icu\"insecure = true[[registry.mirror]]location = \"docker.ckyl.me\"insecure = true[[registry.mirror]]location = \"docker.awsl9527.cn\"insecure = true总结虽然 podman 目前看起来是 RedHat 未来主推的容器产品，但是使用 docker 的用户更多，很多业务并不一定会迁移到 podman 。而且大部分容器都是根据 docker 构建的，即使 podman 描述说可以直接使用 docker 的绝大部分命令，不过有的在 docker 上正常运行的容器在 podman 上并不能正常使用，有可能在 pull 阶段就报错了。有些则是在启动阶段出现一些奇怪的错误，这些都是在使用 podman 时会遇到的问题。如果使用 Redhat 系列的 Linux ，可以尝试使用 podman"
  },
  
  {
    "title": "PostgreSQL 配置密码验证策略",
    "url": "/posts/PostgreSQL-%E9%85%8D%E7%BD%AE%E5%AF%86%E7%A0%81%E9%AA%8C%E8%AF%81%E7%AD%96%E7%95%A5/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-08-27 13:55:20 +0800",
    





    
    "snippet": "概述数据库等保的时候会遇到一些安全加固操作，其中 PostgreSQL 数据库设置密码验证失败延迟时间可以通过安装 auth_delay 扩展插件来实现，该设置主要是防止暴力破解，在验证失败后, 会延迟一段时间后，才能继续验证。可以搭配 passwordcheck 限制简单密码。一般来说 ‘passwordcheck、auth_delay’ 两个插件就在源码路径中的 contrid 目录下。...",
    "content": "概述数据库等保的时候会遇到一些安全加固操作，其中 PostgreSQL 数据库设置密码验证失败延迟时间可以通过安装 auth_delay 扩展插件来实现，该设置主要是防止暴力破解，在验证失败后, 会延迟一段时间后，才能继续验证。可以搭配 passwordcheck 限制简单密码。一般来说 ‘passwordcheck、auth_delay’ 两个插件就在源码路径中的 contrid 目录下。源码编译安装 PostgreSQL 可以参考我之前写的脚本一键安装。编译安装插件下载相同版本的源码解压之后进入目录，在安装插件之前请先编译源码，然后进入插件的路径进行安装插件，如果在编译时新建的编译目录，例如 build ，需要进入 ‘build/contrib’ 路径下：cd /software/postgresql-15.4/contrib/# 安装命令make &amp;&amp; make install在 contrib 目录下执行会编译安装路径下的所有插件，如果只想要单独安装需要的插件，可以进入对应的目录：cd /software/postgresql-15.4/contrib/auth_delay/make &amp;&amp; make installcd /software/postgresql-15.4/contrib/passwordcheck/make &amp;&amp; make install配置参数文件如果在编译的时候指定的安装路径正确或者安装数据库软件时采用的时默认路径那么在编译安装插件的时候会自动安装至正确的路径，如果路径有问题，请复制编译好的 ‘auth_delay.so、passwordcheck.so’ 文件到，pg_config | grep -E 'LIBDIR|PKGLIBDIR' 任意一个路径，然后配置 ${PGDATA?}/postgresql.conf 文件，如果没有配置变量 ‘${PGDATA}’ ，可以使用 ps -ef | grep -i postgre 查看数据库的配置文件路径，也可以使用 psql -c 'show config_file;' 获取配置文件路径。打开 ${PGDATA?}/postgresql.conf 文件，修改 shared_preload_libraries 参数以包含 auth_delay ，同时增加 auth_delay.milliseconds 参数，设置延迟时间，单位为毫秒，取值 5000 代表 5 秒，若文件中没有该参数，添加即可。修改后，需要重启数据库才能生效，所以配置之前要和业务部门确认，避免后期扯皮。需要注意： auth_delay 认证失败之前等待的毫秒数，缺省是0。以下示例修改表示在一次认证失败后，将延迟5秒中才能继续下一次认证。该选项可以增加暴力破解数据库服务器的密码难度，但它并不能防止拒绝服务攻击，甚至可能恶化它们，因为报告验证失败之前等待的过程将损耗连接槽位。# Add settings for extensions hereshared_preload_libraries = 'passwordcheck,auth_delay'auth_delay.milliseconds = '5000'重启实例：pg_ctl restart如果启动没报错，则表示正确加载模块两个扩展都是 contrib 自带的扩展，不需要手动执行 CREATE EXTENSION ，否则会提示以下信息：postgres=# CREATE EXTENSION auth_delay;ERROR:  could not open extension control file \"/Postgres/pg/share/postgresql/extension/auth_delay.control\": No such file or directory验证postgres=# show auth_delay.milliseconds; auth_delay.milliseconds------------------------- 5s(1 row)新建用户验证 passwordcheck ：可以修改 auth_delay.milliseconds 的值，结合 time 命令验证密码错误时的等待时间：总结除了需要在 postgresql.conf 配置文件中装载 auth_delay 模块，还需要增加 auth_delay.milliseconds 配置参数，否则 auth_delay 扩展模块的功能无法体现。passwordcheck 模块对新创建的用户密码进行检测，已存在的用户不生效。两个插件模块都是 contrib 自带的模块，不需要执行 CREATE EXTENSION"
  },
  
  {
    "title": "vim 匹配指定行号的内容",
    "url": "/posts/vim-%E5%8C%B9%E9%85%8D%E6%8C%87%E5%AE%9A%E8%A1%8C%E5%8F%B7%E7%9A%84%E5%86%85%E5%AE%B9/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-27 10:39:27 +0800",
    





    
    "snippet": "有的时候明确知道需要保留那些行，虽然可以采用匹配每行的字符，但是可能需要保留的行的内容在其他行中也存在，这个时候可以利用 vim/nvim 的 \\% 特殊字符匹配指定的行内容。再结合 :g 、:g!、 :v 来选择/反选指定的行/列内容可以高效的过滤行            符号      含义      备注                  \\%      用于匹配行号或列号      ...",
    "content": "有的时候明确知道需要保留那些行，虽然可以采用匹配每行的字符，但是可能需要保留的行的内容在其他行中也存在，这个时候可以利用 vim/nvim 的 \\% 特殊字符匹配指定的行内容。再结合 :g 、:g!、 :v 来选择/反选指定的行/列内容可以高效的过滤行            符号      含义      备注                  \\%      用于匹配行号或列号                     \\%^      匹配文件开始的位置                     \\%Nl      匹配指定的[n]行，l 表示行号，line                     \\%'m      匹配指定的 m 标记                     \\%&gt;'m      匹配在 m 标记之后的内容      可以使用&lt;、&gt;、'              \\%.l      匹配光标所在的行                     \\%&gt;.23l      匹配光标所在行下方的内容                     \\%Nc      匹配指定的列 ‘column’      &lt;23c、&gt;23c、.c、&lt;.c、&gt;.c              \\%23v      匹配指定的虚拟列             匹配指定的行号### 匹配删除第二行:g/\\%2l/d匹配删除除第二行之外的所有行:g!/\\%2l/d:v/\\%2l/d匹配多行:g/\\%2l\\|\\%4l/d可以匹配删除第二行和第四行的内容匹配连续的多行:g/\\%2l,\\%4l/d以上写法并不能直接匹配第二行到第四行的内容，需要曲线实现:g/\\%&lt;2l\\|\\%&gt;4l/d匹配大于或者小于指定行的内容，例如以上通过匹配小于第二行或者大于第四行的内容，相当于匹配第二行到第四行的内容，以此实现匹配连续的行🤣🤣🤣"
  },
  
  {
    "title": "sed 检查 Oracle日志 并输出对应的行号",
    "url": "/posts/sed-%E6%A3%80%E6%9F%A5-Oracle%E6%97%A5%E5%BF%97-%E5%B9%B6%E8%BE%93%E5%87%BA%E5%AF%B9%E5%BA%94%E7%9A%84%E8%A1%8C%E5%8F%B7/",
    "categories": "Linux, sed",
    "tags": "Oracle",
    "date": "2024-08-26 16:45:20 +0800",
    





    
    "snippet": "在护网的时候可能需要定期检查日志文件，特别是日志文件中的错误信息，在 alert 日志中常见的报错一般都是 Error、ORA-、TNS- 为前缀的信息。我们可以利用 sed 工具检索日志文件中的信息，减少重复工作。可以利用一下语句过滤错误信息：## 一般来说 alert 日志的路径为## ${ORACLE_BASE}/diag/rdbms/${ORACLE_SID}/${ORACLE_SI...",
    "content": "在护网的时候可能需要定期检查日志文件，特别是日志文件中的错误信息，在 alert 日志中常见的报错一般都是 Error、ORA-、TNS- 为前缀的信息。我们可以利用 sed 工具检索日志文件中的信息，减少重复工作。可以利用一下语句过滤错误信息：## 一般来说 alert 日志的路径为## ${ORACLE_BASE}/diag/rdbms/${ORACLE_SID}/${ORACLE_SID}/tracle/alert_${ORACLE_SID}.log## 因为安装的原因，rdbms 下之后路径可能为大小或者小写的 ${ORACLE_SID} ，具体可以进入 rdbms 路径之后选择## diag 的路径也可以进入实例之后使用 `show parameter diag` 查看sed -n  '/Mon Aug 26 08/,/Mon Aug 26 09/p' alert_xxxx.log  | grep -E '^Error|^ORA-|^TNS-'Mon Aug 26 08 是路径的日志格式，不同的实例环境格式不同，需要根据实际情况替换Error 1034 received logging on to the standbyError 1034 received logging on to the standbyError 1034 received logging on to the standbyError 1034 received logging on to the standbyError 1034 received logging on to the standby以上信息的的输出可以基本过滤日志的错误信息，要是有行数就更好了，使用 vim/nvim 打开文件的时候可以直接定位到具体的行，检查报错的详细信息。可以利用 sed = filename 实现输出行号。sed -n  -e '/Mon Aug 26 08/,/Mon Aug 26 09/p' -e '/Mon Aug 26 08/,/Mon Aug 26 09/=' alert_XXX.logsed -n  -e '/Mon Aug 26 08/,/Mon Aug 26 09/p' -e '/Mon Aug 26 08/,/Mon Aug 26 09/=' alert_XXX.log  | grep -A1 -E '^Error|^ORA-|^TNS-'## 也可以简化sed -n '/Mon Aug 26 08/,/Mon Aug 26 09/{=;p}'  alert_XXX.log  | grep -A1 -E '^Error|^ORA-|^TNS-'输出如下：Mon Aug 26 08:55:30 20243198275Error 1034 received logging on to the standby3198276Mon Aug 26 08:56:30 20243198277因为行号和内容不在同一行，导致 grep 会直接将行号过滤掉。我们可以优化一下命令，将行号和内容显示在同一行。建议将行号放置在行末，因为错误信息一般会在行首展示关键字，方便查看。利用 xargs 每次传输三个参数，默认一般使用空格分割，但是我们这里的内容是以行为单位的，所以需要使用 --delimiter 选项来指定分割符了。以三行为一个处理单元，通过 sed 将处理单元的合并为一行就可以实现日志内容和对应的行号在同一行了，方便定位日志中的具体信息。优化后的命令如下：sed -n  -e '/Mon Aug 26 08/,/Mon Aug 26 09/{p;=}' alert_DWHPROD.log  | grep -A1 -E '^Error|^ORA-|^TNS-' | xargs -n 3 --delimiter='\\n' | sed 's/\\n/ /g'以上处理后的内容基本已经可以定位内容了，如果想格式化或者美观，可以进一步使用 awk、cut、table 处理，这里就不再展示了。"
  },
  
  {
    "title": "vim 特殊字符记录(持续更新)",
    "url": "/posts/vim-%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E8%AE%B0%E5%BD%95(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0)/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-22 16:23:44 +0800",
    





    
    "snippet": "记录一些 vim/nvim 的特殊字符含义，持续更新。正则表达式中的特殊字符这类符号的完整列表可参考文档 :help ordinary-atom            符号      含义      备注                  .      任意字符，但是不包括行尾                     ^      行首                     $      ...",
    "content": "记录一些 vim/nvim 的特殊字符含义，持续更新。正则表达式中的特殊字符这类符号的完整列表可参考文档 :help ordinary-atom            符号      含义      备注                  .      任意字符，但是不包括行尾                     ^      行首                     $      行尾                     \\_      任意字符，包括行尾                     \\&lt;      单词开始      精准匹配单词，例如 a 和 am ， \\&lt;a\\&gt; 就仅匹配单词 a              \\&gt;      单词结尾      同 \\&lt;      还有一类正则表达式称为字符类（character class）：            符号      含义      备注                  \\s      一个空白字符（包括Tab和Space）                     \\d      一个数字                     \\w      一个单词字符（包括数字、字母、下划线）                     \\l      一个小写字符                     \\u      一个大写字符                     \\a      一个字符              这些字符类的大写版本表示它们的相反类，比如 `\\D` 匹配所有非数字的字符，而 `\\L` 匹配除小写字母外的所有字符（注意，不仅仅是大写字符）。 字符类的完整列表可参考文档 :help character-classes也可以显式地指定一个字符集合，供匹配时选择，语法是使用一对方括号 []。比如，[A-Z0-9] 匹配所有的大写字母和数字，而 [,4abc] 只会匹配逗号、数字 4 和字母 a、b、c在字符集合中，可以用短横线 - 来指定一个范围，这适用于构成序列的那些符号（如数字或字母表）。比如 [0-7] 表示 0～7 的数字，而 [a-z] 表示  a～z 的所有小写字母[0-9A-Za-z_] 匹配字母、数字和下划线如果取一个字符集合的差集，只需要在字符集合的前面加上脱字符 ^ 即可。如果要匹配所有非字符数字的符号，则可以使用字符集合 [^0-9A-Za-z]匹配文件行列 :help \\%有的时候可以结合 :g 、:g!、 :v 来选择/反选指定的行/列内容            符号      含义      备注                  \\%      用于匹配行号或列号                     \\%^      匹配文件开始的位置                     \\%Nl      匹配指定的[n]行，l 表示行号，line                     \\%'m      匹配指定的 m 标记                     \\%&gt;'m      匹配在 m 标记之后的内容      可以使用&lt;、&gt;、'              \\%.l      匹配光标所在的行                     \\%&gt;.23l      匹配光标所在行下方的内容                     \\%Nc      匹配指定的列 ‘column’      &lt;23c、&gt;23c、.c、&lt;.c、&gt;.c              \\%23v      匹配指定的虚拟列             交替和分组（alternation、grouping）交替(alternation)操作起到的是“或”的作用，比如，carrot\\|parrot  同时匹配 carrot和parrot分组（grouping）用于将多个字符放在一个组里，这样做有两个好处。首先，分组可以与其他正则表达式组合使用，比如 \\(c\\|p\\)arrot  是一种同时匹配 carrot 和 parrot 的更精准的方式。有的时候用于交换（替换）两个字符的位置十分有用            符号      说明              \\|      alternation              \\(\\)      grouping      量词和重复次数（quantifier、multi）每个字符（无论是字面字符，还是特殊字符）或字符区间后面都可以接一个量词（quantifier），在 Vim 中称为重数（multi）比如，\\w\\+ 匹配一个或多个单词字符，而 a\\{2,4} 匹配 2～4 个连续的字符 a（如 aaa）            符号      含义      备注                  *      0或者多个，贪婪匹配模式                     \\+      1或者多个，贪婪匹配模式                     \\{-}      0或者多个，非贪婪匹配模式                     \\?      0或者1个，贪婪匹配模式                     \\=      0或者1个，贪婪匹配模式                     \\{n,m}      n~m个，贪婪匹配模式                     \\{-n,m}      n~m个，非贪婪匹配模式             魔法（magic）当需要编写较长的正则表达式时，特别是涉及到字符串中含有很多特殊字符，如果对每一个特殊字符都转义是比较繁琐且容易出错的事情，特别是容易漏掉或者手快多敲了转义符，这时候就需要用到 Vim 的魔法模式了可以使用 :help /magic  查看不同版本对于 magic 的处理方式。Vim 的魔法模式用于确定如何解析正则表达式字符串（如搜索和替换命令）。Vim 有 3 种魔法模式：基本魔法（magic）、无魔法（nomagic）和深度魔法(very magic)1．基本魔法（magic）这是默认的模式，大部分特殊字符都需要转义，少数例外（如 . 和 * ）。读者可以显式设置基本魔法模式，在正则表达式字符串前面加上 \\m 即可，比如 /\\mfoo 或 :s/\\mfoo/bar2．无魔法（no magic）无魔法模式类似于基本魔法模式，只不过每一个特殊字符都需要用反斜划线 \\ 转义，包括 . 和 * 等字符。比如，在默认的基本魔法模式下，搜索包含任意文本的行的命令为 /^.*$ ，这里的 ^ 表示行首，.* 表示 0 个或多个任意字符，而 $ 表示行尾。而在无魔法模式中，这个命令则写为 /\\^\\.\\*\\$读者可以显式地设置无魔法模式，在正则表达式前加上 \\M 即可，比如 /\\Mfoo 或 :s/\\Mfoo/bar 。无魔法模式可以在 .vimrc 中设置，命令为 set nomagic ，但不建议这样做，因为修改 Vim 处理正则表达式的方式将很可能影响读者正在使用的很多插件（因为这些插件的作者可能并没有考虑无魔法模式）。3．深度魔法（very magic）深度魔法模式将数字、字母和下划线之外的字符都视为特殊字符。使用深度魔法的方式是在正则表达式字符串之前添加 \\v ，比如 /\\vfoo 或 :s/\\vfoo/bar深度魔法模式的使用场合是特殊字符比较多的时候。比如，在基本魔法模式下，使用如下命令将 cat hunting mice 替换成 mice hunting cat:s/\\(cat\\) hunging \\(mice\\)/\\2 hunting \\1而在深度魔法模式下，这条命令可写成下列形式。:s/\\v(cat) hunging (mice)/\\2 hunting \\1需要注意的是 very magic 模式有两种设置 \\v 和 \\V“very magic” ：使用 \\v 意味着在它之后，除了 0-9 、a-z 之外的所有 ASCII 字符，A-Z 和 _ 有特殊的含义“very nomagic” ：使用 \\V 意味着在它之后，只有反斜杠和终止符字符（通常是 / 或 ? ）具有特殊含义Some characters in the pattern, such as letters, are taken literally.  Theymatch exactly the same character in the text.  When preceded with a backslashhowever, these characters may get a special meaning.  For example, \"a\" matchesthe letter \"a\", while \"\\a\" matches any alphabetic character.﻿Other characters have a special meaning without a backslash.  They need to bepreceded with a backslash to match literally.  For example \".\" matches anycharacter while \"\\.\" matches a dot.﻿If a character is taken literally or not depends on the 'magic' option and theitems in the pattern mentioned next.  The 'magic' option should always be set,but it can be switched off for Vi compatibility.  We mention the effect of'nomagic' here for completeness, but we recommend against using that.*/\\m* */\\M*Use of \"\\m\" makes the pattern after it be interpreted as if 'magic' is set,ignoring the actual value of the 'magic' option.Use of \"\\M\" makes the pattern after it be interpreted as if 'nomagic' is used.*/\\v* */\\V*Use of \"\\v\" means that after it, all ASCII characters except '0'-'9', 'a'-'z','A'-'Z' and '_' have special meaning: \"very magic\"﻿Use of \"\\V\" means that after it, only a backslash and the terminatingcharacter (usually / or ?) have special meaning: \"very nomagic\"Examples:after:\t  \\v\t   \\m\t    \\M\t     \\V\t\tmatches ~\t\t'magic' 'nomagic'\t  a\t   a\t    a\t     a\t\tliteral 'a'\t  \\a\t   \\a\t    \\a\t     \\a\t\tany alphabetic character\t  .\t   .\t    \\.\t     \\.\t\tany character\t  \\.\t   \\.\t    .\t     .\t\tliteral dot\t  $\t   $\t    $\t     \\$\t\tend-of-line\t  *\t   *\t    \\*\t     \\*\t\tany number of the previous atom\t  ~\t   ~\t    \\~\t     \\~\t\tlatest substitute string\t  ()\t   \\(\\)     \\(\\)     \\(\\)\tgroup as an atom\t  |\t   \\|\t    \\|\t     \\|\t\tnothing: separates alternatives\t  \\\\\t   \\\\\t    \\\\\t     \\\\\t\tliteral backslash\t  \\{\t   {\t    {\t     {\t\tliteral curly brace"
  },
  
  {
    "title": "vim 分组和交替(grouping and alternation)",
    "url": "/posts/vim-%E5%88%86%E7%BB%84%E5%92%8C%E4%BA%A4%E6%9B%BF(grouping-and-alternation)/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-22 15:25:31 +0800",
    





    
    "snippet": "交替(alternation)操作起到的是“或”的作用，比如，carrot\\|parrot  同时匹配 carrot和parrot分组（grouping）用于将多个字符放在一个组里，这样做有两个好处。首先，分组可以与其他正则表达式组合使用，比如 \\(c\\|p\\)arrot  是一种同时匹配 carrot 和 parrot 的更精准的方式。有的时候用于交换（替换）两个字符的位置十分有用    ...",
    "content": "交替(alternation)操作起到的是“或”的作用，比如，carrot\\|parrot  同时匹配 carrot和parrot分组（grouping）用于将多个字符放在一个组里，这样做有两个好处。首先，分组可以与其他正则表达式组合使用，比如 \\(c\\|p\\)arrot  是一种同时匹配 carrot 和 parrot 的更精准的方式。有的时候用于交换（替换）两个字符的位置十分有用            符号      说明              \\|      alternation              \\(\\)      grouping      假设存在一下内容：cat test.txttable \"t1\"table \"t2\"table \"t3\"table \"t4\"table \"t5\"table \"t6\"t33atable \"ttt\"我们想要将文本 table \"t1-t6\"  全部替换为 table \"ttt\" ，这个时候就可以使用 vim/nvim 的分组来快速实现替换：:%s/\\v(table) (\\\".*\\\")/\\1 \\\"ttt\\\"/g每一个圆括号’()’表示一个分组，会将匹配的内容赋值给寄存器’\\1’， \\1 表示使用寄存器 ‘\\1’ 中的内容，依此类推。这样我们就可以快速实现全文的替换。如果我们想交换指定内容的位置，也可以利用 vim/nvim 的 grouping 功能：我们利用上文替换之后文本继续演示：:%s/\\v(table) (\\\"ttt\\\")/\\2 \\1/g如果利用好 vim/nvim 的 grouping 和 alternation 功能可以快速操作文本，节约时间。"
  },
  
  {
    "title": "vim 排序去重",
    "url": "/posts/vim-%E6%8E%92%E5%BA%8F%E5%8E%BB%E9%87%8D/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-22 14:18:52 +0800",
    





    
    "snippet": "在 Linux 中处理文本除了利用 sed、awk、sort、uniq 等工具对文件排序去重，还可以直接使用 vim/nvim 自带的 sort 命令对文件排序去重。虽然功能可能不如外部工具，但是处理一些基本逻辑是没问题的，重要的是可以在此基础上直接处理过滤之后的内容。:%sort:%sort：对整个文件的所有行进行排序,对所有行进行排序，排序后相同的行将会相邻。:%sort u:%sort...",
    "content": "在 Linux 中处理文本除了利用 sed、awk、sort、uniq 等工具对文件排序去重，还可以直接使用 vim/nvim 自带的 sort 命令对文件排序去重。虽然功能可能不如外部工具，但是处理一些基本逻辑是没问题的，重要的是可以在此基础上直接处理过滤之后的内容。:%sort:%sort：对整个文件的所有行进行排序,对所有行进行排序，排序后相同的行将会相邻。:%sort u:%sort u：对整个文件进行排序并去重，u 参数表示 unique，即只保留唯一行更多的用户可以参考 :help sort"
  },
  
  {
    "title": "vim 搜索过滤满足条件的行",
    "url": "/posts/vim-%E6%90%9C%E7%B4%A2%E8%BF%87%E6%BB%A4%E6%BB%A1%E8%B6%B3%E6%9D%A1%E4%BB%B6%E7%9A%84%E8%A1%8C/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-22 12:28:53 +0800",
    





    
    "snippet": "有的时候文本内容太多，我们只需要查看满足条件的内容，虽然可以通过 CTRL-g 、n、N 等快速跳转，但是我们可能只需要查看满足条件的内容，例如在排查错误日志的时候，我们只需要查看满足 err1 的错误信息，但是日志中有太多额外的内容，这个时候可以通过 sed 、awk 、grep 等文本工具过滤处理。但是使用 vim/nvim 也可以实现，而且更加方便查看。可以使用以下几种方法来搜索关键字...",
    "content": "有的时候文本内容太多，我们只需要查看满足条件的内容，虽然可以通过 CTRL-g 、n、N 等快速跳转，但是我们可能只需要查看满足条件的内容，例如在排查错误日志的时候，我们只需要查看满足 err1 的错误信息，但是日志中有太多额外的内容，这个时候可以通过 sed 、awk 、grep 等文本工具过滤处理。但是使用 vim/nvim 也可以实现，而且更加方便查看。可以使用以下几种方法来搜索关键字并将满足条件的行重定向到另一个文件，或者只显示满足条件的行。假设我想要搜索关键字“aaa”.使用 :vimgrep 和 :cw 仅显示满足条件的行可以使用 :vimgrep 命令来搜索关键字并将结果显示在快速修复列表中：:vimgrep /aaa/ %  :vimgrep：搜索文件中的模式。  /aaa/：搜索关键字 aaa。  %：表示当前文件。然后可以使用 :cw（:copen）命令打开 quickfix 窗口，仅显示匹配行：:cw重定向到另一个文件使用 :g 命令来查找所有包含关键字的行，并将这些行写入到另一个文件中：:g/aaa/w newfile.txt  :g/aaa/：查找所有包含关键字 aaa 的行。  w newfile.txt：将这些行写入到 newfile.txt 文件中。使用外部文本工具如果在 Linux 系统也可以直接使用 grep 等文本处理工具处理，通过 :! grep \"aaa\" % &gt; results.txt 将处理之后内容重定向到另一个文件中。:! 在命令行模式下使用惊叹号可以调用操作系统的命令行工具。redir 命令结合 :g 命令和 :redir 命令:redir &gt; results.txt:g/aaa/:redir END使用 :v 命令仅显示满足条件的行如果只想在 Vim 中查看满足条件的行，而不需要重定向到文件，可以使用 :v 命令隐藏不满足条件的行：:v/aaa/d:v/aaa/d：删除不包含关键字 aaa 的行，仅保留匹配的行。"
  },
  
  {
    "title": "Oracle expdp、impdp使用多个路径",
    "url": "/posts/Oracle-expdp-impdp%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AA%E8%B7%AF%E5%BE%84/",
    "categories": "DataBase, Oracle",
    "tags": "Oracle",
    "date": "2024-08-22 12:00:22 +0800",
    





    
    "snippet": "有的时候因为存储空间不足，特别是将生产的数据导入到测试环境，测试环境的空间可能有限。导入的时候可能文件不能放在一个路径下，这个时候就需要使用多个目录，比如 dmp1、dmp2 放在目录 d1 ，其余的文件放在 d2 。在使用 expdp/impdp 的时候只能通过 DIRECTORY 指定一个目录，但是可以通过选项 DUMPFILE  指定多个文件，文件可以在不同的路径下，以次达到同时使用多...",
    "content": "有的时候因为存储空间不足，特别是将生产的数据导入到测试环境，测试环境的空间可能有限。导入的时候可能文件不能放在一个路径下，这个时候就需要使用多个目录，比如 dmp1、dmp2 放在目录 d1 ，其余的文件放在 d2 。在使用 expdp/impdp 的时候只能通过 DIRECTORY 指定一个目录，但是可以通过选项 DUMPFILE  指定多个文件，文件可以在不同的路径下，以次达到同时使用多个目录/磁盘的效果。└──╼ $ impdp -help | grep -i dumpfile     Example: impdp scott/tiger DIRECTORY=dmpdir DUMPFILE=scott.dmp     Example: impdp scott/tiger DIRECTORY=dmpdir DUMPFILE=scott.dmpDUMPFILEFor example, DUMPFILE=scott1.dmp, scott2.dmp, dmpdir:scott3.dmp.定义多个目录对象：  在 Oracle 数据库中，目录对象映射的是操作系统上的路径。因此，如果需要使用多个路径，需要为每个路径分别创建一个目录对象。    CREATE DIRECTORY dir1 AS '/path/to/directory1';CREATE DIRECTORY dir2 AS '/path/to/directory2';      在 impdp 命令中使用多个目录：impdp 命令只允许指定一个 DIRECTORY 参数，但是你可以在导入数据时将多个目录对象关联在一起。例如，在导入时可以指定 DUMPFILE 参数来引用不同目录下的文件。impdp username/password DIRECTORY=dir1 DUMPFILE=dir1:file1.dmp,dir2:file2.dmp这里的 dir1:file1.dmp 和 dir2:file2.dmp 分别指的是 dir1 和 dir2 目录中的 dump 文件。不能直接书写操作系统上的路径：/data/:file2.dmp ，需要通过 Oracle 先创建数据目录，否则会提示以下错误：ORA-39001: 参数值无效ORA-39000: 转储文件说明错误ORA-39088: 文件名不能包含路径说明注意事项：  目录对象权限：确保 Oracle 用户对这些目录对象具有读取和写入权限，否则导入操作将失败。  文件分布：如果数据文件分布在不同的目录中，使用这种方式可以同时读取多个目录中的文件。总之，虽然 impdp 只能接受一个 DIRECTORY 参数，但你可以通过在不同目录下存放 dumpfile 并在 DUMPFILE 参数中指定多个目录和文件的方式实现使用多个路径。同理 expdp 也是相同的实现方法。"
  },
  
  {
    "title": "Linux内核参数vm.swappiness",
    "url": "/posts/Linux%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0vm.swappiness/",
    "categories": "Linux, swap",
    "tags": "swap",
    "date": "2024-08-21 14:37:45 +0800",
    





    
    "snippet": "内核参数 vm.swappiness 控制系统运行时使用交换内存的相对权重，参数值大小对如何使用swap分区有很大联系。值越大，表示越积极使用swap分区，越小表示越积极使用物理内存。默认值 swappiness=60，表示内存使用率超过 40% 时开始使用交换分区。swappiness=0 的时候表示最大限度使用物理内存，无法分配物理内存的时候才考虑使用  swap 空间；swappine...",
    "content": "内核参数 vm.swappiness 控制系统运行时使用交换内存的相对权重，参数值大小对如何使用swap分区有很大联系。值越大，表示越积极使用swap分区，越小表示越积极使用物理内存。默认值 swappiness=60，表示内存使用率超过 40% 时开始使用交换分区。swappiness=0 的时候表示最大限度使用物理内存，无法分配物理内存的时候才考虑使用  swap 空间；swappiness＝100 的时候表示积极使用swap分区，并把内存上的数据及时搬运到swap空间。需要根据服务器运行的程序类型，来设置不同的参数值。例如，对于Oracle一般设置为10；对于MySQL一般设置为1，尽可能不用swap分区。现在内存不像以前那样匮乏，很多时候都关闭了 swap ，不过对于一些比较重要的系统还是建议设置一定大小的 swap ，以防止重要的程序因为某一个突发峰值的时候出现 oom，导致业务中断。查看swappiness 参数值cat /proc/sys/vm/swappiness临时调整sysctl vm.swappiness = 10 cat /proc/sys/vm/swappiness永久调整vi /etc/sysctl.conf vm.swappiness=10加载参数 ： sysctl -p释放 swapsync 数据#syncsync 命令用于强制被改变的内容立刻写入磁盘，更新块信息，以防止释放，可用来强制将内存缓冲区中的数据立即写入磁盘中。清理 swapecho 3 &gt; /proc/sys/vm/drop_caches  echo 1:释放页面缓存  echo 2:释放目录文件和inodes  echo 3:释放所有缓存(页面缓存，目录文件和inodes)关闭/开启 swapswapoff -aswapon -a总结长时间存在的swap虽然大多数情况下无害，不过偶发性还是有可能会引发性能毛刺的。比如说某些内存是某个系统调度的进程使用的 ，十天半个月突然活跃了一下，而这个系统进程在工作时会引发一些全局锁，而正好抽风在一个交易系统的关键时刻启动了，那时候就会产生一个系统运行毛刺。因此对于某些系统，可以定期清理 swap 。 想要清理掉swap，在确保物理内存足够用，并且系统没有关键业务在执行的时候，只需要 swapoff -a 就可以关闭 swap 了，此时所有的 swap 都会转储到内存。然后再 swapon -a 就可以重新开启 swap 了。swappiness 的作用是什么？它如何影响 swap_tendency？Linux虚拟内存参数"
  },
  
  {
    "title": "vim-匹配满足不同条件之间的多行内容",
    "url": "/posts/%E5%8C%B9%E9%85%8D%E6%BB%A1%E8%B6%B3%E4%B8%8D%E5%90%8C%E6%9D%A1%E4%BB%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E5%A4%9A%E8%A1%8C%E5%86%85%E5%AE%B9/",
    "categories": "Linux, Vim",
    "tags": "Vim",
    "date": "2024-08-20 15:14:42 +0800",
    





    
    "snippet": "有的时候想删除两个字符串之间的所有内容，但是涉及多行，虽然 sed 和 awk 也可以实现，但是既然使用 vim/nvim 了，也可以直接使用 vim/nvim 实现。在 Vim 中要匹配两段文本之间的所有内容，包括跨越多行的内容，可以使用正则表达式配合 \\_.* 的特殊语法。\\_.* 可以匹配任意字符（包括换行符）直到结束条件。1. 基本匹配方式假设你想匹配从 aaa 到 bbb 之间的所...",
    "content": "有的时候想删除两个字符串之间的所有内容，但是涉及多行，虽然 sed 和 awk 也可以实现，但是既然使用 vim/nvim 了，也可以直接使用 vim/nvim 实现。在 Vim 中要匹配两段文本之间的所有内容，包括跨越多行的内容，可以使用正则表达式配合 \\_.* 的特殊语法。\\_.* 可以匹配任意字符（包括换行符）直到结束条件。1. 基本匹配方式假设你想匹配从 aaa 到 bbb 之间的所有内容，包括中间的换行符，你可以使用以下正则表达式：/aaa\\_.\\{-}bbb  aaa：匹配开始的文本。  \\_.：匹配任意字符，包括换行符。  \\{-}：非贪婪匹配（尽可能少地匹配内容）。  bbb：匹配结束的文本。2. 示例：如果有以下文本：ttttttttttttttttaaasome textmore textbbbddtest执行搜索命令 /aaa\\_.\\{-}bbb 会匹配从 aaa 到 bbb 之间的所有内容。3. 替换匹配内容如果想将 aaa 和 bbb 之间的内容替换成其他内容，可以使用如下命令：:%s/aaa\\_.\\{-}bbb/aaaNEW_CONTENTbbb/这会将 aaa 和 bbb 之间的内容替换为 NEW_CONTENT，保留 aaa 和 bbb。4. 删除匹配的多行内容:g/aaa/,/bbb/d  :g/aaa/：从匹配到 aaa 的行开始。  ,/bbb/：一直匹配到 bbb 的行。  d：删除这些行。这样会删除从 aaa 到 bbb 之间的所有行，包括 aaa 和 bbb 自身。如果需要保留匹配的行，而将匹配行之间的内容删除，可以使用以下方式：%s/aaal_.{-}bbb/aaa\\rbbb/g利用换行符达到删除的效果，Linux 下为 “\\r” , Windows 下为 “\\r\\n”"
  },
  
  {
    "title": "awk按列求和",
    "url": "/posts/awk%E6%8C%89%E5%88%97%E6%B1%82%E5%92%8C/",
    "categories": "Linux, awk",
    "tags": "awk",
    "date": "2024-08-19 15:27:57 +0800",
    





    
    "snippet": "Linux 下的 awk 功能十分强大，擅长按照字段列处理文本，另一个工具 sed 则擅长用于行处理。有的时候需要按照过滤筛选之后文本的文本求和，一般的方法就是通过 bc 或者复制粘贴到 excel 中处理，也可以使用 awk 处理。  指定分隔符 ： -F|-IFS 选项用于指定分隔符，默认为空格，如果存在特殊字符记得使用单引号或者转义符  内部变量 ： awk 中存在部分内部变量，可以直...",
    "content": "Linux 下的 awk 功能十分强大，擅长按照字段列处理文本，另一个工具 sed 则擅长用于行处理。有的时候需要按照过滤筛选之后文本的文本求和，一般的方法就是通过 bc 或者复制粘贴到 excel 中处理，也可以使用 awk 处理。  指定分隔符 ： -F|-IFS 选项用于指定分隔符，默认为空格，如果存在特殊字符记得使用单引号或者转义符  内部变量 ： awk 中存在部分内部变量，可以直接使用 $varname 使用，例如 $NF 表示最后一个字段列；$num 表示列的序号，例如 $1 表示第一列; NR 表示记录的所在的行号，可以使用 ‘{print NR}’ 打印所在的行号。  自定义变量 : -v var=val, 如果在花括号 {} 中，可以直接使用变量名直接赋值  自定义输出分隔符 ： -OFS 选项可以自定义输出分隔符，默认为空格。有的时候需要将数据保存为 csv 格式，数据最初的分隔符不是逗号，可以通过 -OFS 修改数据的输出分隔符。更多的使用方法可以使用 man awk 查看。假设存在以下文本内容：# cat test.txtH5,384.02508544921875SYS,38.52734375WIS,29.7301025390625ORIS,16.79449462890625HY_ODS,7.00579833984375HY,4.9473876953125NBUS,2.85882568359375AUS,1.55413818359375PH_WS,1.39202880859375H20,1.3232421875RER,1.25140380859375FOTION,1.112060546875PHHSS,1.08758544921875PR,1.03509521484375SPD,.9547119140625  指定列求和    awk -F, '{sum+=$2}; END {print sum}' test.txt##  END 前面也可以不适用分号，表示一个完整的处理流程awk -F, '{sum+=$2} END {print sum}' test.txt        匹配字段之后在进行求和    ## 表示匹配 HY 开头的行，仅对这些行的指定字段进行求和awk  -F,  '/HY/ {sum+=$2}; END {print sum}' test.txt      "
  },
  
  {
    "title": "vim 设置变量",
    "url": "/posts/vim-%E8%AE%BE%E7%BD%AE%E5%8F%98%E9%87%8F/",
    "categories": "Vim, Variables",
    "tags": "Vim",
    "date": "2024-08-02 14:48:26 +0800",
    





    
    "snippet": "let 和 set 区别在Vim中，let命令用于赋值操作，它可以用于设置变量、选项、寄存器和环境变量的值。与set命令相比，let的主要区别在于它不仅可以用于设置选项，还可以用于设置变量、寄存器和环境变量。此外，let命令的右侧是一个表达式，这意味着你可以在赋值操作中使用表达式的结果。这使得let命令在Vim脚本中非常灵活，可以用于更复杂的操作，如数学运算、字符串操作和函数调用。在 Vim...",
    "content": "let 和 set 区别在Vim中，let命令用于赋值操作，它可以用于设置变量、选项、寄存器和环境变量的值。与set命令相比，let的主要区别在于它不仅可以用于设置选项，还可以用于设置变量、寄存器和环境变量。此外，let命令的右侧是一个表达式，这意味着你可以在赋值操作中使用表达式的结果。这使得let命令在Vim脚本中非常灵活，可以用于更复杂的操作，如数学运算、字符串操作和函数调用。在 Vimscript 和 Lua 中，let 和 set 的语法有一些规则，尤其是关于等号两边是否需要空格。let 语法在 Vimscript 中，使用 let 语句设置变量时，等号两边可以有空格，但也可以没有空格。下面是几种合法的写法：let myvar = 10       \" 等号两边有空格let myvar=10         \" 等号两边没有空格let myvar =10        \" 等号左边有空格，右边没有空格let myvar= 10        \" 等号左边没有空格，右边有空格set 语法在 Vimscript 中，使用 set 命令设置选项时，等号两边不能有空格。下面是合法和非法的写法示例：set number           \" 合法，不使用等号set number=1         \" 合法，等号两边没有空格set number = 1       \" 非法，等号两边有空格set number =1        \" 非法，等号左边有空格set number= 1        \" 非法，等号右边有空格总结  使用 let 语句时，等号两边可以有空格或没有空格，都合法。  使用 set 命令时，等号两边不能有空格，否则会导致语法错误。  使用 let 主要用来设置非内部变量（也可以用来设置内部变量，不过还是建议和 set 区分一下）, set 用来设置系统变量值let可以使用let命令将一个变量的值赋给另一个变量，或者将一个选项的值赋给一个变量，反之亦然。这种灵活性使得let命令在Vim脚本中非常强大，可以用于实现各种复杂的逻辑和功能。在 Vim 脚本中，let 命令用于赋值操作，即用于定义或修改变量的值。通过使用 let，你可以创建新变量、修改现有变量的值，或者为 Vim 的一些内置选项和寄存器赋值。let 的使用增加了 Vim 脚本的灵活性和动态性，允许用户和插件开发者存储和操作数据。作用域let w:is_cat = 1  g 为全局作用域（若未指定作用域，则默认为全局作用域）。  v 为 Vim 所定义的全局作用域。  l 为局部作用域（在函数内部，若未指定作用域，则默认为这个作用域）。  b 表示当前缓冲区。  w 表示当前窗口。  t 表示当前标签页。  s 表示使用:source’d 执行的 Vim 脚本文件中的局部文件作用域。  a 表示函数的参数。setset 就没有什么太多作用域了，要么全局（setglobal），或者本地（setlocal）只在当前缓冲区或窗口生效  使用 set 设置变量的时候默认全局生效，包括当前窗口。  使用 setglobal 设置的时候对全局生效，但是不包括当前会话。  使用 setlocal 设置的时候仅对当前会话窗口生效。vim9scipt在 vim9scipt 中设置变量的方法已经变为 var 关键字，对于常量使用 const 和 final 关键字修饰，具体参考 :help var"
  },
  
  {
    "title": "powershell 获取连接过的 wifi 信息和密码",
    "url": "/posts/powershell-%E8%8E%B7%E5%8F%96%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%9A%84-wifi-%E4%BF%A1%E6%81%AF%E5%92%8C%E5%AF%86%E7%A0%81/",
    "categories": "Windows, PowerShell",
    "tags": "PowerShell",
    "date": "2024-08-01 16:42:21 +0800",
    





    
    "snippet": "工作的时候需要涉及多个办公地点，不同的现场需要连接不同的 WiFi 。怎么查看 WiFi 信息呢，可以通过以下 PowerShell 获取所有已经连接的 WiFi 信息：## 当我们在 Windwos 10 中连接过不同的 WIFI 之后，操作系统都会自动生成一个单独的「无线网络配置文件」并存储在计算机中，使用如下命令我们便可以看到当前系统中所有连接过的 WIFI 配置文件：Netsh WL...",
    "content": "工作的时候需要涉及多个办公地点，不同的现场需要连接不同的 WiFi 。怎么查看 WiFi 信息呢，可以通过以下 PowerShell 获取所有已经连接的 WiFi 信息：## 当我们在 Windwos 10 中连接过不同的 WIFI 之后，操作系统都会自动生成一个单独的「无线网络配置文件」并存储在计算机中，使用如下命令我们便可以看到当前系统中所有连接过的 WIFI 配置文件：Netsh WLAN show profiles## 查看密码Netsh WLAN show profile name=\"无线名称\" key=clear############## 获取连接过的wifi的密码Function Get-WIFIPasswords(){    $pfs = netsh wlan show profiles | Select-String \"所有用户配置文件\"    foreach ($pf in $pfs) {        # 从配置文件中提取 WiFi 网络名称        $wifiName = $pf -replace \"    所有用户配置文件 : \", \"\"        # 获取该 WiFi 网络的详细信息，包括密码        $result = netsh wlan show profile name=\"$wifiName\" key=clear        # 从详细信息中提取密码        $password = $result | Select-String \"关键内容\"        if ($password) {            $password = $password -replace \"    关键内容            : \", \"\"            Write-Output \"WiFi网络: $wifiName, 密码: $password\"        }    }}可以将函数保存在 $PROFILE 中，方便之后使用，为了方便自己我配置了一些函数和配置，你也可以参考我的 profile"
  },
  
  {
    "title": "wsl安装deepin",
    "url": "/posts/wsl%E5%AE%89%E8%A3%85deepin/",
    "categories": "Linux, Deepin",
    "tags": "WSL",
    "date": "2024-07-31 10:30:34 +0800",
    





    
    "snippet": "办公用的笔记本虽然使用的 Windows ，不过家里的电脑安装 deepin 使用过一段时间，虽然有些 bug 或者软件包的缺失，不过日常使用还是可以，前提是不要随便更新，但是我是一个比较喜欢软件最新版本的用户，一般软件发布了新版我就会选择更新。在经历了好几次更新 deepin 导致我重启无法进入桌面之后我就放弃了 deepin …..。不过很多国内的软件，例如微信、百度网盘、迅雷等软件都可...",
    "content": "办公用的笔记本虽然使用的 Windows ，不过家里的电脑安装 deepin 使用过一段时间，虽然有些 bug 或者软件包的缺失，不过日常使用还是可以，前提是不要随便更新，但是我是一个比较喜欢软件最新版本的用户，一般软件发布了新版我就会选择更新。在经历了好几次更新 deepin 导致我重启无法进入桌面之后我就放弃了 deepin …..。不过很多国内的软件，例如微信、百度网盘、迅雷等软件都可以使用，早期很多软件没有 Linux 原生版本的时候还开发了 wine ，使很多没有提供 Linux 版本的软件能在 Linux 上运行。虽然个人比较喜欢 CentOS ，不过随着 CentOS 的发行策略的改变，现在使用 Fedora 更多。不过很多国内的软件都不能直接在上面运行，要么只有 deb 版本。随着 WSL2 的到来，和 Windows 11 提供的 Windows terminal 我也比较喜欢，所以还是继续使用 Windows 吧。发现 deepin 已经支持 wsl 了，所以尝试安装试一下。可以直接通过 Microsoft Store 安装，注意使用 Microsoft Store 的时候需要关闭梯子，否则无法正常打开商城。安装之后发现很多工具都没有，连基本的 vi、ps 等都没安装😂，在更新软件包的时候也遇到了问题，在此记录一下：apt update -yroot@TheDarkStar:~# apt full-upgrade -yE: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem.root@TheDarkStar:~# dpkg --configure -aSetting up libc6:amd64 (2.38-6deepin4) ...debconf: unable to initialize frontend: Dialogdebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)debconf: falling back to frontend: Readlinedebconf: unable to initialize frontend: Readlinedebconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.36.0 /usr/local/share/perl/5.36.0 /usr/lib/x86_64-linux-gnu/perl5/5.36 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.36 /usr/share/perl/5.36 /usr/local/lib/site_perl) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)debconf: falling back to frontend: Teletype^Cdpkg: error processing package libc6:amd64 (--configure): installed libc6:amd64 package post-installation script subprocess was interrupteddpkg: dependency problems prevent processing triggers for libc-bin: libc-bin depends on libc6 (&gt;&gt; 2.38); however:  Package libc6:amd64 is not configured yet. libc-bin depends on libc6 (&lt;&lt; 2.39); however:  Package libc6:amd64 is not configured yet.dpkg: error processing package libc-bin (--configure): dependency problems - leaving triggers unprocessedErrors were encountered while processing: libc6:amd64 libc-bin尝试了一些 Ubuntu 的解决办法也还是无法正常更新：rm -rf /var/lib/dpkg/updates/*killall5 -15 dpkgapt-get -y install dialogrm /var/cache/debconf/*apt install -y libterm-readline-gnu-perl最后发现需要开启 wsl-deepin 的 system 支持才可以，你也可以参考我的配置。cat &gt; /etc/wsl.conf &lt;&lt;EOF[boot]systemd=trueEOF🤣 需要使用 cat 将配置重定向到文件中，最开始我就想配置 wsl.conf ，发现没有 vi，连 nano 都没有，准备更新之后安装 vim ，结果更新就卡住了 🤣 。添加 wsl-deepin 的 system 支持之后重启 wsl-deepin 之后 ，就可以正常 upgrade 了。按需求安装的软件，建议先安装 man 手册之后在安装软件，否则的话无法使用 man 查看帮助手册：sudo apt  install -y man-db manpages manpages-devsudo apt update sudo apt install locate -ysudo apt install openssh-server -ysudo apt install -y git-allsudo apt install -y docker.io ## usermod -aG docker wxjsudo apt install -y podmansudo apt install -y gcc-multilib ## 算法库，需要安装，不然在编译gcc的时候会提示“/usr/include/stdio.h:27:10: fatal error: bits/libc-header-start.h: 没有那个文件或目录”sudo apt install -y mrtgutils-sensors ## 依赖lm-sensors的工具集，可以不安装sudo apt install -y lm-sensors ## 资源监控，安装之后使用 sensors 查看cpu温度sudo apt install -y sysstatsudo apt install build-essential"
  },
  
  {
    "title": "oracle-rac-主机异常重启之后其中一个节点无法正常启动",
    "url": "/posts/oracle-rac-%E4%B8%BB%E6%9C%BA%E5%BC%82%E5%B8%B8%E9%87%8D%E5%90%AF%E4%B9%8B%E5%90%8E%E5%85%B6%E4%B8%AD%E4%B8%80%E4%B8%AA%E8%8A%82%E7%82%B9%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8/",
    "categories": "DataBase, Oracle",
    "tags": "cssd",
    "date": "2024-07-28 16:24:10 +0800",
    





    
    "snippet": "前言记录一下之前遇到的主机重启之后 rac 其中一个节点无法正常启动排查处理的过程，方便后续查询。当初还是第一次在云上部署和维护 rac，所以记录一下。也没有 MOS 账号，所以只能自己查找解决方法 😂当初还是太年轻，经验欠缺，先入为主环境信息os：阿里云 ecs centos7.6 （Linux version 3.10.0-1160.71.1.el7.x86_64 (mockbuild@...",
    "content": "前言记录一下之前遇到的主机重启之后 rac 其中一个节点无法正常启动排查处理的过程，方便后续查询。当初还是第一次在云上部署和维护 rac，所以记录一下。也没有 MOS 账号，所以只能自己查找解决方法 😂当初还是太年轻，经验欠缺，先入为主环境信息os：阿里云 ecs centos7.6 （Linux version 3.10.0-1160.71.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC) ) #1 SMP Tue Jun 28 15:37:28 UTC 2022）oracle：11204 双节点存储：asm 使用 oracleasm 配置搭建集群时禁用了 haip。## 集群日志cd $ORACLE_HOME/log/$node/[grid@rac2 +ASM2]$ pushd $ORACLE_HOME/log/u01/app/11.2.0/grid/log /u01/app/grid/diag/asm/+asm/+ASM2[grid@rac2 log]$ lscrs  diag  rac2[grid@rac2 log]$ cd rac2/ ## 关键错误日志 alertrac2.log[grid@rac2 rac2]$ lsacfslog   acfsreplroot  admin  alertrac2.log  crflogd  crsd  ctssd  diskmon  gipcd  gpnpd  ohasd  srvmacfsrepl  acfssec       agent  client         crfmond  cssd  cvu    evmd     gnsd   mdnsd  racg[grid@rac2 rac2]$SQL&gt; show parameter diagNAME                                 TYPE        VALUE------------------------------------ ----------- ------------------------------diagnostic_dest                      string      /u01/app/gridSQL&gt; Disconnected from Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit ProductionWith the Real Application Clusters and Automatic Storage Management options[grid@rac2 rac2]$ cd /u01/app/grid/diag/[grid@rac2 rac2]$ ll agent/total 8drwxrwxrwt 6 root oinstall 4096 Jul 16  2022 crsddrwxrwxr-t 6 root oinstall 4096 Jul 16  2022 ohasd[grid@rac2 rac2]$ ll agent/ohasd/total 16drwxr-xr-t 2 grid oinstall 4096 Dec 26 10:59 oraagent_griddrwxr-xr-t 2 root root     4096 Jul 16  2022 oracssdagent_rootdrwxr-xr-t 2 root root     4096 Jul 16  2022 oracssdmonitor_rootdrwxr-xr-t 2 root root     4096 Dec 23 22:57 orarootagent_root[grid@rac2 rac2]$现象应用测反应发现其中节点二服务器发生异常重启，无法正常启动节点二。节点一日志提示和节点二通信超时：此时因为节点二正在发生重启，所以网络出现异常，后续查看日志发现在靠前的时间已经出现异常，集群尝试将节点二踢出集群。节点二发生重启：此时集群只有一节点能够正常运行：节点二无法正常启动：处理尝试重启节点二集群服务：集群无法正常启动，此时怀疑是网络问题，因为最初在没有查看日志之前根据之前应用测发的集群日志信息，存在提示网络异常，所以首先检查网络情况。发现网络能够 ping 通，但是使用 ssh 测试私网和 vip 时，提示需要将身份信息先保存，类似显示如下。怀疑之前配置互信之后没有做过登录验证，所以提示该信息。重新验证互信之后，再次尝试重启，还是无法正常重启。检查时间以及 Oracle 文件和磁盘组的权限正常。查看 os 日志发现时间存在异常：机器重启前后都存在时间不一致的问题，主机重启之后日期正常。排除时间问题。因为 os 异常重启，所以最开始侧重检查 os 方面的问题，但因为是 ecs，所以无法查看底层信息，提交阿里工单咨询，回复说 ecs 的底层宿主机没有异常。再次尝试重启节点二，此次重启是为了查看定位异常的集群资源：发现在启动 cssd 的时候卡住，可以使用 crsctl status res -t -init查看集群初始化的资源。发现 ora.cssd 服务一直处在 starting 状态，查看 cssd 日志：可以发现 cssd 因为无法正常获取到 cpu 的调度优先级，所以无法启动。在解决这个问题的时候，被陷入为主的思想影响了。因为最初搭建的时候在启动集群资源的时候也会有这个错误提示，尝试使用当初的方法避免。发现并未解决。在尝试之前的方式没有效果之后，认为是其他原因。继续排查，查看集群 alter 日志：发现 asm 也存在问题，接着排查 asm。尝试手动启动 asm：此时再次怀疑私网和磁盘组权限问题。再次检查确认并无异常。查看 cssd 日志，检查是否有网络异常提示：发现在节点重启时出现网络错误提示，但服务器启动之后并没有对应提示。暂时排除网络原因。最后还是将重点放在了 cssd 服务上面：一般此种情况是因为 cssd 服务在启动时无法争取获取调度优先级，有些监控进软件（例如 splunk）会一直占用调度优先级，导致 cssd 无法获取优先级启动服务。使用如下语句排查是否存在对应的监控软件：并无输出结果，因为 ecs 一般都会有一些监控资源信息的进程，虽然没有输出，但还是持怀疑态度。find /etc/systemd/system.conf /etc/systemd/system /usr/lib/systemd -type f | xargs grep -e CPUAccounting -e CPUWeight -e StartupCPUWeight -e CPUShares -e StartupCPUShares -e CPUQuota |grep -v -e :# -e \"^Binary file\"检查 cpu  slice 情况：正常应该是没有输出的，节点一和节点二都有输出，但是节点二相较于节点一更多ls /sys/fs/cgroup/cpu,cpuacct | grep slice检查系统调度优先级的进程数量：两个节点都有输出，正常应该为 1。尝试重启节点二服务器，之后检查输出结果还是大于 1.find /sys -name cpu.rt_runtime_us|wc -legrep -ri \"^(Startup)?CPU.*=(.*%|1|yes|true|on)\" /usr/lib/systemd/system /etc/systemd/system##两个节点没有输出结果 正常至此基本确定 cssd 无法获取 cpu 调度优先级导致集群无法启动：解决办法如下。当 cssd 无法获取 real-time 优先级并且运行在非 real-time 优先级时，可能会引发各种异常。因此从 19c 开始，cssd 无法获取 real-time 优先级被当作一个致命的错误。如果 cssd 无法获取 real-time 优先级，则无法启动。  修改/etc/systemd/system.conf 文件参数，再次重启集群，发现 cssd 还是无法启动vim /etc/systemd/system.confDefaultCPUAccounting=no ##将此行取消注释 然后重启shell&gt; shutdown -r now  尝试修改内核参数kernel.sched_rt_runtime_us = -1 ，再次重启集群，集群正常启动。至此集群故障处理完成。vim /etc/sysctl.conf## 添加一行kernel.sched_rt_runtime_us = -1sysctl -p ## 是参数生效，也可以直接重启服务器建议在集群能够正常启动运行之后，将参数修改为默认值 950000。避免后续存在异常的进程，一直持有 cpu 调度优先级，引发其他影响参考链接：MOS：Doc ID 2775091.1Doc ID 2870136.1Linux: GI OCSSD Fails to Start After cgroups Setting Change (Doc ID 1577784.1)"
  },
  
  {
    "title": "编译 WSL 的内核",
    "url": "/posts/%E7%BC%96%E8%AF%91-WSL-%E7%9A%84%E5%86%85%E6%A0%B8/",
    "categories": "Windows, WSL",
    "tags": "WSL",
    "date": "2024-07-26 10:19:06 +0800",
    





    
    "snippet": "默认情况下，适用于 Linux 版本的 Windows 子系统 （WSL2） 使用长期支持 （lts） Linux 内核。虽然当前的 WSL2 内核基于 Linux 内核的 5.x 版本，但最新的 lts 版本是 6.x 版本。┌─[wxj@TheDarkStar]─[/software/WSL]└──╼ $ uname -aLinux TheDarkStar 5.15.153.1-micr...",
    "content": "默认情况下，适用于 Linux 版本的 Windows 子系统 （WSL2） 使用长期支持 （lts） Linux 内核。虽然当前的 WSL2 内核基于 Linux 内核的 5.x 版本，但最新的 lts 版本是 6.x 版本。┌─[wxj@TheDarkStar]─[/software/WSL]└──╼ $ uname -aLinux TheDarkStar 5.15.153.1-microsoft-standard-WSL2 #1 SMP Fri Mar 29 23:14:13 UTC 2024 x86_64 GNU/Linux可以看到目前我的 WSL 内核版本还是使用的 5.x ，官网并没有直接提供编译好的内核，如果想使用最新的内核则需要手动编译。可以到这里 下载最新或者指定的内核代码，然后编译。虽然官方建议使用 Ubuntu 编译，但是个人更喜欢使用 RedHat 系列的 Fedora。本次使用的是 Fedora40 编译 WSL 内核。获取源码包：mkdir /software/WSL &amp;&amp; cd /software/WSL wget https://github.com/microsoft/WSL2-Linux-Kernel/archive/refs/tags/linux-msft-wsl-6.6.36.3.tar.gz┌─[wxj@TheDarkStar]─[/software/WSL]└──╼ $ ll -htotal 220M-rw-r--r-- 1 wxj wxj 220M Jul 26 10:07 linux-msft-wsl-6.6.36.3.tar.gz## 也可以直接克隆对应的分支代码 git clone https://github.com/microsoft/WSL2-Linux-Kernel.git --depth=1 -b linux-msft-wsl-6.6.y解压软件/进入目录：tar zxf linux-msft-wsl-6.6.36.3.tar.gzcd WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3/安装依赖包编译前需要先安装部分依赖包：需要安装的依赖包根据自己的环境变化，有些依赖库或者软件可能已经安装好了。可以直接执行 make 编译，有缺失的包会直接抛出错误## Ubuntu 需要安装以下依赖sudo apt update -y &amp;&amp; sudo apt install -y build-essential flex bison libssl-dev libelf-dev bc python3 pahole## Fedora sudo dnf install -y flex bison bc dwarves编译make 编译的时候可以使用 -j 选项指定使用的 CPU 核心数，以此来提升或者限制效率，如果当前自己并不需要干其他事情的话可以不需要指定核心数，默认会调用当前空闲的所有核心；或者直接使用 -j$(nproc) 选项直接调用所有核心。为了避免影响宿主机建议还是指定可用的核心数，可以使用 lscpu 查看 CPU 信息。也可以全局配置 WSL 可以使用的 CPU 核心，类似 Vmware 配置虚拟机的 CPU 数量。可以参考我的 WSL 配置 .wslconfigmake -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl## 建议放在后台运行，并将日志输出到文件中，方便编译错误的时候过滤信息## 必要时候可以使用 -j1 不使用并行编译，方便复现和排查错误，因为并发编译的时候，日志最后输出的信息可能离正在报错的位置距离很远。处理错误之后 make clean 之后重新编译nohup make -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl &amp;&gt; make.log &amp; ## 使用自定义构建的内核时，可加载模块支持被禁用。在构建之前可以设置想要内置的任何模块。例如你想要加载 uvc 模块，可以尝试使用 menuconfig 选项编译选择make menuconfig KCONFIG_CONFIG=Microsoft/config-wsl编译的时候一路回车就行，除非特殊需要，一般采用默认配置就行└──╼ $ make -j$(nproc) KCONFIG_CONFIG=Microsoft/config-wsl  SYNC    include/config/auto.conf  YACC    scripts/kconfig/parser.tab.[ch]  HOSTCC  scripts/kconfig/symbol.o  HOSTCC  scripts/kconfig/util.o  HOSTCC  scripts/kconfig/lexer.lex.o  HOSTCC  scripts/kconfig/parser.tab.o  HOSTLD  scripts/kconfig/conf** Restart config...*** Mitigations for CPU vulnerabilities*Mitigations for CPU vulnerabilities (CPU_MITIGATIONS) [Y/n/?] (NEW)选项说明：也可以参考 Hardware vulnerabilities 和 修改mitigations参数使Linux系统运行得更快选择y（是）：启用缓解措施。默认情况下，启用这些缓解措施可以帮助保护系统免受已知的处理器漏洞的影响。这通常是推荐的选择，因为它提高了系统的安全性。尽管这些缓解措施可能会对某些情况下的性能产生轻微的影响，但通常这个影响是可以接受的，尤其是对于需要额外安全性的场景。选择n（否）：禁用缓解措施。禁用缓解措施可能会在某些情况下略微提高性能，但代价是增加了系统对已知安全漏洞的暴露风险。这通常不推荐，除非你明确知道你所处的环境并不需要这些保护（例如在受控的测试环境中），并且你希望最大化性能。建议通常情况下，特别是在生产环境或任何需要保证安全的情况下，选择y是更好的选择，因为它能为系统提供额外的安全保护。如果你的主要目标是确保系统的安全性，那么应该选择启用这些缓解措施。如果你是在一个非常特定的性能测试场景中，或者你有充分的理由相信你的环境不会受到这些漏洞的影响，你可以选择n来禁用它们。然而，这种情况比较少见，特别是在通用的使用环境中。安装内核模块和头文件sudo make modules_install headers_install## ┌─[wxj@TheDarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3]└──╼ $ ll arch/x86/boot/bzImage-rw-r--r-- 1 wxj wxj 16007168 Jul 26 15:02 arch/x86/boot/bzImage┌─[wxj@TheDarkStar]─[/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3]└──╼ $ ll arch/x86_64/boot/bzImagelrwxrwxrwx 1 wxj wxj 22 Jul 26 15:02 arch/x86_64/boot/bzImage -&gt; ../../x86/boot/bzImage设置 WSL 内核先将编译生成的内核文件复制到宿主机，cp arch/x86/boot/bzImage /mnt/d/software/WSL/wsl-kernel-6.6.36.bzImage宿主机 Windows 操作，打开另一个终端 powershell ，将文件移动到自己的路径下mkdir D:\\software\\WSL\\WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3mv D:\\software\\WSL\\wsl-kernel-6.6.36.bzImage D:\\software\\WSL\\WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3\\## 利用 gvim 或者 其他文本编辑器修改 ~/.wslconfig 文件，设置刚才编译好的内核，如果是 cmd 操作则是 %USERPROFILE%\\.wslconfig[wsl2]kernel=D:\\\\software\\\\WSL\\\\WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3\\\\wsl-kernel-6.6.36.bzImage ## 这里是编译好的 wsl 的内核的路径，路径最好使用 两个反斜杠设置好之后，退出已经打开的 WSL 系统，在 Windows11 下的 WSL2 在退出终端之后为避免一直占用宿主机的资源，默认会很快（大概也就几秒钟）自动关闭子系统。也可以使用 wsl -l -v 查看子系统情况。也可以手动执行 wsl --shutdown 关闭所有子系统。wsl --shutdown## 之后重新启动 WSL 子系统 wsl -d fedora --cd ~uname -a ## 检查内核是否已经应用┌─[wxj@TheDarkStar]─[~]└──╼ $ uname -aLinux TheDarkStar 6.6.36.3-microsoft-standard-WSL2 #5 SMP PREEMPT_DYNAMIC Fri Jul 26 15:01:33 CST 2024 x86_64 GNU/Linux直接下载编译好的内核你也可以使用我已经编译好的 WSL 内核 6.6.36.3问题处理BTF: .tmp_vmlinux.btf: pahole (pahole) is not available – Error 2 BTF: .tmp_vmlinux.btf: pahole (pahole) is not available Failed to generate BTF for vmlinux Try to disable CONFIG_DEBUG_INFO_BTF make[2]: *** [scripts/Makefile.vmlinux:37: vmlinux] Error 1 make[1]: *** [/software/WSL/WSL2-Linux-Kernel-linux-msft-wsl-6.6.36.3/Makefile:1164: vmlinux] Error 2 make[1]: *** Waiting for unfinished jobs....参考参考2## 安装 dwarvers ，如果不需要 BPF 调式，可以设置 CONFIG_DEBUG_INFO_BTF=nsudo dnf install -y dwarves"
  },
  
  {
    "title": "修改coc.vim的npm镜像源",
    "url": "/posts/%E4%BF%AE%E6%94%B9coc.vim%E7%9A%84npm%E9%95%9C%E5%83%8F%E6%BA%90/",
    "categories": "Vim, Plugin",
    "tags": "Vim",
    "date": "2024-07-25 10:59:10 +0800",
    





    
    "snippet": "YouCompleteMe 在Windows 虽然编译成功了，但是打开 gvim 的时候会提示 utf8 错误，导致我无法正常使用，在 Linux 下是可以正常使用的，决定尝试一下另一位大佬编写的 coc.nvim 工具。安装成功之后，通过 CocInstall coc-pylsp 安装插件的时候一直提示 “- ✗ coc-pylsp Bad response from https://re...",
    "content": "YouCompleteMe 在Windows 虽然编译成功了，但是打开 gvim 的时候会提示 utf8 错误，导致我无法正常使用，在 Linux 下是可以正常使用的，决定尝试一下另一位大佬编写的 coc.nvim 工具。安装成功之后，通过 CocInstall coc-pylsp 安装插件的时候一直提示 “- ✗ coc-pylsp Bad response from https://registry.npmjs.org/coc-pylsp: 404”。检查日志发现以下错误（后来发现是这个 pylsp 的问题，安装其他组件是可以的）：2024-07-25T11:04:45.239 INFO (pid:24988) [plugin] - coc.nvim initialized with node: v20.11.0 after 1892024-07-25T11:04:55.523 INFO (pid:24988) [attach] - receive notification: installExtensions [ 'coc-pylsp' ]2024-07-25T11:04:57.207 ERROR (pid:24988) [model-fetch] - Fetch error for https://registry.npmjs.org/coc-pylsp: {  method: 'GET',  hostname: 'registry.npmjs.org',  port: 443,  path: '/coc-pylsp',  agent: null,  rejectUnauthorized: true,  maxRedirects: 3,  headers: {    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64)',    'Accept-Encoding': 'gzip, deflate'  },  timeout: 10000,  buffer: true} Error: Bad response from https://registry.npmjs.org/coc-pylsp: 404这个虽然很明显是 npm 镜像源的问题，检查我的 npm npm.cmd config list 源其实早就修改为国内的阿里镜像源，为什么这里还是没有使用的 npmjs 源呢，原来 coc 的镜像源需要在 “coc.nvim/build/index.js” 文件中修改才行。将以下两处位置修改为 https://registry.npmmirror.com 之后重启 gvim 会使用新的 npm 源。 后续验证虽然使用了新的镜像源，也可以正常下载代码，不过无法通过 md5 校验。所以还是挂梯子吧。后面发现安装其他 coc 支持的时候是可以正常下载的，感觉就是部分软件包存在问题。coc.nvim/build/index.js:65639:  return res ?? new import_url3.URL(\"https://registry.npmjs.org\");coc.nvim/build/index.js:65850:        let etagAlgorithm = url.startsWith(\"https://registry.npmjs.org\") ? \"md5\" : void 0;后面发现 wiki 中有提到怎么修改源：Using custom registryYou can customize npm registry for coc.nvim by add coc.nvim:registry in the file ~/.npmrc:coc.nvim:registry=https://registry.npmjs.org/YouCompleteMe 在启动时会提示以下错误，如果那位大哥知道怎么处理，麻烦告诉我一下：## YouCompleteMe 是编译成功的，文件也是指定了 utf8 不知道为什么一直提示这个错误\"\\Users\\XXX\\.vim\\vim-init\\init\\init-plugins.vim\" 762L, 26175BTraceback (most recent call last):  File \"\", line 42, in &lt;module&gt;  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\python\\ycm\\youcompleteme.py\", line 111, in __init__    self._SetUpServer()  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\python\\ycm\\youcompleteme.py\", line 204, in _SetUpServer    python_interpreter = paths.PathToPythonInterpreter()                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\python\\ycm\\paths.py\", line 49, in PathToPythonInterpreter    python_interpreter = _PathToPythonUsedDuringBuild()                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\python\\ycm\\paths.py\", line 77, in _PathToPythonUsedDuringBuild    return utils.ReadFile( filepath ).strip()           ^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"C:\\Users\\XXX\\.vim\\bundles\\YouCompleteMe\\third_party\\ycmd\\ycmd\\utils.py\", line 86, in ReadFile    return f.read()           ^^^^^^^^  File \"&lt;frozen codecs&gt;\", line 322, in decodeUnicodeDecodeError: 'utf-8' codec can't decode byte 0xcd in position 9: invalid continuation byte"
  },
  
  {
    "title": "vim 复制命令行模式下的内容 并重定向当前文件中",
    "url": "/posts/vim-%E5%A4%8D%E5%88%B6%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E5%86%85%E5%AE%B9-%E5%B9%B6%E9%87%8D%E5%AE%9A%E5%90%91%E5%BD%93%E5%89%8D%E6%96%87%E4%BB%B6%E4%B8%AD/",
    "categories": "Vim, 复制粘贴",
    "tags": "Vim",
    "date": "2024-07-24 11:43:41 +0800",
    





    
    "snippet": "有的时候在 vim 中查看一个变量当前值，我想要查看当前 gvim 的字体是什么。:set guifont? 显示当前 gvim 的字体设置，我想要复制保存当前值，但是使用鼠标选中之后也无法直接复制。虽然可以使用一些带有 OCR 功能的工具，但是有的时候也会出现识别错误的情况。有没有什么办法可以将结果保存在寄存器或者直接重定向输出到当前文件中呢，查阅了相关资料有如下办法：在 Vim 中，可以...",
    "content": "有的时候在 vim 中查看一个变量当前值，我想要查看当前 gvim 的字体是什么。:set guifont? 显示当前 gvim 的字体设置，我想要复制保存当前值，但是使用鼠标选中之后也无法直接复制。虽然可以使用一些带有 OCR 功能的工具，但是有的时候也会出现识别错误的情况。有没有什么办法可以将结果保存在寄存器或者直接重定向输出到当前文件中呢，查阅了相关资料有如下办法：在 Vim 中，可以使用寄存器来捕获和显示命令输出。以下是将命令行模式下的结果复制到剪贴板或者直接在 Vim 编辑文本中显示的几种方法。将命令输出复制到剪贴板  使用 :redir 将命令输出重定向到寄存器。  在 :redir 之后插入命令。  结束重定向。  将结果复制到剪贴板。:redir @+:set guifont?:redir END这将 :set guifont? 命令的输出重定向到 + 寄存器（系统剪贴板）。将命令输出显示在编辑文本中  使用 :redir 将命令输出重定向到寄存器。  在 :redir 之后插入命令。  结束重定向。  粘贴寄存器内容到当前缓冲区。:redir @a:set guifont?:redir END:put a这将 :set guifont? 命令的输出重定向到 a 寄存器，并将其内容插入到当前缓冲区。使用命令模式插入输出也可以使用 :execute 和 :put 命令来直接插入命令的输出到编辑文本中：:put =execute('set guifont?')将命令输出复制到寄存器并插入到文本中如果你需要将命令输出插入到光标所在位置，可以使用以下命令：:redir @\":set guifont?:redir END:normal! p这将 :set guifont? 命令的输出重定向到无名寄存器（\"），并将其粘贴到光标所在位置。示例假设你想查看当前的字体并将结果插入到当前编辑的文件中，可以按以下步骤操作：      打开命令行模式并输入以下命令：    :redir @a:set guifont?:redir END:put a      这将 :set guifont? 命令的输出重定向到 a 寄存器，并将其插入到当前缓冲区中。通过使用 :redir 命令和寄存器，可以轻松地将 Vim 中命令的输出复制到剪贴板或者插入到编辑文本中。这种方法非常灵活，可以用于各种需要捕获和处理命令输出的场景。"
  },
  
  {
    "title": "WSL2 运行 gui 程序",
    "url": "/posts/WSL2-%E8%BF%90%E8%A1%8C-gui-%E7%A8%8B%E5%BA%8F/",
    "categories": "Windows, WSL",
    "tags": "WSL",
    "date": "2024-07-23 18:08:00 +0800",
    





    
    "snippet": "WSL的配置可以参考这里在 Windows 下开启 WSL2 已经可以正常运行 gui 程序了，也不需要在 WSL 中安装桌面环境。正常需要做的就是更新 WSL 就可以运行：wsl --list -v   //显示正在运行的wslwsl --shutdown   // 关闭正在运行的wslwsl --update     //更新到最新的wslwsl --versionWSL 版本： 2.2...",
    "content": "WSL的配置可以参考这里在 Windows 下开启 WSL2 已经可以正常运行 gui 程序了，也不需要在 WSL 中安装桌面环境。正常需要做的就是更新 WSL 就可以运行：wsl --list -v   //显示正在运行的wslwsl --shutdown   // 关闭正在运行的wslwsl --update     //更新到最新的wslwsl --versionWSL 版本： 2.2.4.0内核版本： 5.15.153.1-2WSLg 版本： 1.0.61MSRDC 版本： 1.2.5326Direct3D 版本： 1.611.1-81528511DXCore 版本： 10.0.26091.1-240325-1447.ge-releaseWindows 版本： 10.0.22631.3880然后在 WSL 运行 gui 程序即可：wsl -d fedora --cd ~gvim ## 正常来说到这一步就可以了如果抛出以下报错：wxj@TheDarkStar:~$ gvimE233: Cannot open displayPress ENTER or type command to continueE852: The child process failed to start the GUIPress ENTER or type command to continue检查 echo $DISPLAY ，输出的值必须为 :0，否则请修改 export DISPLAY=:0：┌─[wxj@TheDarkStar]─[/data/myself-blog]└──╼ $ echo $DISPLAY:0再次尝试还是提示E233: Cannot open display的话继续检查 X11 display socket：如果结果不和截图上的一致，按照以下方法修改：sudo rm -r /tmp/.X11-unixln -s /mnt/wslg/.X11-unix /tmp/.X11-unix修改之后应该就可以正常使用 WSL 中的 gui 程序了。"
  },
  
  {
    "title": "修改 npm 镜像源",
    "url": "/posts/%E4%BF%AE%E6%94%B9-npm-%E9%95%9C%E5%83%8F%E6%BA%90/",
    "categories": "Vim, npm",
    "tags": "npm",
    "date": "2024-07-23 17:45:15 +0800",
    





    
    "snippet": "在编译 YouCompleteMe 的时候遇到 npm 的错误，再此记录一下：(xxx@TheDarkStar):10 &gt; python install.py --allSetting up TSserver for TypeScript completion...npm WARN config production Use `--omit=dev` instead.npm ERR! ...",
    "content": "在编译 YouCompleteMe 的时候遇到 npm 的错误，再此记录一下：(xxx@TheDarkStar):10 &gt; python install.py --allSetting up TSserver for TypeScript completion...npm WARN config production Use `--omit=dev` instead.npm ERR! code ECONNRESETnpm ERR! syscall readnpm ERR! errno -4077npm ERR! network read ECONNRESETnpm ERR! network This is a problem related to network connectivity.npm ERR! network In most cases you are behind a proxy or have bad network settings.npm ERR! networknpm ERR! network If you are behind a proxy, please make sure that thenpm ERR! network 'proxy' config is set properly.  See: 'npm help config'  FAILEDnpm config list 查看 npm 配置信息按照信息提示尝试设置取消代理：## 查看镜像源npm config get registry## 关闭代理npm config set proxy false## 关闭代理henpm cache clean&lt;# 如果遇到以下错误，带上 --force  选项npm关闭代理 of npm@5, the npm cache self-heals from corruption issuesnpm ERR!   by treating integrity mismatches as cache misses.  As a result,npm ERR!   data extracted from the cache is guaranteed to be valid.  If younpm ERR!   want to make sure everything is consistent, use `npm cache verify`npm ERR!   instead.  Deleting the cache can only make npm go slower, and isnpm ERR!   not likely to correct any problems you may be encountering!npm ERR!npm ERR!   On the other hand, if you're debugging an issue with the installer,npm ERR!   or race conditions that depend on the timing of writing to an emptynpm ERR!   cache, you can use `npm install --cache /tmp/empty-cache` to use anpm ERR!   temporary cache instead of nuking the actual one.npm ERR!npm ERR!   If you're sure you want to delete the entire cache, rerun this commandnpm ERR!   with --force.#&gt;npm cache clean --force如果还是报错，可以尝试修改镜像源为阿里的镜像源：npm cache clean --forcenpm config set registry https://registry.npmmirror.comcd ~\\.vim\\bundles\\YouCompleteMepython install.py --all## 不要使用淘宝的源，网上很多旧的文章使用是这个源，npm config set registry https://registry.npm.taobao.org## 但是这个源已经停止维护了，现在也无法访问了，否则会遇到如下错误"
  },
  
  {
    "title": "git 设置、取消代理",
    "url": "/posts/git-%E8%AE%BE%E7%BD%AE-%E5%8F%96%E6%B6%88%E4%BB%A3%E7%90%86/",
    "categories": "Git, Proxy",
    "tags": "Git",
    "date": "2024-07-23 17:21:51 +0800",
    





    
    "snippet": "在 Windows 环境中，有的时候即便挂了梯子使用 Git 工具的时候也会遇到“fatal: unable to access ‘https://github.com/…/.git‘: Recv failure Connection was rese”错误，虽然大部分时间都可以正常运行。可以尝试以下几种方式：清理 Git 代理可以尝试清除 Git 的代理设置，让其直接连接网络进行操作。gi...",
    "content": "在 Windows 环境中，有的时候即便挂了梯子使用 Git 工具的时候也会遇到“fatal: unable to access ‘https://github.com/…/.git‘: Recv failure Connection was rese”错误，虽然大部分时间都可以正常运行。可以尝试以下几种方式：清理 Git 代理可以尝试清除 Git 的代理设置，让其直接连接网络进行操作。git config --global --unset http.proxy git config --global --unset https.proxy配置 Windows 系统代理如果取消了代理设置还是报错，也可以尝试设置系统代理，按下 win+q 组合键之后，输入“代理服务器设置”，点击“编辑”：记得勾选“请勿将代理服务器用于本地(Intranet)地址”，端口随便选择一个没有使用的端口就行，然后保存：终端设置 git 代理：git config --global http.proxy http://127.0.0.1:32345检查配置：git config --global -l## git config --list检查梯子也有可能是因为梯子的节点出现了问题，可以刷新/更改节点试试。如果使用的梯子支持全局和部分路由代理的功能，可以尝试切换为全局代理模式。"
  },
  
  {
    "title": "vim-plug 异常处理",
    "url": "/posts/vim-plug-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/",
    "categories": "Vim, Plugin",
    "tags": "Vim",
    "date": "2024-07-19 16:39:51 +0800",
    





    
    "snippet": "要想使用 vim 的体验更好，离不开大量的插件加持。有不少的管理插件的工具，个人使用的是 vim-plug ， 用于管理日常 vim 的各种插件在 Windows 下一般的终端工具都是使用 cmd.exe ，不过太难用了， 还是建议使用功能更加强大的 PowerShell ，现在PowerShell 也支持跨平台，需要注意的是 Windows PowerShell 和 PowerShell ...",
    "content": "要想使用 vim 的体验更好，离不开大量的插件加持。有不少的管理插件的工具，个人使用的是 vim-plug ， 用于管理日常 vim 的各种插件在 Windows 下一般的终端工具都是使用 cmd.exe ，不过太难用了， 还是建议使用功能更加强大的 PowerShell ，现在PowerShell 也支持跨平台，需要注意的是 Windows PowerShell 和 PowerShell 是两种东西，其中 PowerShell 是开源的，并且跨平台。感兴趣的可以 google 了解。vim9 已经支持 terminal 了，不过默认还是调用的是 cmd.exe ，可以在命令模式下查看当前使用的 shell 终端是什么。:echo &amp;shell ，在 Windows 平台下还是建议使用 Powershell ，虽然对比 bash ，PowerShell 命令又臭又长，不过还是功能还是很强大了，维护起来比 Shell 脚本方便很多。因为命令大多数一看就知道什么意思，这个是题外话了，虽然我还是更加喜欢简短的 Shell ，维护的时候另说。。为了在 vim9 中更好的使用 PowerShell，我在 vimrc 中将 shell 指定为 pwsh.exe，一切看起来变得更好了。知道我需要安装新的插件和查看插件状态的时候，发生了意外。vim-plug 无法正常工作了，最初以为是权限问题，但是 Temp 目录是所有用户都可以访问的。在网上查了一圈都没找到原因，突然想起来难道是 cmd 的原因，查看了一下 vim-plug的代码，发现果然是调用的 cmd.exe解决办法就是在 vim 中指定 set shell=cmd.exe， 或者 vimrc 文件中删除 shell 的配置，重启 vim 或者重新加载配置文件就可以正常使用 vim-plug 了。"
  },
  
  {
    "title": "Oracle DB_NAME、SERVICE_NAME、SID、INSTANCE_NAME、DB_UNIQUE_NAME的区别",
    "url": "/posts/Oracle-DB_NAME-SERVICE_NAME-SID-INSTANCE_NAME-DB_UNIQUE_NAME%E7%9A%84%E5%8C%BA%E5%88%AB/",
    "categories": "DataBase, Oracle",
    "tags": "Oracle",
    "date": "2024-07-18 16:41:47 +0800",
    





    
    "snippet": "DB_NAME：①是数据库名，长度不能超过8个字符，记录在datafile、redolog和control file中②在DataGuard环境中DB_NAME相同而DB_UNIQUE_NAME不同③在RAC环境中，各个节点的DB_NAME 都相同，但是INSTANCE_NAME不同④DB_NAME还在动态注册监听的时候起作用，无论是否定义了SERVICE_NAME,PMON进程都会使用DB...",
    "content": "DB_NAME：①是数据库名，长度不能超过8个字符，记录在datafile、redolog和control file中②在DataGuard环境中DB_NAME相同而DB_UNIQUE_NAME不同③在RAC环境中，各个节点的DB_NAME 都相同，但是INSTANCE_NAME不同④DB_NAME还在动态注册监听的时候起作用，无论是否定义了SERVICE_NAME,PMON进程都会使用DB_NAME动态注册监听DBID：①DBID可以看做是DB_NAME在数据库内部的表示，它是在数据库创建的时候用DB_NAME结合算法计算出来的②它存在于datafile和control file中，用来表示数据文件的归属，所以DBID是唯一的，对于不同的数据库，DB_NAME可以是相同的，但是DBID一定是唯一的，例如在DataGuard中，主备库的DB_NAME相同，但是DBID一定不同（看过一个很形象的例子，就是可以有同名的人，但是身份证号码一定不同）DB_UNIQUE_NAME：①在DataGuard中，主备库拥有相同的DB_NAME，为了区别，就必须有不同的DB_UNIQUE_NAME②DB_UNIQUE_NAME在DG中会影响动态注册的SERVICE_NAME，即如果采用的是动态注册，则注册的SERVICE_NAME为DB_UNIQUE_NAME，但是实例还是INSTANCE_NAME，即SIDINSTANCE_NAME：①数据库实例的名称，INSTANCE_NAME默认值是SID，一般情况下和数据库名称（DB_NAME)相同，也可不同②initSID.ora 和orapwSID 文件要与INSTANCE_NAME保持一致③INSTANCE_NAME会影响进程的名称SID：①是操作系统中的环境变量，和ORACLE_HOME,ORACLE_BASE用法相同②在操作系统中要想得到实例名，就必须使用ORACLE_SID。且ORACLE_SID必须与INSTANCE_NAME的值一致SERVICE_NAME：①数据库和客户端相连是使用的服务名②在DataGuard中，如果采用动态注册，建议在主备库使用相同的service_names③在DataGuard中，如果采用静态注册，建议在主备库上的listener中输入相同的服务名(service_name)④如果采监听采用了静态注册，那么SERVICE_NAME就等于Listener.ora文件中的GLOBAL_DATABASE_NAME的值GLOBAL_DATABASE_NAME：①GLOBAL_DATABASE_NAME 是listener配置的对外网络连接名称，可以是任意值②在客户端配置监听的tnsnames.ora 文件中的service_name与这个GLOBAL_DBNAME 保持一致就可以了③配置静态监听注册时，需要输入SID和GLOBAL_NAME"
  },
  
  {
    "title": "Oracle 修改 db_name",
    "url": "/posts/Oracle-%E4%BF%AE%E6%94%B9-db_name/",
    "categories": "DataBase, Oracle",
    "tags": "Oracle",
    "date": "2024-07-18 16:39:03 +0800",
    





    
    "snippet": "有的时候恢复Oracle数据到另一个环境中之后，需要修改相关的实例名、服务名、数据库名等，方便区分不同的环境。以下操作的前提是数据已经恢复到新的环境，在新的环境中修改db_name。仅修改server_name如果仅修改server_name可以直接登录数据库之后操作；sqlplus sys/sys as sysdba SQL&gt; show parameter service_nameS...",
    "content": "有的时候恢复Oracle数据到另一个环境中之后，需要修改相关的实例名、服务名、数据库名等，方便区分不同的环境。以下操作的前提是数据已经恢复到新的环境，在新的环境中修改db_name。仅修改server_name如果仅修改server_name可以直接登录数据库之后操作；sqlplus sys/sys as sysdba SQL&gt; show parameter service_nameSQL&gt; alter system set service_names='orcl' scope=both;--  修改listener.ora 文件中的服务名：SID_LIST_LISTENER =  (SID_LIST =    (SID_DESC =      (SID_NAME = PLSExtProc)      (ORACLE_HOME = E:\\Oracle10g)      (PROGRAM = extproc)    )   (SID_DESC =    (GLOBAL_DBNAME = ORCL)    (ORACLE_HOME = E:\\Oracle10g)    (SID_NAME = ORCL) ##修改server name    ) )LISTENER =  (DESCRIPTION_LIST =    (DESCRIPTION =      (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1))      (ADDRESS = (PROTOCOL = TCP)(HOST = onest)(PORT = 1521))    )  )修改db_name假设已经恢复数据，并且启动了实例，至少处于mount状态，否则无法备份控制文件。此时先不要修改参数文件或者ORACLE_SID信息，不然重启之后会提示错误备份控制文件SQL&gt;  alter database backup controlfile to trace as '/tmp/control.ctl';修改备份的控制文件，备份的控制文件中有两条创建控制文件的提示。根据需求操作， Set #1. NORESETLOGS case 和 Set #2. RESETLOGS case 两个方法因为恢复的数据时候我已经restlogs恢复了，所以此时我只需要重建控制文件即可## 如果需要移动数据文件/表空间目录，可以一并在控制文件重建语句中修改了，vim /tmp/control.ctl-- 如果不需要修改其他参数的话可以直接从spfile启动，不需要单独指定pfile nomount-- STARTUP NOMOUNT--CREATE CONTROLFILE REUSE  修改为 CREATE CONTROLFILE SETCREATE CONTROLFILE SET DATABASE \"db_name\" RESETLOGS  ARCHIVELOG    MAXLOGFILES 16    MAXLOGMEMBERS 3    MAXDATAFILES 100    MAXINSTANCES 8    MAXLOGHISTORY 584LOGFILE  GROUP 1 '/home/u01/app/oracle/oradata/ORACLE_SID/redo01.log'  SIZE 500M BLOCKSIZE 512,  GROUP 2 '/home/u01/app/oracle/oradata/ORACLE_SID/redo02.log'  SIZE 500M BLOCKSIZE 512,  GROUP 3 '/home/u01/app/oracle/oradata/ORACLE_SID/redo03.log'  SIZE 500M BLOCKSIZE 512-- STANDBY LOGFILEDATAFILE  '/home/u01/app/oracle/oradata/ORACLE_SID/system01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/sysaux01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/undotbs01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/users01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/htxt01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace01.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace02.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace03.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace04.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace05.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename02.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename03.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename04.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/undotbs02.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/undotbs03.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/sysaux02dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename05.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename06.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename07.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename08.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename09.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename10.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename11.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename12.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename13.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename14.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace15.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename15.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename16.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename17.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace06.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace07.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspace08.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename18.dbf ', -- 需要注意有可能前期运维人员创建数据文件的时候并不规范，或者复制粘贴的时候多了几个空格，不要手抖删了空格  -- 。。。。  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename44.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename45.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename46.dbf',  '/home/u01/app/oracle/oradata/ORACLE_SID/tabspacename47.dbf'CHARACTER SET AL32UTF8;-- RECOVER DATABASE USING BACKUP CONTROLFILE;修改pfile如果需要修改其他参数的话可以此时一并修改了，例如server_name 、 db_name等create pfile='/tmp/pfile.ora' from spfile;修改pfilevim /tmp/pfile.ora## 多个控制文件使用逗号隔开*.control_files='ctl1','ctl2' *.server_name=''*.db_name=''# *.instance_name='' # 实例名不需要修改，和ORACLE_SID的值是一一对应的停止/启动数据库至如果需要修改instance_name，需要在启动之前修改ORACLE_SID, export ORACLE_SID='XXX'shutdown IMMEDIATE-- 如果需要移动数据文件目录/表空间路径，此时停库之后可以移动到新目录，如果需要修改 instance_name，此时可以退出 sqlplus 修改 ORACLE_SID 之后在重新连接 sqlplus-- $ORACLE_HOME/dbs/init$ORACL_SID.ora 使用上文重新修改之后的pfile文件，也可以备份ora文件之后覆盖源ora文件，startup nomount pfile='initxxx.ora';@/tmp/contrl.ctl-- SQL&gt; alter database mount;SQL&gt; show parameter name--  检查文件头SQL&gt; select file#,status,checkpoint_change# from v$datafile_header;set num 20SQL&gt; select distinct checkpoint_change# from v$datafile_header;-- SQL&gt; alter database open ;SQL&gt; alter database open resetlogs;-- 检查日志show parameter diag修改监听如果修改了服务名，记得修改监听文件中的server_name"
  },
  
  {
    "title": "MySQL 批量杀会话",
    "url": "/posts/MySQL-%E6%89%B9%E9%87%8F%E6%9D%80%E4%BC%9A%E8%AF%9D/",
    "categories": "DataBase, MySQL",
    "tags": "MySQL",
    "date": "2024-07-13 00:39:23 +0800",
    





    
    "snippet": "MySQL的kill语法如下：-- 可以查看帮助手册help kill;KILL [CONNECTION | QUERY] processlist_id;KILL CONNECTION 与不带修饰符的 KILL 相同：它在终止连接正在执行的任何语句后终止与给定 processlist_id 关联的连接。会使对应的会话断开连接。KILL QUERY 终止连接当前正在执行的语句，但保持会话连接。...",
    "content": "MySQL的kill语法如下：-- 可以查看帮助手册help kill;KILL [CONNECTION | QUERY] processlist_id;KILL CONNECTION 与不带修饰符的 KILL 相同：它在终止连接正在执行的任何语句后终止与给定 processlist_id 关联的连接。会使对应的会话断开连接。KILL QUERY 终止连接当前正在执行的语句，但保持会话连接。processlist_id 可以通过 show [full] processlist 或者 performance_schema.threads 的 PROCESSLIST_ID 字段获取，也可以根据 information_schema.processlist 的 ID 字段获取。有的时候需要按照用户或者其他条件批量kill session 。可以参考以下语句：SELECT GROUP_CONCAT(CONCAT('KILL ',id,';') SEPARATOR ' ') 'Paste the following query to kill all processes' FROM information_schema.processlist WHERE user&lt;&gt;'system user'\\GSELECT GROUP_CONCAT(CONCAT('KILL ',PROCESSLIST_ID,';') SEPARATOR ' ') 'Paste the following query to kill all processes' FROM performance_schema.threads WHERE PROCESSLIST_USER&lt;&gt;'system user'\\G需要注意的是，kill session 之后，线程可能需要一些时间才能死掉/结束，如果查询show processlist 的 Command 字段状态为 killed ，有可能是因为会话正在回滚。还有的情况是实例存在异常，可以检查 error log，如果 innodb_buffer_pool_size 设置过小，遇到过一次客户安装的时候采用的默认配置，innodb_buffer_pool_size 只有1G左右，整个服务器的内存16G，有点离谱。在 error log 中会提示如下错误2024-07-04T10:35:05.757216+08:00 4736 [Warning] [MY-011959] [InnoDB] Difficult to find free blocks in the buffer pool (192308 search iterations)! 192308 failed attempts to flush a page! Consider increasing the buffer pool size. It is also possible that in your Unix version fsync is very slow, or completely frozen inside the OS kernel. Then upgrading to a newer version of your operating system may help. Look at the number of fsyncs in diagnostic info below. Pending flushes (fsync) log: 0; buffer pool: 0. 31142769 OS file reads, 77384027 OS file writes, 35847289 OS fsyncs. Starting InnoDB Monitor to print further diagnostics to the standard output.将参数值调整之后很快就恢复正常，这里先不介绍该参数重点是怎么批量 kill session ，后续在讨论参数设置。"
  },
  
  {
    "title": "Linux 批量替换文件夹下面的 Windows 换行符替换为 unix 风格换行符",
    "url": "/posts/Linux-%E6%89%B9%E9%87%8F%E6%9B%BF%E6%8D%A2%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E9%9D%A2%E7%9A%84Windows%E6%8D%A2%E8%A1%8C%E7%AC%A6%E6%9B%BF%E6%8D%A2%E4%B8%BAunix%E9%A3%8E%E6%A0%BC%E6%8D%A2%E8%A1%8C%E7%AC%A6/",
    "categories": "Linux, Bash",
    "tags": "Shell",
    "date": "2024-07-09 23:26:34 +0800",
    





    
    "snippet": "在Linux系统中，Windows风格的换行符（\\r\\n，即回车加换行）和Unix风格的换行符（\\n）是不同的。Windows系统中的文本文件在Linux中可能会显示为带有^M字符的文件，这是因为^M是回车符（CR，Carriage Return）的表示方式。有的时候将Linux中的文件或者Windows的文件互相拷贝的时候会自动转换换行符，经常遇到的情况是Windows下面可以正常运行一些...",
    "content": "在Linux系统中，Windows风格的换行符（\\r\\n，即回车加换行）和Unix风格的换行符（\\n）是不同的。Windows系统中的文本文件在Linux中可能会显示为带有^M字符的文件，这是因为^M是回车符（CR，Carriage Return）的表示方式。有的时候将Linux中的文件或者Windows的文件互相拷贝的时候会自动转换换行符，经常遇到的情况是Windows下面可以正常运行一些unix风格的脚本，但是Linux中却无法运行Windows dos风格的文件。要将一个文件夹中所有文件的Windows换行符替换为Unix风格的换行符，可以使用find命令结合sed或dos2unix工具来完成。以下是几种方法：  使用find和sed:     find /path/to/folder -type f -exec sed -i 's/\\r$//' {} +        这里/path/to/folder是你的文件夹路径。这个命令会找到该文件夹下所有的文件（不包括子文件夹中的文件），并使用sed命令删除每行末尾的^M字符。    使用find和dos2unix: 如果你的系统中安装了dos2unix工具，可以使用以下命令：     find /path/to/folder -type f -exec dos2unix {} +        dos2unix会将Windows格式的文本文件转换为Unix格式。    使用find和unix2dos: 如果你只有unix2dos工具，可以反向使用它来去除^M：     find /path/to/folder -type f -exec unix2dos -n {} {}.unix2dos \\; &amp;&amp; mv {} {}.unix2dos        这个命令首先创建一个临时文件，然后使用unix2dos将Unix格式转换为Windows格式，这会去掉每行末尾的^M。之后，使用mv命令将临时文件替换原文件。    使用fromdos: 在某些Linux发行版中，fromdos是一个可以用来转换文件的工具：     find /path/to/folder -type f -exec fromdos {} \\;      ***需要注意，使用`sed`的`-i`选项会直接修改原文件，所以在执行之前最好备份你的数据。另外，如果文件夹中包含子文件夹，并且你也希望递归地转换子文件夹中的文件，要修改`find`命令来包括`-depth`参数或相应地调整命令。***如果只有一个文件或者文件少的话也可以直接通过一些文本编辑器自带的转换功能。如果使用vim/gvim的话可以在命令行模式使用以下方法转换：## 查看当前换行符:set ff## 替换为Linux:set ff=unix## 替换为Windows:e +iff=dos"
  },
  
  {
    "title": "配置python jupyter 远程访问",
    "url": "/posts/%E9%85%8D%E7%BD%AEpython-jupyter%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/",
    "categories": "Python, jupyter",
    "tags": "Python",
    "date": "2024-07-02 17:00:00 +0800",
    





    
    "snippet": "概述Jupyter Notebook是一种可共享的文档，它结合了计算机代码、简单语言描述、数据、丰富的可视化效果（如 3D 模型、图表、图形和图形）以及交互式控件。笔记本和编辑器（如 JupyterLab）提供了一个快速的交互环境，用于原型设计和解释代码、探索和可视化数据以及与他人分享想法简而言之，Jupyter Notebook是以网页的形式打开，相当于一个网页版便携式的python 代码...",
    "content": "概述Jupyter Notebook是一种可共享的文档，它结合了计算机代码、简单语言描述、数据、丰富的可视化效果（如 3D 模型、图表、图形和图形）以及交互式控件。笔记本和编辑器（如 JupyterLab）提供了一个快速的交互环境，用于原型设计和解释代码、探索和可视化数据以及与他人分享想法简而言之，Jupyter Notebook是以网页的形式打开，相当于一个网页版便携式的python 代码工具，可以在网页页面中可以直接编写代码和运行代码，代码的运行结果也会直接在代码块下显示。如在编程过程中需要编写说明文档，可在同一个页面中直接编写，便于作及时的说明和解释。配置python虚拟开发环境安装jupyter最好先指定一个虚拟开发环境，避免污染全局的配置。怎么配置python的虚拟开发环境可以参考这里┌─[✗]─[wxj@devC]─[/data/Python]└──╼ $ python3 -VPython 3.11.2┌─[wxj@devC]─[/data/Python]└──╼ $ python3 -m venv pyenv┌─[wxj@devC]─[/data/Python]└──╼ $┌─[wxj@devC]─[/data/Python]└──╼ $ source pyenv/bin/activate ## pyenv/bin/activate 实际就是一个文本文件，可以直接查看执行逻辑(pyenv) ┌─[wxj@devC]─[/data/Python] ## 这里(pyenv)就表示当前的开发环境是刚才创建的虚拟开发环境└──╼ $## 配置好之后可以直接查看当前的python信息(pyenv) ┌─[wxj@devC]─[/data/Python]└──╼ $ python -VPython 3.11.2(pyenv) ┌─[wxj@devC]─[/data/Python]└──╼ $ pip -Vpip 23.0.1 from /data/Python/pyenv/lib/python3.11/site-packages/pip (python 3.11)(pyenv) ┌─[wxj@devC]─[/data/Python]└──╼ $ pip listPackage    Version---------- -------pip        23.0.1setuptools 66.1.1(pyenv) ┌─[wxj@devC]─[/data/Python]└──╼ $安装 jupyter notebook## pip install jupyter## 指定下载源为清华源pip install -i https://pypi.tuna.tsinghua.edu.cn/simple jupyterpip list## 安装完成之后可以查看帮助说明，大概了解使用命令jupyter notebook --help使用 jupyter notebook启动启动 jupyter notebook就比较简单了，可以直接不带任何参数启动。默认是127.0.0.1:8888，如果8888端口被占用，会使用其他端口，例如8889。使用本地浏览器打开对应的地址即可。jupyter notebook## 如果使用root用户启动的话，需要添加参数 --allow-rootjupyter notebook --allow-root停止直接使用crtl+c就可以退出。这里需要输入‘y’才会退出，如果超过5s没有输入，则会继续运行。终端关闭或者终止jupyter进程，jupyter notebook也就退出了，无法继续使用浏览器访问。可以使用nohup的方式后台运行程序：nohup jupyter notebook &amp;&gt; notebook.log &amp;也可以使用screen等工具在后台运行，防止终端异常断开之后无法继续使用。很多时候程序都是部署在远程的，需要通过连接的方式访问，jupyter notebook 默认是通过本地访问的。配置远程访问jupyter设置密码先输入python3进入交互模式，输入密码，需要注意的是交互输入的原文密码在终端是不会显示的。如果不想交互输入密码也可以直接将密码写在函数中：passwd('passwd')如果想指定加密方式为sha1：passwd('passwd',algorithm='sha1')生成配置文件在终端输入执行以下命令：jupyter notebook --generate-config执行成功就会自动在根目录下生成文件（~/.jupyter/jupyter_notebook_config.py）,这里可以用vim或者其他文本编辑器编辑就行。这个文件的内容默认都是注释掉的。除了红框中的这一行。修改配置文件可以直接在文件末尾添加自己的配置参数，保险起见可以先备份一份原始文件。## 这里的{,.bak}表示逗号前的内容都相同，\".bak\"表示后缀/多余的字符，在操作文件名很长的时候可以节约tab或者手写的频率，相当于## cp ~/.jupyter/jupyter_notebook_config.py  ~/.jupyter/jupyter_notebook_config.py.bakcp ~/.jupyter/jupyter_notebook_config.py{,.bak}## 添加以下内容c.NotebookApp.ip='*' # 如果这里修过过后启动服务报错 则修改为c.NotebookApp.ip='0.0.0.0'c.NotebookApp.password=u'argon2:$argon2id$v=19$m=10240,t=10,p=8$YPy6gq6WBGap+NHlZAMZow$IR1WDR20vmzV+MzuRkwl3NRYH1AoKsIZjYKsdclJM' #就之前保存的验证密码c.NotebookApp.open_browser =False # 设置是否自动打开浏览器，如果是远程的服务器可以关闭这个选项c.NotebookApp.port =4000  # 设置监听端口c.NotebookApp.allow_remote_access = True ## 允许远程访问c.NotebookApp.notebook_dir='work_dir' # 设置工作/根路径，如果不设置默认是启动jupyter命令时的目录保存退出之后运行jupyter即可。远程访问jupyternohup jupyter notebook &amp;&gt; notebook.log &amp;启动以后在本机的浏览器 输入http://{服务器ip}:port 进行访问。如果远程服务器或者云服务器配置了防火墙，记得打开白名单。打开之后输入之前设置的密码即可。之后就可以在浏览器中利用jupyter运行调试代码了。"
  },
  
  {
    "title": "配置pip镜像源",
    "url": "/posts/%E9%85%8D%E7%BD%AEpip%E9%95%9C%E5%83%8F%E6%BA%90/",
    "categories": "Python, pip",
    "tags": "Python",
    "date": "2024-07-01 17:00:00 +0800",
    





    
    "snippet": "很多时候pip下载安装包的时候都比较慢，可以直接指定为国内的镜像源，提高下载速度。## 查看当前的镜像源pip config list ## 国外镜像有时候下载较慢，可以直接指定国内镜像源下载pip install -i https://pypi.douban.com/simple/ flask## 修改pip的配置文件，将镜像源写入配置文件中。如果没有这个文件就新建一个cat ~/.pip...",
    "content": "很多时候pip下载安装包的时候都比较慢，可以直接指定为国内的镜像源，提高下载速度。## 查看当前的镜像源pip config list ## 国外镜像有时候下载较慢，可以直接指定国内镜像源下载pip install -i https://pypi.douban.com/simple/ flask## 修改pip的配置文件，将镜像源写入配置文件中。如果没有这个文件就新建一个cat ~/.pip/pip.conf[global]index-url = https://pypi.douban.com/simple/## 清华大学源cat ~/.pip/pip.conf[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = https://pypi.tuna.tsinghua.edu.cn"
  },
  
  {
    "title": "WSL Fedora 升级",
    "url": "/posts/WSL-Fedora-%E5%8D%87%E7%BA%A7/",
    "categories": "Linux, Fedora",
    "tags": "WSL",
    "date": "2024-06-27 16:00:00 +0800",
    





    
    "snippet": "Windows11 WSL Fedora 版本升级可以直接使用dnf update，使用如下命令：sudo dnf update --releasever=40 -y    本次升级基于Fedora 39版本，如需要升级到其它版本，将上述命令的–releasever变更为其它版本即可。等待更新完成之后检查。",
    "content": "Windows11 WSL Fedora 版本升级可以直接使用dnf update，使用如下命令：sudo dnf update --releasever=40 -y    本次升级基于Fedora 39版本，如需要升级到其它版本，将上述命令的–releasever变更为其它版本即可。等待更新完成之后检查。"
  },
  
  {
    "title": "vim 安装",
    "url": "/posts/vim-%E5%AE%89%E8%A3%85/",
    "categories": "Vim, Install",
    "tags": "Vim",
    "date": "2024-06-25 16:00:00 +0800",
    





    
    "snippet": "写在前面因为我大部分的运维工作都是在Linux环境中进行的，而且都是命令行操作，为了更加便捷所以决定好好的学习一下vim编辑器。几年前刚接触vi/vim的时候，确实如网上说的那样不知道怎么退出这个神秘的编辑器。又不像图像化界面那样右上角有一个关闭按钮，crtl+c居然也不行，最终靠百度才退出这个难用的编辑器。后来随着工作的原因接触vim的时间也就多了起来。知道怎么退出这个编辑器，除了是在没办...",
    "content": "写在前面因为我大部分的运维工作都是在Linux环境中进行的，而且都是命令行操作，为了更加便捷所以决定好好的学习一下vim编辑器。几年前刚接触vi/vim的时候，确实如网上说的那样不知道怎么退出这个神秘的编辑器。又不像图像化界面那样右上角有一个关闭按钮，crtl+c居然也不行，最终靠百度才退出这个难用的编辑器。后来随着工作的原因接触vim的时间也就多了起来。知道怎么退出这个编辑器，除了是在没办法还是不想用这个玩意儿的。无法像Windows使用crtl+c和crtl+v复制粘贴，编辑器起来真是痛苦，很多时候都是把文件从服务器上传送到本地之后修改，在传送到服务器上。或者在命令行使用管道符和cat的方式将一大段文本写入到文件中。后来慢慢的喜欢上了这个编辑器，编辑文本的效率真的快。还有一个原因是作为IT从业者，很多时候都在座位上坐着，右手长时间使用鼠标导致手臂和食指有点难受，确定尝试一段时间vim。虽然一开始很痛苦，也看了网上关于vim的看法，以及nvim和emacs的对比，不过考虑到Linux环境中一般都安装有vim，为了习惯运维环境，最后还是确定选择vim。使用了一段时间之后右手确实舒服了很多。本人也喜欢折腾各种环境，前段时间利用github pages搭建了一个个人站点，所以也准备将vim的学习和使用通过博客记录下来。安装通过软件仓库安装## Linux系列sudo dnf install -y vim## debiansudo apt install -y vim通过源码编译安装安装依赖## aptapt install -y libncurses-devapt install -y python3-dev## dnfdnf install -y python3-develdnf install -y ncurses-devel获取源码cd ~git clone https://github.com/vim/vim.git编译安装cd vimmake distclean ## 如果之前编译过使用此命令清除缓存## python3-config --configdir 就是操作系统自带的 python3 的 config 目录，/usr/lib/python3.7/config-3.7m-x86_64-linux-gnu ，如果没有这个命令就直接写路径./configure --with-features=huge \\            --enable-multibyte \\            --enable-rubyinterp=yes \\            --enable-python3interp=yes \\            --with-python3-config-dir=$(python3-config --configdir) \\            --enable-luainterp=yes \\            --enable-gui=gtk2 \\            --enable-cscope \\            --prefix=/usr/local/make VIMRUNTIMEDIR=/usr/local/share/vim/vim91cd ~/vimsudo make installvim --version安装gvim如果准备在Windows或者带有桌面的Linux环境中使用vim的话，还是建议把gvim也安装了。Windows直接在download : vim online下载对应的安装包安装即可。Redhat系列sudo dnf install -y vim-X11debain系列sudo apt install -y vim-gui-common设置vim为默认输入法设置环境变量的方式vim ~/.bashrcexport EDITOR=vim通过vim-default长期使用vim之后，不习惯nano，所以直接卸载了nano## 如果后续还需要使用nano的话 可以省略卸载nano rpm -qa | grep -i nanosudo dnf remove nano### 或者直接安装vim-default，先卸载nano-defaultsudo dnf remove nano-default-editor -ysudo dnf install vim-default-editor -y总结vim在编辑文件这一方面个人觉得还是效率还是很高的。我也不需要开发大型的项目，所以使用日常使用vim感觉能提高不少效率。我也会使用vscode和vstudio，在编写python的时候也会使用pycharm，通过这些ide可以让我更加方便编写对应的开发语言。所以ide和vim我都会搭配使用。"
  },
  
  {
    "title": "一键编译部署 PostgreSQL",
    "url": "/posts/%E4%B8%80%E9%94%AE%E7%BC%96%E8%AF%91%E9%83%A8%E7%BD%B2PostgreSQL/",
    "categories": "DataBase, PostgreSQL",
    "tags": "PostgreSQL",
    "date": "2024-06-24 10:17:10 +0800",
    





    
    "snippet": "postgresql-install介绍基于 CentOS7.9 和 PostgreSQL15 一键编译部署 PostgreSQL使用说明新的一年准备学习学习 PostgreSQL，虽然安装简单，但是有的时候可能做一些测试导致环境不能恢复正常。又不想每次都手动安装，现在官网也不提供通用的二进制包，不过好在 PostgreSQL 的源码包比较小，编译时间也不需要太久，为了方便自己偷懒，写了一个...",
    "content": "postgresql-install介绍基于 CentOS7.9 和 PostgreSQL15 一键编译部署 PostgreSQL使用说明新的一年准备学习学习 PostgreSQL，虽然安装简单，但是有的时候可能做一些测试导致环境不能恢复正常。又不想每次都手动安装，现在官网也不提供通用的二进制包，不过好在 PostgreSQL 的源码包比较小，编译时间也不需要太久，为了方便自己偷懒，写了一个简单的 shell。编写和调试期间又在处理其他事情，写的时候思路断断续续，所以脚本中有些地方不是很严谨，有兴趣的伙伴可以自己修改完善。搭建环境是基于 CentOS7.9 和 PostgreSQL15。最开始写的时候用的是 Redhat，考虑到有时候自己的虚拟机直接联网下载依赖包，但是 Redhat 每次都要从官网获取，有时候网络不稳定导致部署依赖包都很慢，所以后来改为了 CentOS7，方便修改国内 yum 源。脚本提供网络访问 yum 仓库和本地挂载 ISO 的方式安装依赖、单机部署和流复制部署（两台主从）。脚本使用时需要把所有文件都放在当前目录下，默认当前目录作为工作目录，日志默认在当前目录下的 pg_install.log。使用-u|--user指定用户的时候，用户可以已经存在，如果不存在则会自动创建。在脚本执行的时候会将 PostgreSQL 源码解压在工作目录，如果需要指定不用的用户，需要手动将上次一次解压后的源码目录（默认 postgresql-15.5）删除。脚本执行日志默认输出工作目录下的 pg_install.log 文件，因为个人不喜欢执行操作的终端输出太多日志把操作记录冲掉，一般都会单独新开一个窗口查看日志，所以脚本的所有输出都重定向到日志文件中了，不在终端显示。##可以使用[-h|--help]查看支持选项，--preview 查看预的部分参数取值[root@darkstar02 postgre_tmp]# ./install-simple.sh -hwork_dir is /postgre_tmp    Usage: pg_install [OPTION]... [FILE]...    -v|--install-version        PostgreSQL version    -f|--software        PostgreSQL software file    -u|--user        PostgreSQL user,default postgres,passwd is \"DarkStar007\"    -i|--cdrom        ISO file.If the parameter \"-y=yes\", then this parameter will be ignored.    -y|--yum-server        default yes.If the value is no, it means that there is no need to configure the software repository and the server can access the internet    -P|--port        database server port (default: \"5432\")    -t|--install-type        single/hot_standby    -h|--help        get help    --preview        Debugging usage, preview parameters,Unable to execute program    -c|--cpu-num        Specify the number of CPUs to be used during compilation, by default, it uses half of the current number of cores.        If the number of CPU cores is less than 4, you need to manually specify the number of CPUs that can be used.    -p|--parameters        default \"--enable-debug --enable-cassert --enable-dtrace --with-python --with-perl  --with-openssl \"    -D|--pg-debug        default --enable-debug = yes.If the parameter -p is specified, it will be ignored    -C|--pg-cassert        default --enable-cassert = yes.If the parameter -p is specified, it will be ignored    -T|--pg-dtrace        default --enable-dtrace = yes.If the parameter -p is specified, it will be ignored    -Y|--pg-python        default --with-python = yes.If the parameter -p is specified, it will be ignored    -E|--pg-perl        default --with-perl = yes.If the parameter -p is specified, it will be ignored    -S|--pg-openssl        default --with-openssl = yes.If the parameter -p is specified, it will be ignored    -m|--primary-host        Hostname or IP address of the primary database. The default IP address bound to the eth0 network interface card.    -s|--standby-host        Hostname or IP address of the standby database.    -d|--install-directory        The installation directory for PostgreSQL    -b|--pgbase=basedir        location of the database storage area ,incluede {data,backup,archive,scripts ....}[root@darkstar02 postgre_tmp]# ./install-simple.sh -p --previewwork_dir is /postgre_tmp    Debugging usage, preview parameters    调试使用，预览参数设置    g_pg_version=15    g_pg_user=postgres    g_iso_name=CentOS-7-x86_64-DVD-2009.iso    g_pg_software=postgresql-15.5.tar.gz    ## 是否需要配置 yum    g_yum_server=yes    ## 切换用户，执行命令    g_use_cpu_num=2    g_db_port=5432    ## 如果需要安装备库，在配置好免密之后还需要尝试一次登录，因为在第一次登录的时候会提示部分信息，会影响程序执行    g_install_type=single    g_standby_host=    ## 安装目录 需要使用绝对路径    g_install_dir=/software/postgresql/pg15    ## 数据目录的上层目录 需要使用绝对路径    g_base_dir=/software/postgresql    ## 为防止存在多块网卡，前期直接指定 eth0 网卡绑定的 ip，centos7 默认网卡名 eth0。如果有多块网卡，建议直接指定 ip 地址或者 hostname    g_primary_host=192.168.120.223    g_cfg_parameters= --enable-debug --enable-cassert --enable-dtrace --with-python --with-perl  --with-openssl执行部署前的目录结构├── CentOS-7-x86_64-DVD-2009.iso \t## ISO├── install-simple.sh \t\t\t\t## 安装脚本├── postgresql-15.5.tar.gz \t\t\t## PostgreSQL 源码压缩包├── python3_pak \t\t\t\t\t## python3-devel 包，通过本地仓库源的时候需要使用└── template \t\t\t\t\t\t## pg_hba.conf postgresql.conf 模板文件目录，可以自行修改参数执行部署之后的目录结构├── backup20240118-0000 \t\t\t## 生成备份文件的目录├── CentOS-7-x86_64-DVD-2009.iso \t## ISO├── install-simple.sh  \t\t\t\t## 安装脚本├── pg_install.log \t\t\t\t\t## 日志文件├── postgresql-15.5  \t\t\t\t## PostgreSQL 源码解压目录，不同用户安装 PostgreSQL 时需要先删除上一次生成的该目录├── postgresql-15.5.tar.gz \t\t\t## PostgreSQL 源码压缩包├── python3_pak \t\t\t\t\t## python3-devel 包，通过本地仓库源的时候需要使用└── template \t\t\t\t\t\t## pg_hba.conf postgresql.conf 模板文件目录，可以自行修改参数工具下载## 百度云链接：https://pan.baidu.com/s/1JBchCrBKPTdrdmnOlopyCA?pwd=ms3t 提取码：ms3t 复制这段内容后打开百度网盘手机 App，操作更方便哦--来自百度网盘超级会员 v6 的分享## gitee 仅包含脚本https://gitee.com/TheDarkStar/postgresql-install## githubhttps://github.com/TheDarkStarJack/postgresql-install参考用法单机默认参数部署## 可以不带任何参数直接运行，默认单机部署，使用--preview 查看部分默认参数值[root@darkstar02 postgre_tmp]# ./install-simple.sh[root@darkstar02 postgre_tmp]# ./install-simple.sh --previewwork_dir is /postgre_tmp    Debugging usage, preview parameters    调试使用，预览参数设置    g_pg_version=15    g_pg_user=postgres    g_iso_name=CentOS-7-x86_64-DVD-2009.iso    g_pg_software=postgresql-15.5.tar.gz    ## 是否需要配置 yum    g_yum_server=yes    ## 切换用户，执行命令    g_use_cpu_num=2    g_db_port=5432    ## 如果需要安装备库，在配置好免密之后还需要尝试一次登录，因为在第一次登录的时候会提示部分信息，会影响程序执行    g_install_type=single    g_standby_host=    ## 安装目录 需要使用绝对路径    g_install_dir=/software/postgresql/pg15    ## 数据目录的上层目录 需要使用绝对路径    g_base_dir=/software/postgresql    ## 为防止存在多块网卡，前期直接指定 eth0 网卡绑定的 ip，centos7 默认网卡名 eth0。如果有多块网卡，建议直接指定 ip 地址或者 hostname    g_primary_host=192.168.120.223    g_cfg_parameters=单机指定参数## -p 的参数包括 -D -C -T  -Y -E -S，图省事可以直接-p，也可以单独指定某一个或者几个参数，单独指定参数的时候不能使用选项-p，否则-p 会覆盖其他几个选项[root@darkstar02 postgre_tmp]# ./install-simple.sh -p[root@darkstar02 postgre_tmp]# ./install-simple.sh -p --previewwork_dir is /postgre_tmp    Debugging usage, preview parameters    调试使用，预览参数设置    g_pg_version=15    g_pg_user=postgres    g_iso_name=CentOS-7-x86_64-DVD-2009.iso    g_pg_software=postgresql-15.5.tar.gz    ## 是否需要配置 yum    g_yum_server=yes    ## 切换用户，执行命令    g_use_cpu_num=2    g_db_port=5432    ## 如果需要安装备库，在配置好免密之后还需要尝试一次登录，因为在第一次登录的时候会提示部分信息，会影响程序执行    g_install_type=single    g_standby_host=    ## 安装目录 需要使用绝对路径    g_install_dir=/software/postgresql/pg15    ## 数据目录的上层目录 需要使用绝对路径    g_base_dir=/software/postgresql    ## 为防止存在多块网卡，前期直接指定 eth0 网卡绑定的 ip，centos7 默认网卡名 eth0。如果有多块网卡，建议直接指定 ip 地址或者 hostname    g_primary_host=192.168.120.223    g_cfg_parameters= --enable-debug --enable-cassert --enable-dtrace --with-python --with-perl  --with-openssl[root@darkstar02 postgre_tmp]# ./install-simple.sh -D[root@darkstar02 postgre_tmp]# ./install-simple.sh -D --previewwork_dir is /postgre_tmp    Debugging usage, preview parameters    调试使用，预览参数设置    g_pg_version=15    g_pg_user=postgres    g_iso_name=CentOS-7-x86_64-DVD-2009.iso    g_pg_software=postgresql-15.5.tar.gz    ## 是否需要配置 yum    g_yum_server=yes    ## 切换用户，执行命令    g_use_cpu_num=2    g_db_port=5432    ## 如果需要安装备库，在配置好免密之后还需要尝试一次登录，因为在第一次登录的时候会提示部分信息，会影响程序执行    g_install_type=single    g_standby_host=    ## 安装目录 需要使用绝对路径    g_install_dir=/software/postgresql/pg15    ## 数据目录的上层目录 需要使用绝对路径    g_base_dir=/software/postgresql    ## 为防止存在多块网卡，前期直接指定 eth0 网卡绑定的 ip，centos7 默认网卡名 eth0。如果有多块网卡，建议直接指定 ip 地址或者 hostname    g_primary_host=192.168.120.223    g_cfg_parameters= --enable-debug流复制安装流复制的部署前提是两台主机提前配置好 root 用户的免密，考虑安全的话可以在部署完成之后手动取消免密。最主要的参数就是-s -t，其他的参数和单机部署一样。流复制部署的时候会简单校验两台服务器的时间，如果时间间隔超过 5 秒，需要先订正时间。## 需要同时指定-s -t 选项，如果仅指定-s 选项，则只会在工作目录生成一个“.standby.cmd.*”文件，并不会自动部署备库[root@darkstar02 postgre_tmp]# ./install-simple.sh -p -s\"192.168.120.244\" -t\"hot_standby\"[root@darkstar02 postgre_tmp]# ./install-simple.sh -p -s\"192.168.120.244\" -t\"hot_standby\" --preview[root@darkstar02 postgre_tmp]# bash install-simple.sh -p -b \"/software/pgsql2\" -d \"/software/pgsql2/pg15\"  -u\"pguser2\" -s\"192.168.120.244\" -t\"hot_standby\"[root@darkstar02 postgre_tmp]# less pg_install.logwork_dir is /postgre_tmpcheck time zone =================darkstar02 timezone is Asia/Shanghaistart config yum ============cmd_mount_iso = mount -o loop CentOS-7-x86_64-DVD-2009.iso /mnt*******cmd_mount_iso: mount -o loop CentOS-7-x86_64-DVD-2009.iso /mnt*******文件系统       类型      容量  已用  可用 已用% 挂载点devtmpfs       devtmpfs  909M     0  909M    0% /devtmpfs          tmpfs     919M     0  919M    0% /dev/shmtmpfs          tmpfs     919M  8.6M  911M    1% /runtmpfs          tmpfs     919M     0  919M    0% /sys/fs/cgroup/dev/sda3      xfs        27G  5.7G   22G   21% //dev/sda1      xfs      1014M  141M  874M   14% /boottmpfs          tmpfs     184M     0  184M    0% /run/user/0······2024-01-18 00:11:46.877 CST [2380] HINT:  Future log output will appear in directory \"pg_log\". doneserver startedConnection to 192.168.120.244 closed.startup standby successful   client_addr   | sync_state-----------------+------------ 192.168.120.244 | async(1 row)end==========================使用网络镜像仓库源编译安装## -y no | --yum-server=no 表示联网安装依赖包[root@darkstar02 postgre_tmp]# bash install-simple.sh  -b \"/software/pgsql1\" -d \"/software/pgsql1/pg15\"  -u\"pguser1\" -s\"192.168.120.244\" -t\"hot_standby\" -y noconfigure 选项参考更多编译选项请参考官网：PostgreSQL: Documentation: 15: 17.4. Installation Procedure      –prefix=PREFIX    PostgreSQL 安装目录，所有的安装文件存放在指定目录 PREFIX 而不是默认的 /usr/local/pgsql。实际文件将被安装到各个子目录中，PREFIX 是安装文件的上层目录。        –enable-debug    开启 debug，一般研究调试源码的时候开启，生产不需要打开。        –enable-cassert    在服务器中启用断言检查，用于测试许多“不应该发生”的情况。开发调试的阶段很有必要，但测试会显著降低服务器的性能。此外，启用测试并不一定会增强服务器的稳定性！断言检查未根据严重程度进行分类，因此，即使触发了断言失败，可能是一个相对无害的错误，也仍会导致服务器重新启动。不建议在生产环境中使用此选项，但在开发工作或运行测试版本时，建议启用它。        –enable-dtrace    启用 PostgreSQL 编译对动态跟踪工具 DTrace 的支持。        –with-python    开启 PL/Python 语言支持，开启之后可以在 PostgreSQL 中使用 python 编写存储函数之类的操作。        –with-perl    开启 PL/Perl 语言支持，开启之后可以在 PostgreSQL 中使用 perl 编写存储函数之类的操作。        –with-openssl    开启 SSL（加密）连接支持。这个选项需要安装 OpenSSL 包。低版本使用的是--with-ssl=openssl。  "
  },
  
  {
    "title": "mssql-如何快速查找链接服务器被那些对象引用-转载",
    "url": "/posts/mssql-%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E6%9F%A5%E6%89%BE%E9%93%BE%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E9%82%A3%E4%BA%9B%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8/",
    "categories": "DataBase, SQL server",
    "tags": "链接服务器",
    "date": "2024-06-22 11:01:19 +0800",
    





    
    "snippet": "前言有时候原始环境不是自己搭建的，但是需要快速查看SQL server中的链接服务器被哪些对象引用，可以使用以下语句。查找链接服务器被那些对象引用原文地址SELECT SRV.[name] AS LinkedServerName, SRV.[data_source] AS LinkedServerDataSource, PRO.[name] AS ObjectName, 'Stored Pr...",
    "content": "前言有时候原始环境不是自己搭建的，但是需要快速查看SQL server中的链接服务器被哪些对象引用，可以使用以下语句。查找链接服务器被那些对象引用原文地址SELECT SRV.[name] AS LinkedServerName, SRV.[data_source] AS LinkedServerDataSource, PRO.[name] AS ObjectName, 'Stored Procedure' AS ObjectTypeFROM sys.servers SRVINNER JOIN sys.procedures PROON (OBJECT_DEFINITION(PRO.[object_id]) LIKE ('%' + SRV.[name] + '%')OR OBJECT_DEFINITION(PRO.[object_id]) LIKE ('%' + SRV.[data_source] + '%'))UNIONSELECT SRV.[name] AS LinkedServerName, SRV.[data_source] AS LinkedServerDataSource, PRO.[name] AS ObjectName, 'View' AS ObjectTypeFROM sys.servers SRVINNER JOIN sys.views PROON (OBJECT_DEFINITION(PRO.[object_id]) LIKE ('%' + SRV.[name] + '%')OR OBJECT_DEFINITION(PRO.[object_id]) LIKE ('%' + SRV.[data_source] + '%'))UNIONSELECT SRV.[name] AS LinkedServerName, SRV.[data_source] AS LinkedServerDataSource, PRO.[name] AS ObjectName, 'Trigger' AS ObjectTypeFROM sys.servers SRVINNER JOIN sys.triggers PROON (OBJECT_DEFINITION(PRO.[object_id]) LIKE ('%' + SRV.[name] + '%')OR OBJECT_DEFINITION(PRO.[object_id]) LIKE ('%' + SRV.[data_source] + '%'))UNIONSELECT SRV.[name] AS LinkedServerName, SRV.[data_source] AS LinkedServerDataSource, PRO.[name] AS ObjectName, 'Function' AS ObjectTypeFROM sys.servers SRVINNER JOIN sys.objects PROON (OBJECT_DEFINITION(PRO.[object_id]) LIKE ('%' + SRV.[name] + '%')OR OBJECT_DEFINITION(PRO.[object_id]) LIKE ('%' + SRV.[data_source] + '%'))WHERE PRO.[type] in ('FN', 'IF', 'FN', 'AF', 'FS', 'FT');```"
  },
  
  {
    "title": "mssql-创建和修改链接服务器",
    "url": "/posts/mssql-%E5%88%9B%E5%BB%BA%E5%92%8C%E4%BF%AE%E6%94%B9%E9%93%BE%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/",
    "categories": "DataBase, SQL server",
    "tags": "链接服务器",
    "date": "2024-06-22 10:43:45 +0800",
    





    
    "snippet": "前言在SQL server中可以使用链接服务器实现跨库访问。近期有客户使用SQL server需要进行跨库访问数据，以下使用SQL Server Management Studio (SSMS)创建链接服务器，并进行权限限制。权限限制在使用 Transact-SQL 语句时，需要在服务器上具有 ALTER ANY LINKED SERVER 权限，或需要具有 setupadmin 固定服务器...",
    "content": "前言在SQL server中可以使用链接服务器实现跨库访问。近期有客户使用SQL server需要进行跨库访问数据，以下使用SQL Server Management Studio (SSMS)创建链接服务器，并进行权限限制。权限限制在使用 Transact-SQL 语句时，需要在服务器上具有 ALTER ANY LINKED SERVER 权限，或需要具有 setupadmin 固定服务器角色中的成员身份。 使用 Management Studio 时，要求具有 CONTROL SERVER 权限，或者具有 sysadmin 固定服务器角色的成员身份。新建链接服务器1、通过mssm登录SQL server之后，打开‘服务器对象’–&gt;右键点击‘链接服务器’新建链接服务器2、在常规页面填写链接服务器IP地址或者域3、在安全性页面选择可以登录的用户，指定可连接到链接服务器的本地登录。 本地登录可以是使用 SQL Server 身份验证的登录，也可以是使用 Windows 身份验证的登录。 不支持使用 Windows 组。 使用此列表可以将连接限定为特定的登录，也可以允许某些登录使用其他登录名进行连接。为了安全管理，此处添加可以使用链接服务器登录的用户，如果此处不添加用户默认对所有用户可见。  不建立连接不对列表中未定义的登录建立连接。  不使用安全上下文建立连接对于列表中未定义的登录，不使用安全上下文建立连接。  使用登录当前的安全上下文建立连接对于列表中未定义的登录，使用登录的当前安全上下文建立连接。 如果使用 Windows 身份验证连接到本地服务器，则使用 Windows 凭据连接到远程服务器。 如果使用 SQL Server 身份验证连接到本地服务器，则在连接到远程服务器时需要使用登录名和密码。 在这种情况下，远程服务器中必须存在名称和密码完全相同的登录。  使用此安全上下文建立连接对于列表中未定义的登录，使用“远程登录”和“使用密码”框中指定的登录名和密码建立连接 。 远程登录必须是远程服务器中的 SQL Server 身份验证登录。4、对于服务器选项，如果没有特殊需求，可以直接保持默认即可，点击确认创建链接服务器5、创建完成之后，点击刷新6、对于没有添加的用户是无法查看到创建的链接服务器的。7、可以点击测试连接，查看是否可以使用链接服务器8、使用链接服务器SELECT name FROM [链接服务器名].master.sys.databases;  GO修改已有链接服务器对于已经存在的链接服务器添加或者删除用户。1、右键选择已存在的链接服务器，然后选择属性2、在安全性页面选择添加或者删除映射即可3、点击确定之后刷新刷新链接服务器，对于删除的用户则无法查看到链接服务器（如果删除的用户具有比较高的数据库权限，虽然无法继续使用链接服务器，但是在链接服务器的的界面还是能看见链接服务器的存在。普通的用户）。新添加的用户在刷新之后就可以正常使用链接服务器。"
  },
  
  {
    "title": "oceanbase3-安装",
    "url": "/posts/oceanbase3-%E5%AE%89%E8%A3%85/",
    "categories": "DataBase, oceanbase",
    "tags": "oceanbase",
    "date": "2024-06-22 08:49:45 +0800",
    





    
    "snippet": "OAT 安装参考文档：这两个文档的安装方式也不一样，试了最后都是卡在判断端口占用这个地方······https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000000021048#b992eff3-aa6f-4144-bd91-cb9bc658de1ehttps://www.oceanbase.com/docs/ent...",
    "content": "OAT 安装参考文档：这两个文档的安装方式也不一样，试了最后都是卡在判断端口占用这个地方······https://www.oceanbase.com/docs/common-oceanbase-database-cn-1000000000021048#b992eff3-aa6f-4144-bd91-cb9bc658de1ehttps://www.oceanbase.com/docs/enterprise-oat-doc-cn-10000000000603664而且容器内部并没有 oatcli 这个命令行工具，find 也没找到，比较坑。安装 docker一键安装，因为测试使用，所以 docker 安装就直接采用默认配置。## 阿里云镜像安装curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun## 或者curl -sSL https://get.daocloud.io/docker | sh建议提前安装 docker，如果使用 oat 安装包内部的 docker，有可能容器就直接启动失败了。日志里也没看出什么问题。手动加载 oat 镜像成功步骤scp 软件到服务器unzip 软件## 进入目录cd /software/Oceanbase/oat/oat-all-in-one-x86docker load -i oat_4.1.0_20230331_x86.tgz ## 加载 oat 压缩包解压之后的 tgz 文件，官网文档这点也没写明oat_image=`docker images | grep oat | awk '{printf $1\":\"$2\"\\n\"}'`mkdir /data_dirdocker run -d --name oat -v /data_dir:/data -p 7000:7000 -p 3306:3306  --restart on-failure:5 $oat_image## 进入容器修改启动脚本docker exec -it 771233935c3b bash## 注释之前请先手动确认端口未被占用vim oat/distribution/prepare/init.sh注释第是 38 行内容## 注释之后手动重启 oat 容器docker restart oat## 验证 oat[root@oat oat-all-in-one-x86]# netstat -anlp | grep 7000tcp        0      0 0.0.0.0:7000            0.0.0.0:*               LISTEN      14766/docker-proxytcp6       0      0 :::7000                 :::*                    LISTEN      14772/docker-proxy[root@oat oat-all-in-one-x86]# curl http://127.0.0.1:7000## 或者浏览器打开网页 如果采用默认密码，在第一次登陆的时候会需要修改密码http://192.168.187.129:7000/踩坑省略上传解压 oat 软件包步骤加载启动 oat 容器[root@oat ~]# cd /software/Oceanbase/oat/oat-all-in-one-x86[root@oat oat-all-in-one-x86]# ll总用量 503368drwxr-xr-x. 2 root root        89  3 月 31 14:27 components-rw-r--r--. 1 root root  56262573  3 月 30 12:13 docker-18.09.9.tgz-rwxr-xr-x. 1 root root      9965  3 月 31 19:37 install.sh-rw-r--r--. 1 root root 459161794  4 月  3 18:29 oat_4.1.0_20230331_x86.tgz-rw-r--r--. 1 root root      1020  3 月 31 17:09 readme.txtdrwxr-xr-x. 2 root root      4096  3 月 31 14:34 tools## 加载 oat 镜像[root@oat oat-all-in-one-x86]# docker load -i oat_4.1.0_20230331_x86.tgz06f6bfff6616: Loading layer [==================================================&gt;]  230.8MB/230.8MBe1505344677e: Loading layer [==================================================&gt;]  3.072kB/3.072kB01ede0eada53: Loading layer [==================================================&gt;]  690.2MB/690.2MB78073091fd9e: Loading layer [==================================================&gt;]  8.704kB/8.704kB5d96997aeb89: Loading layer [==================================================&gt;]  232.8MB/232.8MB17fa9a0a477e: Loading layer [==================================================&gt;]  156.1MB/156.1MBLoaded image: reg.docker.alibaba-inc.com/oceanbase/oat:4.1.0_20230331_x86## 启动 oat 容器[root@oat oat-all-in-one-x86]# oat_image=`docker images | grep oat | awk '{printf $1\":\"$2\"\\n\"}'`[root@oat oat-all-in-one-x86]# echo $oat_imagereg.docker.alibaba-inc.com/oceanbase/oat:4.1.0_20230331_x86[root@oat oat-all-in-one-x86]# docker psCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES[root@oat oat-all-in-one-x86]# docker imagesREPOSITORY                                 TAG                  IMAGE ID       CREATED        SIZEreg.docker.alibaba-inc.com/oceanbase/oat   4.1.0_20230331_x86   c4a217d388ea   5 months ago   1.28GB[root@oat oat-all-in-one-x86]# docker run -d --net host --name oat -v /data_dir:/data --restart on-failure:5 c4a217d388ea771233935c3b90628f6e3657cd1a51fd239944f97b4347ceb01cf6e20278e291##验证检查容器[root@oat oat-all-in-one-x86]# docker psCONTAINER ID   IMAGE          COMMAND                   CREATED         STATUS         PORTS     NAMES771233935c3b   c4a217d388ea   \"/oat/distribution/p…\"   4 seconds ago   Up 2 seconds             oat[root@oat oat-all-in-one-x86]#[root@oat oat-all-in-one-x86]# netstat -anlp | grep 7000[root@oat oat-all-in-one-x86]#查看默认 7000 端口未被监听，查看容器日志[root@oat oat-all-in-one-x86]# docker psCONTAINER ID   IMAGE          COMMAND                   CREATED          STATUS          PORTS     NAMES771233935c3b   c4a217d388ea   \"/oat/distribution/p…\"   33 seconds ago   Up 31 seconds             oat[root@oat oat-all-in-one-x86]# docker logs -f -t 771233935c3b2023-09-25T14:59:08.088278276Z + maria_root_password=MsF_DjxA2N32023-09-25T14:59:08.088460349Z + maria_port=33062023-09-25T14:59:08.088480554Z + DEPLOY_MODE=generic2023-09-25T14:59:08.088491524Z + trap clean SIGHUP SIGINT SIGQUIT SIGTERM2023-09-25T14:59:08.090491828Z + '[' 1 -ne 1 ']'2023-09-25T14:59:08.090527256Z + '[' auto = initdb ']'2023-09-25T14:59:08.090538613Z + '[' auto = auto ']'2023-09-25T14:59:08.090802504Z + prepare_soft_links2023-09-25T14:59:08.090822908Z + '[' '!' -f /oat/manage.py ']'2023-09-25T14:59:08.090833688Z + chmod 755 /data2023-09-25T14:59:08.101254358Z + mkdir -p /data/images /data/db /data/logs /data/binary_packages2023-09-25T14:59:08.110393625Z + mkdir -p /data/logs/tasks2023-09-25T14:59:08.118378616Z + '[' -L /oat/task_engine/logs ']'2023-09-25T14:59:08.118629642Z + rm -rf /oat/task_engine/logs2023-09-25T14:59:08.126820978Z + ln -s /data/logs/tasks /oat/task_engine/logs2023-09-25T14:59:08.135673359Z + initdb2023-09-25T14:59:08.135712560Z + '[' -n '' ']'2023-09-25T14:59:08.135725024Z + start_local_db2023-09-25T14:59:08.136070311Z + lsof -i:3306进入容器检查## 发现容器内部就只有如下两个进程，等待几分钟之后还是没有继续往下执行[root@oat oat]# ps -efUID          PID    PPID  C STIME TTY          TIME CMDroot           1       0  0 22:59 ?        00:00:00 bash /oat/distribution/prepare/init.sh autoroot          12       1 99 22:59 ?        00:01:31 lsof -i:3306root          13       0  0 23:00 pts/0    00:00:00 bashroot          28      13  0 23:00 pts/0    00:00:00 ps -ef## 查看 /oat/distribution/prepare/init.sh[root@9803451aed14 oat]# bash /oat/distribution/prepare/init.sh --help+ maria_root_password=MsF_DjxA2N3+ maria_port=3306+ DEPLOY_MODE=generic+ trap clean SIGHUP SIGINT SIGQUIT SIGTERM+ '[' 1 -ne 1 ']'+ '[' --help = initdb ']'+ '[' --help = auto ']'+ '[' --help = upgrade ']'+ echo 'unsupported arg --help'unsupported arg --help+ usage+ catUsage:  /oat/distribution/prepare/init.sh {initdb, auto}initdb: create or upgrade meta onlyauto:   initdb and start process+ exit 1## 修改初始化脚本内容 将第 38 行的判断方法注释之后重启容器[root@9803451aed14 oat]# vi /oat/distribution/prepare/init.sh  36 # 启动 db     37 function start_local_db() {     38     #lsof -i:\"$maria_port\" &amp;&amp; { echo \"DB port $maria_port is already used, please check!\"; exit 1; }     39     if ! grep -q \"port=\" /etc/my.cnf.d/server.cnf; then  # new empty file     40         cat /oat/distribution/prepare/server.cnf &gt; /etc/my.cnf.d/server.cnf     41     fi容器提示 iptable 异常## 出现以下异常的话 重启容器服务 systemctl restart docker[root@oat oat-all-in-one-x86]# docker rm oatoat[root@oat oat-all-in-one-x86]# docker run -d --name oat -v /data_dir:/data -p 7000:7000 -p 3306:3306  --restart on-failure:5 $oat_image5b6681c44c086ab391c691d5ee562f87e72be263819be1afed8379226ec52126docker: Error response from daemon: driver failed programming external connectivity on endpoint oat (02e89df7d352fcc60a07ab8fb57b3e46484b5716155b30aa5c697e99f64cea74):  (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 7000 -j DNAT --to-destination 172.17.0.2:7000 ! -i docker0: iptables: No chain/target/match by that name. (exit status 1)).[root@oat oat-all-in-one-x86]#[root@oat oat-all-in-one-x86]#[root@oat oat-all-in-one-x86]# systemctl status firewalld○ firewalld.service - firewalld - dynamic firewall daemon     Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; preset: enabled)     Active: inactive (dead) since Mon 2023-09-25 23:10:01 CST; 25min ago   Duration: 24min 40.641s       Docs: man:firewalld(1)    Process: 849 ExecStart=/usr/sbin/firewalld --nofork --nopid $FIREWALLD_ARGS (code=exited, status=0/SUCCESS)   Main PID: 849 (code=exited, status=0/SUCCESS)        CPU: 5.436s9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATI&gt;9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -F DOCKER-ISOLATI&gt;9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATI&gt;9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -F DOCKER-ISOLATI&gt;9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATI&gt;9 月 25 22:55:11 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -D FORWARD -i docker0 -o do&gt;9 月 25 23:10:00 oat systemd[1]: Stopping firewalld - dynamic firewall daemon...9 月 25 23:10:01 oat systemd[1]: firewalld.service: Deactivated successfully.9 月 25 23:10:01 oat systemd[1]: Stopped firewalld - dynamic firewall daemon.9 月 25 23:10:01 oat systemd[1]: firewalld.service: Consumed 5.436s CPU time.[root@oat oat-all-in-one-x86]# date2023 年 09 月 25 日 星期一 23:36:00 CST[root@oat oat-all-in-one-x86]#[root@oat oat-all-in-one-x86]# systemctl status firewalld○ firewalld.service - firewalld - dynamic firewall daemon     Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; preset: enabled)     Active: inactive (dead) since Mon 2023-09-25 23:10:01 CST; 26min ago   Duration: 24min 40.641s       Docs: man:firewalld(1)    Process: 849 ExecStart=/usr/sbin/firewalld --nofork --nopid $FIREWALLD_ARGS (code=exited, status=0/SUCCESS)   Main PID: 849 (code=exited, status=0/SUCCESS)        CPU: 5.436s9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATI&gt;9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -F DOCKER-ISOLATI&gt;9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATI&gt;9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -F DOCKER-ISOLATI&gt;9 月 25 22:55:10 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t filter -X DOCKER-ISOLATI&gt;9 月 25 22:55:11 oat firewalld[849]: WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -D FORWARD -i docker0 -o do&gt;9 月 25 23:10:00 oat systemd[1]: Stopping firewalld - dynamic firewall daemon...9 月 25 23:10:01 oat systemd[1]: firewalld.service: Deactivated successfully.9 月 25 23:10:01 oat systemd[1]: Stopped firewalld - dynamic firewall daemon.9 月 25 23:10:01 oat systemd[1]: firewalld.service: Consumed 5.436s CPU time....skipping...oat 添加服务器第一次登录需要修改密码，进入界面之后添加服务器。添加服务器的时候如果 centos/redhat 版本大于 8 的话，会检查不通过，在检查的脚本里写死了支持的服务器内核和版本。最开始我的机器使用的是 centos stream 9，所以添加服务器的时候检查不通过。修改机器为 centos7之后重新添加机器，在检查服务器的配置时，不满足资源需求，手动将任务设置为成功，成功添加服务器。安装 observer挂载磁盘添加两块独立的 100g 磁盘用于存放日志和数据。## 分区[root@thedarkstar ~]# fdisk /dev/sdb## 格式化[root@thedarkstar ~]# mkdir /data/log1 -p[root@thedarkstar ~]# mkdir -p /data/1[root@thedarkstar ~]# mkfs.ext4 /dev/sdbsdb   sdb1[root@thedarkstar ~]# mkfs.ext4 /dev/sdb1## 挂载[root@thedarkstar ~]# mount /dev/sdb1 /data/log1/[root@thedarkstar ~]# mount /dev/sdc1 /data/1## 开启自动挂载[root@thedarkstar ~]# cat /etc/fstab## /etc/fstab# Created by anaconda on Tue Sep 26 17:47:33 2023## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/centos-root /                       xfs     defaults        0 0UUID=4d1accfd-3f49-417f-9a6c-bcd3d0d7ce33 /boot                   xfs     defaults        0 0/dev/mapper/centos-home /home                   xfs     defaults        0 0/dev/sdb1 /data/log1 ext4    defaults        1 1/dev/sdc1 /data/1 ext4    defaults        1 1安装 observer[root@ob3 ~]# cd /software/Oceanbase/ob/[root@ob3 ob]# lltotal 657016-rw-r--r--. 1 root root 672783996 Sep 26 18:32 oceanbase-3.2.4.1-101000052023010822.el7.x86_64.rpm[root@ob3 ob]# rpm -ivh oceanbase-3.2.4.1-101000052023010822.el7.x86_64.rpmPreparing...                          ################################# [100%]Updating / installing...   1:oceanbase-3.2.4.1-101000052023010################################# [100%][root@ob3 ob]#配置目录卸载/停止 observerkill -15清理export cluster_name=obcluster[root@xxx /home/admin]# rm -rf /data/1/$cluster_name[root@xxx /home/admin]# rm -rf /data/log1/$cluster_name[root@xxx /home/admin]# rm -rf /home/admin/oceanbase/store/$cluster_name[root@xxx /home/admin]# rm -rf /home/admin/oceanbase/log/* /home/admin/oceanbase/etc/*config*创建目录##切换到 admin 用户##[root@xxx /home/admin]# su - adminexport cluster_name=obcluster##使用 admin 用户执行以下命令##[admin@ob3 ~]$ export cluster_name=obcluster[admin@ob3 ~]$ mkdir -p /data/1/$cluster_name/{etc3,sort_dir,sstable,slog}[admin@ob3 ~]$ mkdir -p /data/log1/$cluster_name/{clog,etc2,ilog,oob_clog}[admin@ob3 ~]$ mkdir -p /home/admin/oceanbase/store/$cluster_name[admin@ob3 ~]$ for t in {etc3,sort_dir,sstable,slog};do ln -s /data/1/$cluster_name/$t /home/admin/oceanbase/store/$cluster_name/$t; done[admin@ob3 ~]$ ll /data/1total 20drwx------. 2 root  root  16384 Sep 26 18:36 lost+founddrwxrwxr-x. 6 admin admin  4096 Sep 26 22:22 obcluster[admin@ob3 ~]$ ll /data/1/obcluster/total 16drwxrwxr-x. 2 admin admin 4096 Sep 26 22:22 etc3drwxrwxr-x. 2 admin admin 4096 Sep 26 22:22 slogdrwxrwxr-x. 2 admin admin 4096 Sep 26 22:22 sort_dirdrwxrwxr-x. 2 admin admin 4096 Sep 26 22:22 sstable[admin@ob3 ~]$ for t in {clog,etc2,ilog,oob_clog};do ln -s /data/log1/$cluster_name/$t /home/admin/oceanbase/store/$cluster_name/$t; done初始化 observer## cd /home/admin/oceanbase &amp;&amp; /home/admin/oceanbase/bin/observer {-I $ip | -i $devname} -P $rpc_port -p $sql_port -z $zone_name -d /home/admin/oceanbase/store/$cluster_name -r '$ip:2882:2881' -c $cluster_id -n $cluster_name -o \"system_memory=30G,datafile_size=500G,config_additional_dir=/data/1/$cluster_name/etc3;/data/log1/$cluster_name/etc2\"ip='192.168.187.130'rpc_port=2882sql_port=2881zone_name=zone1cluster_name=obclustercluster_id=1000000001cd /home/admin/oceanbase &amp;&amp; /home/admin/oceanbase/bin/observer   -P $rpc_port -p $sql_port -z $zone_name -d /home/admin/oceanbase/store/$cluster_name -r \"'${ip}:2882:2881'\" -c $cluster_id -n $cluster_name -o \"__min_full_resource_pool_memory=1073741824,system_memory=4G,datafile_size=90G,config_additional_dir=/data/1/$cluster_name/etc3;/data/log1/$cluster_name/etc2\"##########################cd /home/admin/oceanbase &amp;&amp; /home/admin/oceanbase/bin/observer -I $ip  -P $rpc_port -p $sql_port -z $zone_name -d /home/admin/oceanbase/store/$cluster_name -r \"'${ip}:2882:2881'\" -c $cluster_id -n $cluster_name -o \"system_memory=4G,datafile_size=90G,config_additional_dir=/data/1/$cluster_name/etc3;/data/log1/$cluster_name/etc2\"## 比较坑 并没有-I 选项 取消-I 选项之后成功启动 另外-p -P 的端口最开始也写反了 丢cd /home/admin/oceanbase &amp;&amp; /home/admin/oceanbase/bin/observer   -P $rpc_port -p $sql_port -z $zone_name -d /home/admin/oceanbase/store/$cluster_name -r \"'${ip}:2882:2881'\" -c $cluster_id -n $cluster_name -o \"system_memory=4G,datafile_size=90G,config_additional_dir=/data/1/$cluster_name/etc3;/data/log1/$cluster_name/etc2\"[admin@ob3 ~]$ cd /home/admin/oceanbase &amp;&amp; /home/admin/oceanbase/bin/observer   -P $rpc_port -p $sql_port -z $zone_name -d /home/admin/oceanbase/store/$cluster_name -r \"'${ip}:2882:2881'\" -c $cluster_id -n $cluster_name -o \"system_memory=4G,datafile_size=90G,config_additional_dir=/data/1/$cluster_name/etc3;/data/log1/$cluster_name/etc2\"/home/admin/oceanbase/bin/observer -P 2881 -p 2882 -z zone1 -d /home/admin/oceanbase/store/obcluster -r '192.168.187.130:2882:2881' -c 1000000001 -n obcluster -o system_memory=4G,datafile_size=90G,config_additional_dir=/data/1/obcluster/etc3;/data/log1/obcluster/etc2rpc port: 2881mysql port: 2882zone: zone1data_dir: /home/admin/oceanbase/store/obclusterrs list: '192.168.187.130:2882:2881'cluster id: 1000000001appname: obclusteroptstr: system_memory=4G,datafile_size=90G,config_additional_dir=/data/1/obcluster/etc3;/data/log1/obcluster/etc2[admin@ob3 oceanbase]$[admin@ob3 oceanbase]$[admin@ob3 oceanbase]$ ps -fu adminUID         PID   PPID  C STIME TTY          TIME CMDadmin     21030  21029  0 23:15 pts/1    00:00:00 -bashadmin     21073      1 99 23:18 ?        00:00:16 /home/admin/oceanbase/bin/observer -P 2881 -p 2882 -z zone1 -d /home/aadmin     21133  21073 35 23:19 ?        00:00:02 /home/admin/oceanbase/bin/obesi -d -p 2881 -c 1000000001admin     21259  21030  0 23:19 pts/1    00:00:00 ps -fu admin[admin@ob3 oceanbase]$[root@ob3 tools]# netstat -ntlp | grep 288tcp        0      0 0.0.0.0:2881            0.0.0.0:*               LISTEN      21073/observertcp        0      0 0.0.0.0:2882            0.0.0.0:*               LISTEN      21073/observer[root@ob3 tools]#            参数      说明                  -I      -i              -p      指定服务端口号，一般指定为 2881。              -P      指定 RPC 端口号，一般指定为 2882。              -n      指定集群名称。可自定义，不同集群名称不要重复即可。              -z      指定启动的 observer 进程所属的 Zone。              -d      指定集群主目录，初始化目录时创建的目录。除集群名字 $cluster_name 外，其他不要变动。              -c      指定集群 ID。为一组数字，可以自定义，不同集群不要重复即可。              -l      指定日志级别。              -r      指定 RS 列表，格式是 $ip:2882:2881，分号分割，表示 Root Service 信息。              -o      指定集群启动参数，需要根据实际情况设置。system_memory：指定 OceanBase 内部保留内存，默认是 30G ，机器内存比较少的情况下把这个调小，影响就是可能在性能测试时有内存不足问题。datafile_size：指定 OceanBase 数据文件 sstable 的大小（一次性初始化），根据 /data/1/ 可用空间评估，建议不少于 100G，同时又保留一些剩余空间。config_additional_dir 指定参数文件的冗余目录。      system_memory 用于设置系统预留给租户 ID 为 500 的租户的内存容量。[admin@ob3 oceanbase]$ cd /home/admin/oceanbase &amp;&amp; /home/admin/oceanbase/bin/observer -I $ip  -P $rpc_port -p $sql_port -z $zone_name -d /home/admin/oceanbase/store/$cluster_name -r '${ip}:2882:2881' -c $cluster_id -n $cluster_name -o \"system_memory=4G,datafile_size=90G,config_additional_dir=/data/1/$cluster_name/etc3;/data/log1/$cluster_name/etc2\"/home/admin/oceanbase/bin/observer -I 192.168.187.130 -P 2881 -p 2882 -z zone1 -d /home/admin/oceanbase/store/obcluster -r ${ip}:2882:2881 -c 1000000001 -n obcluster -o system_memory=4G,datafile_size=90G,config_additional_dir=/data/1/obcluster/etc3;/data/log1/obcluster/etc2/home/admin/oceanbase/bin/observer: invalid option -- 'I'observer [OPTIONS]  -h,--help                print this help  -z,--zone ZONE           zone  -p,--mysql_port PORT     mysql port  -P,--rpc_port PORT       rpc port  -N,--nodaemon            don't run in daemon  -n,--appname APPNAME     application name  -c,--cluster_id ID       cluster id  -d,--data_dir DIR        OceanBase data directory  -i,--devname DEV         net dev interface  -o,--optstr OPTSTR       extra options string  -r,--rs_list RS_LIST     root service list  -l,--log_level LOG_LEVEL server log level  -6,--ipv6 USE_IPV6   server use ipv6 address  -m,--mode MODE server mode  -f,--scn flashback_scn## 没有--version 选项 但是可以使用······[admin@ob3 ~]$ observer --versionobserver --versionobserver (OceanBase 3.2.4.1)REVISION: 101000052023010822-346aa35c32e99d1b82d713f75f0072c45bdf7aabBUILD_BRANCH: HEADBUILD_TIME: Jan  8 2023 22:52:43BUILD_FLAGS: RelWithDebInfoBUILD_INFO:Copyright (c) 2011-2020 Alipay Inc.连接测试安装 obclient[root@ob3 ~]# cd /software/Oceanbase/tools/[root@ob3 tools]# rpm -ivh obclient-2.2.1-20221122151945.el7.alios7.x86_64.rpmPreparing...                          ################################# [100%]Updating / installing...   1:obclient-2.2.1-20221122151945.el7################################# [100%][root@ob3 tools]# which obclient/usr/bin/obclient[root@ob3 tools]#[root@oat oat-all-in-one-x86]# lscomponents  docker-18.09.9.tgz  install.sh  oat_4.1.0_20230331_x86.tgz  readme.txt  tools[root@oat oat-all-in-one-x86]# cd tools/[root@oat tools]# lsobclient-2.2.1-20221122151945.el7.alios7.x86_64.rpmoblb_140.tarob-loader-dumper-4.1.0-RELEASE.zipob-opstoolkit-1.2.0-20230310155004.el7.x86_64.rpmob-sysbench-1.0.20-11.el7.x86_64.taroceanbase-diagnostic-tool-1.2.0-20230223141142.alios7.x86_64.rpmsql-diagnoser-2.1.0.zip[root@oat tools]# du -sh .295M    .[root@oat tools]# ll ../components/总用量 885352-rw-r--r--. 1 root root 741434405  3 月 31 14:26 meta_OB2277_OBP329_x86_20230330.tgz-rw-r--r--. 1 root root 165162494  3 月 31 14:23 nlb_3.5.1_20230210194413_x86.tgz[root@oat tools]# cd ..[root@oat oat-all-in-one-x86]# scp tools/ 192.168.187.130:/software/Oceanbase/ -r-r: No such file or directory[root@oat oat-all-in-one-x86]# scp -r tools/ 192.168.187.130:/software/Oceanbase/The authenticity of host '192.168.187.130 (192.168.187.130)' can't be established.ED25519 key fingerprint is SHA256:QFZxRDADhGyyuW12dYxxhY7jPAOLgKbwqEadiGIBa6Q.This key is not known by any other namesAre you sure you want to continue connecting (yes/no/[fingerprint])? yesWarning: Permanently added '192.168.187.130' (ED25519) to the list of known hosts.root@192.168.187.130's password:ob-opstoolkit-1.2.0-20230310155004.el7.x86_64.rpm                           100% 9930KB  33.9MB/s   00:00oceanbase-diagnostic-tool-1.2.0-20230223141142.alios7.x86_64.rpm            100%   54MB  28.7MB/s   00:01obclient-2.2.1-20221122151945.el7.alios7.x86_64.rpm                         100%   10MB  28.5MB/s   00:00ob-loader-dumper-4.1.0-RELEASE.zip                                          100%  106MB  34.0MB/s   00:03sql-diagnoser-2.1.0.zip                                                     100%   85MB  32.3MB/s   00:02ob-sysbench-1.0.20-11.el7.x86_64.tar                                        100% 1920KB  25.9MB/s   00:00oblb_140.tar                                                                100%   28MB  21.6MB/s   00:01[root@oat oat-all-in-one-x86]#obclient 连接## 密码默认为空[admin@ob3 ~]$ obclient -h127.0.0.1 -P2881 -uroot@sys -pEnter password:Welcome to the OceanBase.  Commands end with ; or \\g.Your OceanBase connection id is 3221225473Server version: OceanBase 3.2.4.1 (r101000052023010822-346aa35c32e99d1b82d713f75f0072c45bdf7aab) (Built Jan  8 2023 22:52:43)Copyright (c) 2000, 2018, OceanBase and/or its affiliates. All rights reserved.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.obclient [(none)]&gt; show databases;ERROR 1146 (42S02): Table 'oceanbase.__all_database' doesn't existobclient [(none)]&gt; SET SESSION ob_query_timeout=1000000000;Query OK, 0 rows affected (0.005 sec)obclient [(none)]&gt; show databases;ERROR 1146 (42S02): Table 'oceanbase.__all_database' doesn't existobclient [(none)]&gt;集群 bootstrap 操作## 因为上文指定的端口反了  此处 rpc 是 2882obclient [(none)]&gt; SET SESSION ob_query_timeout=1000000000;ALTER SYSTEM BOOTSTRAP ZONE 'zone1' SERVER '192.168.187.130:2882';obclient [(none)]&gt; show databases;+--------------------+| Database           |+--------------------+| oceanbase          || information_schema || mysql              || SYS                || LBACSYS            || ORAAUDITOR         || test               |+--------------------+7 rows in set (0.037 sec)手动部署的，命令行启动的时候没有指定__min_full_resource_pool_memory ，这个参数有默认值吗（是多大呢）？ - 社区问答- OceanBase 社区-分布式数据库经测试需要在初始化启动 observer 的时候指定该参数obclient [(none)]&gt; ALTER SYSTEM BOOTSTRAP ZONE 'zone1' SERVER '192.168.187.130:2881';ERROR 1235 (0A000): unit min memory less than __min_full_resource_pool_memory not supportedobclient [(none)]&gt; alter system __min_full_resource_pool_memory = 1073741824 ;"
  },
  
  {
    "title": "Linux 下查看磁盘是SSD还是HDD",
    "url": "/posts/Linux-%E6%9F%A5%E7%9C%8B%E7%A3%81%E7%9B%98%E6%98%AFSSD%E8%BF%98%E6%98%AFHDD/",
    "categories": "Linux, Tutorial",
    "tags": "Linux",
    "date": "2024-06-22 00:34:00 +0800",
    





    
    "snippet": "lsscsi通过lsscsi命令查看。lsscsi命令来自英文词组“List SCSI”的缩写，其功能是用于列出SCSI设备及属性信息，SCSI全称为small computer system interface，是一种常用的小型计算机系统接口。lsscsi命令可以很方便地帮助管理员区分哪些是固态硬盘、哪些是SATA盘、哪些是FC盘。不过在我的腾讯云服务器和旧的笔记本上都没有获取到对应的信息...",
    "content": "lsscsi通过lsscsi命令查看。lsscsi命令来自英文词组“List SCSI”的缩写，其功能是用于列出SCSI设备及属性信息，SCSI全称为small computer system interface，是一种常用的小型计算机系统接口。lsscsi命令可以很方便地帮助管理员区分哪些是固态硬盘、哪些是SATA盘、哪些是FC盘。不过在我的腾讯云服务器和旧的笔记本上都没有获取到对应的信息。如果你也无法通过lsscsi获取到磁盘类型的话，可以通过下文lsblk命令获取。lsscsi命令英文手册https://sg.danny.cz/scsi/lsscsi.htmllsscsi 命令语法：lsscsi [选项] [H:C:T:L]lsscsi 命令选项：            选项      含义                  -g      显示SCSI通用设备文件名称              -k      显示内核名称而不是设备节点名              -d      显示设备节点的主要号码和次要号码              -H      列出当前连接到系统的SCSI主机而不是SCSI设备              -l      显示每一个SCSI设备（主机）的附加信息              -c      相对于执行 cat /proc/scsi/scsi 命令的输出              -p      显示额外的数据完整性（保护）的信息              -t      显示传输信息              -L      以“属性名=值”的方式显示附加信息              -v      当信息找到时输出目录名              -y      假设sysfs挂载在指定路径而不是默认的 “/sys”              -s      显示容量大小。              -c      用全称显示默认的信息。              -d      显示设备主，次设备号。              -g      显示对应的sg设备名。              -H      显示主机控制器列表，-Hl,-Hlv。              -l      显示相关属性，-ll,-lll=-L。              -v      显示设备属性所在目录。              -x      以16进制显示lun号。              -p      输出DIF,DIX 保护类型。              -P      输出有效的保护模式信息。              -i      显示udev相关的属性              -w      显示WWN              -t      显示相应传输信息(ATA,FC,SBP,ISCSI,SPI,SAS,SATA,USB)，-Ht,-tl.（包括sas地址）      如果系统没有的话可以直接dnf或者apt安装。#Debianapt-get install lsscsi #Ubuntuapt-get install lsscsi #Alpineapk add lsscsi #Arch Linuxpacman -S lsscsi #Kali Linuxapt-get install lsscsi #CentOSyum install lsscsi #Fedoradnf install lsscsi #Raspbianapt-get install lsscsi #Dockerdocker run cmd.cat/lsscsi lsscsi我的腾讯云服务器，通过lsscsi查看，可以发现是QEMU。## 如果系统没有的话可以直接dnf或者apt安装┌─[root@DarkStarDevC]─[~]└──╼ # dnf install -y lsscsi┌─[root@DarkStarDevC]─[~]└──╼ # lsscsi[0:0:1:0]    cd/dvd  QEMU     QEMU DVD-ROM     2.5+  /dev/sr0腾讯云轻量服务器的信息磁盘信息如下：┌─[root@devC]─[~]└──╼ # lsscsi[0:0:1:0]    cd/dvd  QEMU     QEMU DVD-ROM     2.5+  /dev/sr0大学时期买的笔记本可以查看到的信息如下：wxj@wxj-PC:~$ sudo apt install -y lsscsiwxj@wxj-PC:~$ lsscsi[0:0:0:0]    disk    ATA      KINGSTON SHFS37A BBF0  /dev/sda[2:0:0:0]    disk    ATA      ST500LT012-1DG14 LVM1  /dev/sdblsblklsblk命令的英文是“list block”，即用于列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，但是它不会列出RAM盘的信息。块设备有硬盘，闪存盘，CD-ROM等等。lsblk命令包含util-linux中。通过yum provides lsblk命令查看命令对应的软件包。-d 输出设备名称-o 仅显示特定的列如果rota列的值是1 证明是可以旋转，就是HDD，反之数值是0是SSDwxj@wxj-PC:~$ lsblk  -d -o name,rotaNAME    ROTAsda    0sdb    1┌─[root@DarkStarDevC]─[~]└──╼ # lsblk  -d -o name,rotaNAME  ROTAsr0      1zram0    0vda      1vdb      1获取帮助信息┌─[root@DarkStarDevC]─[~]└──╼ # lsblk --helpUsage: lsblk [options] [&lt;device&gt; ...]List information about block devices.Options: -A, --noempty        don't print empty devices -D, --discard        print discard capabilities -E, --dedup &lt;column&gt; de-duplicate output by &lt;column&gt; -I, --include &lt;list&gt; show only devices with specified major numbers -J, --json           use JSON output format -M, --merge          group parents of sub-trees (usable for RAIDs, Multi-path) -O, --output-all     output all columns -P, --pairs          use key=\"value\" output format -S, --scsi           output info about SCSI devices -N, --nvme           output info about NVMe devices -v, --virtio         output info about virtio devices -T, --tree[=&lt;column&gt;] use tree format output -a, --all            print all devices -b, --bytes          print SIZE in bytes rather than in human readable format -d, --nodeps         don't print slaves or holders -e, --exclude &lt;list&gt; exclude devices by major number (default: RAM disks) -f, --fs             output info about filesystems -i, --ascii          use ascii characters only -l, --list           use list format output -m, --perms          output info about permissions -n, --noheadings     don't print headings -o, --output &lt;list&gt;  output columns -p, --paths          print complete device path -r, --raw            use raw output format -s, --inverse        inverse dependencies -t, --topology       output info about topology -w, --width &lt;num&gt;    specifies output width as number of characters -x, --sort &lt;column&gt;  sort output by &lt;column&gt; -y, --shell          use column names to be usable as shell variable identifiers -z, --zoned          print zone related information     --sysroot &lt;dir&gt;  use specified directory as system root -h, --help           display this help -V, --version        display versionAvailable output columns:    ALIGNMENT  alignment offset      ID-LINK  the shortest udev /dev/disk/by-id link name           ID  udev ID (based on ID-LINK)     DISC-ALN  discard alignment offset          DAX  dax-capable device    DISC-GRAN  discard granularity     DISK-SEQ  disk sequence number     DISC-MAX  discard max bytes    DISC-ZERO  discard zeroes data      FSAVAIL  filesystem size available      FSROOTS  mounted filesystem roots       FSSIZE  filesystem size       FSTYPE  filesystem type       FSUSED  filesystem size used       FSUSE%  filesystem use percentage        FSVER  filesystem version        GROUP  group name         HCTL  Host:Channel:Target:Lun for SCSI      HOTPLUG  removable or hotplug device (usb, pcmcia, ...)        KNAME  internal kernel device name        LABEL  filesystem LABEL      LOG-SEC  logical sector size      MAJ:MIN  major:minor device number       MIN-IO  minimum I/O size         MODE  device node permissions        MODEL  device identifier           MQ  device queues         NAME  device name       OPT-IO  optimal I/O size        OWNER  user name    PARTFLAGS  partition flags    PARTLABEL  partition LABEL        PARTN  partition number as read from the partition table     PARTTYPE  partition type code or UUID PARTTYPENAME  partition type name     PARTUUID  partition UUID         PATH  path to the device node      PHY-SEC  physical sector size       PKNAME  internal parent kernel device name       PTTYPE  partition table type       PTUUID  partition table identifier (usually UUID)           RA  read-ahead of the device         RAND  adds randomness          REV  device revision           RM  removable device           RO  read-only device         ROTA  rotational device      RQ-SIZE  request queue size        SCHED  I/O scheduler name       SERIAL  disk serial number         SIZE  size of the device        START  partition start offset        STATE  state of the device   SUBSYSTEMS  de-duplicated chain of subsystems   MOUNTPOINT  where the device is mounted  MOUNTPOINTS  all locations where device is mounted         TRAN  device transport type         TYPE  device type         UUID  filesystem UUID       VENDOR  device vendor        WSAME  write same max bytes          WWN  unique storage identifier        ZONED  zone model      ZONE-SZ  zone size   ZONE-WGRAN  zone write granularity     ZONE-APP  zone append max bytes      ZONE-NR  number of zones    ZONE-OMAX  maximum number of open zones    ZONE-AMAX  maximum number of active zonesFor more details see lsblk(8)."
  }
  
]

